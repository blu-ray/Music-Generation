{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Genration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wcB5DVhdlDz",
        "colab_type": "text"
      },
      "source": [
        "# Data Gathering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5oJuKywQwaN",
        "colab_type": "code",
        "outputId": "48798f6f-8f33-4530-cf68-05f9e7c47309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "## ABC format DATA\n",
        "! curl -L \"https://api.ipfsbrowser.com/ipfs/download.php?hash=QmSM68rjRZL5WdJFqZqWS33BBrebGMGbmdSnUP56wVeFTx\" > 'abc_data.txt'\n",
        "\n",
        "#MIDI Library\n",
        "!curl -L \"https://pjb.com.au/midi/free/MIDI.py\" > 'MIDI.py'\n",
        "\n",
        "## MIDI format Mozart Data\n",
        "!wget http://www.piano-midi.de/zip/mozart.zip\n",
        "!sudo apt-get install unzip\n",
        "!unzip mozart.zip -d Dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  157k  100  157k    0     0   346k      0 --:--:-- --:--:-- --:--:--  346k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 69122  100 69122    0     0  73769      0 --:--:-- --:--:-- --:--:-- 73690\n",
            "--2020-01-27 19:28:47--  http://www.piano-midi.de/zip/mozart.zip\n",
            "Resolving www.piano-midi.de (www.piano-midi.de)... 82.165.134.185\n",
            "Connecting to www.piano-midi.de (www.piano-midi.de)|82.165.134.185|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167294 (163K) [application/zip]\n",
            "Saving to: ‘mozart.zip’\n",
            "\n",
            "mozart.zip          100%[===================>] 163.37K   786KB/s    in 0.2s    \n",
            "\n",
            "2020-01-27 19:28:48 (786 KB/s) - ‘mozart.zip’ saved [167294/167294]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "Archive:  mozart.zip\n",
            "  inflating: Dataset/mz_333_2.mid    \n",
            "  inflating: Dataset/mz_330_2.mid    \n",
            "  inflating: Dataset/mz_330_3.mid    \n",
            "  inflating: Dataset/mz_333_1.mid    \n",
            "  inflating: Dataset/mz_330_1.mid    \n",
            "  inflating: Dataset/mz_333_3.mid    \n",
            "  inflating: Dataset/mz_331_1.mid    \n",
            "  inflating: Dataset/mz_331_2.mid    \n",
            "  inflating: Dataset/mz_331_3.mid    \n",
            "  inflating: Dataset/mz_332_1.mid    \n",
            "  inflating: Dataset/mz_332_2.mid    \n",
            "  inflating: Dataset/mz_332_3.mid    \n",
            "  inflating: Dataset/mz_311_1.mid    \n",
            "  inflating: Dataset/mz_311_2.mid    \n",
            "  inflating: Dataset/mz_311_3.mid    \n",
            "  inflating: Dataset/mz_545_3.mid    \n",
            "  inflating: Dataset/mz_545_1.mid    \n",
            "  inflating: Dataset/mz_545_2.mid    \n",
            "  inflating: Dataset/mz_570_1.mid    \n",
            "  inflating: Dataset/mz_570_2.mid    \n",
            "  inflating: Dataset/mz_570_3.mid    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4AZQjjIQzk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MIDI Dataset to songs.ms converter \n",
        "import MIDI\n",
        "import os\n",
        "\n",
        "\n",
        "def write_notes(file_address):\n",
        "    midi_file = open(file_address, 'rb')\n",
        "    score = MIDI.midi2score(midi_file.read())\n",
        "    midi_file.close()\n",
        "    # ['note', start_time, duration, channel, note, velocity]\n",
        "\n",
        "    itrack = 1\n",
        "    notes = []\n",
        "    this_channel_has_note = False\n",
        "    while itrack < len(score):\n",
        "        for event in score[itrack]:\n",
        "            if event[0] == 'note':  # for example,\n",
        "                this_channel_has_note = True\n",
        "                notes.append(event[4])\n",
        "\n",
        "        itrack += 1\n",
        "        if this_channel_has_note and len(notes) > 20:\n",
        "            break\n",
        "\n",
        "    with open('songs.ms', 'a') as song_file:  # append\n",
        "        song_file.write('\\n')\n",
        "        for note in notes:\n",
        "            song_file.write(chr(note + 35))\n",
        "        song_file.write('\\t')\n",
        "\n",
        "dataset_addr = \"Dataset\"\n",
        "files = os.listdir(dataset_addr)\n",
        "for file in files:\n",
        "    path = os.path.join(dataset_addr, file)\n",
        "    write_notes(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qu2gDdOesjp",
        "colab_type": "text"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GYpt0CGKLKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "SEQ_LENGTH = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt5s0maT6zyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_unique_chars_dicts(data):\n",
        "    set_of_unique_chars = set(data)\n",
        "    list_of_unique_chars = sorted(list(set_of_unique_chars))\n",
        "    char_to_index = {}\n",
        "    for i in range(len(list_of_unique_chars)):\n",
        "        char_to_index[list_of_unique_chars[i]] = i\n",
        "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
        "    return char_to_index, index_to_char\n",
        "\n",
        "def read_batches(all_chars, unique_chars):\n",
        "    length = all_chars.shape[0]\n",
        "    batch_chars = int(length / BATCH_SIZE)\n",
        "    for start in range(0, batch_chars - SEQ_LENGTH, 64):\n",
        "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))\n",
        "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))\n",
        "        for batch_index in range(0, 16):  \n",
        "            for i in range(0, 64):\n",
        "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
        "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1\n",
        "        yield X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66odJ3O566RJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model(batch_size, seq_length, num_of_unique_chars):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim = num_of_unique_chars, output_dim = 512, \n",
        "                        batch_input_shape = (batch_size, seq_length))) \n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(TimeDistributed(Dense(num_of_unique_chars)))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J1B8dKwNR9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, model_name, num_of_epochs = 100):\n",
        "  epoch_report = {}\n",
        "      \n",
        "  for epoch in range(num_of_epochs):\n",
        "      print(\"Epoch {}/{}\".format(epoch+1, num_of_epochs))\n",
        "\n",
        "      average_epoch_loss = 0\n",
        "      average_epoch_acc = 0\n",
        "      counter = 0\n",
        "\n",
        "      for i, (x, y) in enumerate(read_batches(chars_of_data, num_of_unique_chars)):\n",
        "          if (i + 1) % 5:\n",
        "            counter += 1\n",
        "            batch_loss, batch_accuracy = model.train_on_batch(x, y)\n",
        "            average_epoch_loss += batch_loss\n",
        "            average_epoch_acc += batch_accuracy\n",
        "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, batch_loss, batch_accuracy))\n",
        "          else:\n",
        "            batch_loss, batch_accuracy = model.test_on_batch(x, y)\n",
        "            print(f\"TEST Loss: {batch_loss}, Accuracy: {batch_accuracy}\")\n",
        "\n",
        "      epoch_report[epoch] = (average_epoch_loss / (counter), average_epoch_acc / (counter))\n",
        "      \n",
        "      if (epoch + 1) % 10 == 0:\n",
        "          model.save_weights(f\"Weights_{model_name}.h5\")\n",
        "          print(f'Saved Weights at epoch {epoch+1} to file Weights_{model_name}.h5')\n",
        "\n",
        "  for epoch_num in epoch_report.keys():\n",
        "    epoch_loss, epoch_acc = epoch_report[epoch_num]\n",
        "    print(f\"{epoch_num}\\t{epoch_loss}\\t{epoch_acc}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiuQdPJxkkRy",
        "colab_type": "code",
        "outputId": "fbcc6fd0-7438-419b-d9ec-f3a78e52d5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with open('songs.ms', 'r') as data_file:\n",
        "    data = data_file.read()\n",
        "\n",
        "char_to_index, index_to_char = get_data_unique_chars_dicts(data)\n",
        "num_of_unique_chars = len(char_to_index)\n",
        "chars_of_data = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
        "\n",
        "model = make_model(BATCH_SIZE, SEQ_LENGTH, num_of_unique_chars)\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", \n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "train(model, \"mozart\", 100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Batch: 1, Loss: 3.871164321899414, Accuracy: 0.0205078125\n",
            "Batch: 2, Loss: 3.854757785797119, Accuracy: 0.12109375\n",
            "Batch: 3, Loss: 3.82728910446167, Accuracy: 0.1025390625\n",
            "Batch: 4, Loss: 3.731536388397217, Accuracy: 0.091796875\n",
            "TEST Loss: 3.515650749206543, Accuracy: 0.0869140625\n",
            "Batch: 6, Loss: 3.4810843467712402, Accuracy: 0.0791015625\n",
            "Batch: 7, Loss: 3.2807648181915283, Accuracy: 0.103515625\n",
            "Batch: 8, Loss: 3.29886794090271, Accuracy: 0.0859375\n",
            "Batch: 9, Loss: 3.243844509124756, Accuracy: 0.087890625\n",
            "TEST Loss: 3.285658836364746, Accuracy: 0.0888671875\n",
            "Batch: 11, Loss: 3.4977431297302246, Accuracy: 0.0693359375\n",
            "Batch: 12, Loss: 3.3195223808288574, Accuracy: 0.0576171875\n",
            "Batch: 13, Loss: 3.2680563926696777, Accuracy: 0.068359375\n",
            "Batch: 14, Loss: 3.304166793823242, Accuracy: 0.09765625\n",
            "TEST Loss: 3.241425037384033, Accuracy: 0.0966796875\n",
            "Batch: 16, Loss: 3.1723008155822754, Accuracy: 0.0986328125\n",
            "Batch: 17, Loss: 3.2595808506011963, Accuracy: 0.080078125\n",
            "Batch: 18, Loss: 3.2784245014190674, Accuracy: 0.0859375\n",
            "Batch: 19, Loss: 3.215078353881836, Accuracy: 0.0869140625\n",
            "TEST Loss: 3.2438178062438965, Accuracy: 0.0517578125\n",
            "Batch: 21, Loss: 3.1478700637817383, Accuracy: 0.076171875\n",
            "Batch: 22, Loss: 3.20609712600708, Accuracy: 0.087890625\n",
            "Batch: 23, Loss: 3.1774823665618896, Accuracy: 0.0791015625\n",
            "Batch: 24, Loss: 3.2356505393981934, Accuracy: 0.08203125\n",
            "TEST Loss: 3.3524279594421387, Accuracy: 0.080078125\n",
            "Batch: 26, Loss: 3.374467134475708, Accuracy: 0.07421875\n",
            "Batch: 27, Loss: 3.1998724937438965, Accuracy: 0.072265625\n",
            "Batch: 28, Loss: 3.181881904602051, Accuracy: 0.10546875\n",
            "Batch: 29, Loss: 3.1970481872558594, Accuracy: 0.0849609375\n",
            "TEST Loss: 3.0955586433410645, Accuracy: 0.1005859375\n",
            "Batch: 31, Loss: 3.2377820014953613, Accuracy: 0.0625\n",
            "Batch: 32, Loss: 3.132927417755127, Accuracy: 0.0830078125\n",
            "Batch: 33, Loss: 3.01839542388916, Accuracy: 0.099609375\n",
            "Batch: 34, Loss: 3.2959084510803223, Accuracy: 0.076171875\n",
            "TEST Loss: 3.140928268432617, Accuracy: 0.076171875\n",
            "Batch: 36, Loss: 3.1794214248657227, Accuracy: 0.083984375\n",
            "Batch: 37, Loss: 3.1567649841308594, Accuracy: 0.0888671875\n",
            "Epoch 2/100\n",
            "Batch: 1, Loss: 3.1026663780212402, Accuracy: 0.115234375\n",
            "Batch: 2, Loss: 3.1430530548095703, Accuracy: 0.09765625\n",
            "Batch: 3, Loss: 3.1694493293762207, Accuracy: 0.09375\n",
            "Batch: 4, Loss: 3.1081466674804688, Accuracy: 0.0966796875\n",
            "TEST Loss: 3.11083722114563, Accuracy: 0.1025390625\n",
            "Batch: 6, Loss: 3.172313928604126, Accuracy: 0.08203125\n",
            "Batch: 7, Loss: 3.034644603729248, Accuracy: 0.1015625\n",
            "Batch: 8, Loss: 3.067755699157715, Accuracy: 0.1083984375\n",
            "Batch: 9, Loss: 3.051590919494629, Accuracy: 0.1142578125\n",
            "TEST Loss: 3.1329805850982666, Accuracy: 0.1064453125\n",
            "Batch: 11, Loss: 3.163516044616699, Accuracy: 0.0947265625\n",
            "Batch: 12, Loss: 3.07175350189209, Accuracy: 0.0986328125\n",
            "Batch: 13, Loss: 3.0998332500457764, Accuracy: 0.1025390625\n",
            "Batch: 14, Loss: 3.097148895263672, Accuracy: 0.115234375\n",
            "TEST Loss: 2.9979281425476074, Accuracy: 0.111328125\n",
            "Batch: 16, Loss: 2.9409093856811523, Accuracy: 0.12109375\n",
            "Batch: 17, Loss: 3.030848741531372, Accuracy: 0.1025390625\n",
            "Batch: 18, Loss: 3.0854039192199707, Accuracy: 0.10546875\n",
            "Batch: 19, Loss: 3.0002434253692627, Accuracy: 0.1259765625\n",
            "TEST Loss: 2.992870330810547, Accuracy: 0.119140625\n",
            "Batch: 21, Loss: 2.9233717918395996, Accuracy: 0.1162109375\n",
            "Batch: 22, Loss: 2.96454119682312, Accuracy: 0.1083984375\n",
            "Batch: 23, Loss: 3.013411521911621, Accuracy: 0.11328125\n",
            "Batch: 24, Loss: 3.01809024810791, Accuracy: 0.1240234375\n",
            "TEST Loss: 3.0334725379943848, Accuracy: 0.1142578125\n",
            "Batch: 26, Loss: 3.0994324684143066, Accuracy: 0.109375\n",
            "Batch: 27, Loss: 2.9781928062438965, Accuracy: 0.1064453125\n",
            "Batch: 28, Loss: 2.9923582077026367, Accuracy: 0.111328125\n",
            "Batch: 29, Loss: 3.0004024505615234, Accuracy: 0.1142578125\n",
            "TEST Loss: 2.8466885089874268, Accuracy: 0.12890625\n",
            "Batch: 31, Loss: 2.960627317428589, Accuracy: 0.123046875\n",
            "Batch: 32, Loss: 2.928915023803711, Accuracy: 0.125\n",
            "Batch: 33, Loss: 2.796738624572754, Accuracy: 0.162109375\n",
            "Batch: 34, Loss: 3.0244626998901367, Accuracy: 0.11328125\n",
            "TEST Loss: 2.8310608863830566, Accuracy: 0.1396484375\n",
            "Batch: 36, Loss: 2.900233268737793, Accuracy: 0.134765625\n",
            "Batch: 37, Loss: 2.927480697631836, Accuracy: 0.1357421875\n",
            "Epoch 3/100\n",
            "Batch: 1, Loss: 2.9496326446533203, Accuracy: 0.1220703125\n",
            "Batch: 2, Loss: 2.9041600227355957, Accuracy: 0.1240234375\n",
            "Batch: 3, Loss: 2.8888099193573, Accuracy: 0.134765625\n",
            "Batch: 4, Loss: 2.8295950889587402, Accuracy: 0.13671875\n",
            "TEST Loss: 2.7725062370300293, Accuracy: 0.171875\n",
            "Batch: 6, Loss: 2.8624768257141113, Accuracy: 0.138671875\n",
            "Batch: 7, Loss: 2.729464054107666, Accuracy: 0.150390625\n",
            "Batch: 8, Loss: 2.774707078933716, Accuracy: 0.140625\n",
            "Batch: 9, Loss: 2.8436996936798096, Accuracy: 0.138671875\n",
            "TEST Loss: 2.919084072113037, Accuracy: 0.1103515625\n",
            "Batch: 11, Loss: 2.8917794227600098, Accuracy: 0.1376953125\n",
            "Batch: 12, Loss: 2.805992603302002, Accuracy: 0.13671875\n",
            "Batch: 13, Loss: 2.7738490104675293, Accuracy: 0.1484375\n",
            "Batch: 14, Loss: 2.806124687194824, Accuracy: 0.14453125\n",
            "TEST Loss: 2.772012710571289, Accuracy: 0.13671875\n",
            "Batch: 16, Loss: 2.7452456951141357, Accuracy: 0.1572265625\n",
            "Batch: 17, Loss: 2.773118495941162, Accuracy: 0.1689453125\n",
            "Batch: 18, Loss: 2.797130823135376, Accuracy: 0.1513671875\n",
            "Batch: 19, Loss: 2.7598793506622314, Accuracy: 0.1337890625\n",
            "TEST Loss: 2.7544031143188477, Accuracy: 0.1396484375\n",
            "Batch: 21, Loss: 2.659022808074951, Accuracy: 0.1640625\n",
            "Batch: 22, Loss: 2.728299140930176, Accuracy: 0.142578125\n",
            "Batch: 23, Loss: 2.80818510055542, Accuracy: 0.1396484375\n",
            "Batch: 24, Loss: 2.7383406162261963, Accuracy: 0.146484375\n",
            "TEST Loss: 2.7860074043273926, Accuracy: 0.16015625\n",
            "Batch: 26, Loss: 2.801675796508789, Accuracy: 0.142578125\n",
            "Batch: 27, Loss: 2.694568634033203, Accuracy: 0.1650390625\n",
            "Batch: 28, Loss: 2.7370824813842773, Accuracy: 0.150390625\n",
            "Batch: 29, Loss: 2.7742326259613037, Accuracy: 0.140625\n",
            "TEST Loss: 2.625676155090332, Accuracy: 0.1708984375\n",
            "Batch: 31, Loss: 2.762174606323242, Accuracy: 0.154296875\n",
            "Batch: 32, Loss: 2.676114082336426, Accuracy: 0.162109375\n",
            "Batch: 33, Loss: 2.546267032623291, Accuracy: 0.201171875\n",
            "Batch: 34, Loss: 2.7992868423461914, Accuracy: 0.1513671875\n",
            "TEST Loss: 2.554110050201416, Accuracy: 0.18359375\n",
            "Batch: 36, Loss: 2.645273208618164, Accuracy: 0.1513671875\n",
            "Batch: 37, Loss: 2.680211305618286, Accuracy: 0.1572265625\n",
            "Epoch 4/100\n",
            "Batch: 1, Loss: 2.759336471557617, Accuracy: 0.1396484375\n",
            "Batch: 2, Loss: 2.6537928581237793, Accuracy: 0.1650390625\n",
            "Batch: 3, Loss: 2.690347909927368, Accuracy: 0.1669921875\n",
            "Batch: 4, Loss: 2.564664602279663, Accuracy: 0.1748046875\n",
            "TEST Loss: 2.539656639099121, Accuracy: 0.2041015625\n",
            "Batch: 6, Loss: 2.591075897216797, Accuracy: 0.1806640625\n",
            "Batch: 7, Loss: 2.45751690864563, Accuracy: 0.1796875\n",
            "Batch: 8, Loss: 2.57387638092041, Accuracy: 0.15234375\n",
            "Batch: 9, Loss: 2.6041409969329834, Accuracy: 0.1767578125\n",
            "TEST Loss: 2.6193742752075195, Accuracy: 0.1611328125\n",
            "Batch: 11, Loss: 2.7181236743927, Accuracy: 0.1435546875\n",
            "Batch: 12, Loss: 2.5871994495391846, Accuracy: 0.1611328125\n",
            "Batch: 13, Loss: 2.5317673683166504, Accuracy: 0.171875\n",
            "Batch: 14, Loss: 2.5494003295898438, Accuracy: 0.1728515625\n",
            "TEST Loss: 2.5531249046325684, Accuracy: 0.19921875\n",
            "Batch: 16, Loss: 2.559124708175659, Accuracy: 0.19140625\n",
            "Batch: 17, Loss: 2.613680839538574, Accuracy: 0.16796875\n",
            "Batch: 18, Loss: 2.6446099281311035, Accuracy: 0.1552734375\n",
            "Batch: 19, Loss: 2.613806962966919, Accuracy: 0.15625\n",
            "TEST Loss: 2.558586597442627, Accuracy: 0.1591796875\n",
            "Batch: 21, Loss: 2.4625463485717773, Accuracy: 0.1796875\n",
            "Batch: 22, Loss: 2.5352625846862793, Accuracy: 0.1796875\n",
            "Batch: 23, Loss: 2.68001651763916, Accuracy: 0.173828125\n",
            "Batch: 24, Loss: 2.6512558460235596, Accuracy: 0.154296875\n",
            "TEST Loss: 2.611863851547241, Accuracy: 0.1787109375\n",
            "Batch: 26, Loss: 2.666598081588745, Accuracy: 0.1689453125\n",
            "Batch: 27, Loss: 2.5020666122436523, Accuracy: 0.1796875\n",
            "Batch: 28, Loss: 2.5609567165374756, Accuracy: 0.1552734375\n",
            "Batch: 29, Loss: 2.6576690673828125, Accuracy: 0.1474609375\n",
            "TEST Loss: 2.5285911560058594, Accuracy: 0.18359375\n",
            "Batch: 31, Loss: 2.6532888412475586, Accuracy: 0.1669921875\n",
            "Batch: 32, Loss: 2.589498996734619, Accuracy: 0.185546875\n",
            "Batch: 33, Loss: 2.454948902130127, Accuracy: 0.2109375\n",
            "Batch: 34, Loss: 2.6242682933807373, Accuracy: 0.1884765625\n",
            "TEST Loss: 2.4325098991394043, Accuracy: 0.2021484375\n",
            "Batch: 36, Loss: 2.511139392852783, Accuracy: 0.1748046875\n",
            "Batch: 37, Loss: 2.5678272247314453, Accuracy: 0.166015625\n",
            "Epoch 5/100\n",
            "Batch: 1, Loss: 2.678253650665283, Accuracy: 0.154296875\n",
            "Batch: 2, Loss: 2.5520520210266113, Accuracy: 0.1923828125\n",
            "Batch: 3, Loss: 2.5926308631896973, Accuracy: 0.1708984375\n",
            "Batch: 4, Loss: 2.4848248958587646, Accuracy: 0.1728515625\n",
            "TEST Loss: 2.4536335468292236, Accuracy: 0.212890625\n",
            "Batch: 6, Loss: 2.4869518280029297, Accuracy: 0.205078125\n",
            "Batch: 7, Loss: 2.3285863399505615, Accuracy: 0.220703125\n",
            "Batch: 8, Loss: 2.498694658279419, Accuracy: 0.1611328125\n",
            "Batch: 9, Loss: 2.517106056213379, Accuracy: 0.1796875\n",
            "TEST Loss: 2.4758899211883545, Accuracy: 0.205078125\n",
            "Batch: 11, Loss: 2.5743749141693115, Accuracy: 0.1962890625\n",
            "Batch: 12, Loss: 2.499295234680176, Accuracy: 0.1591796875\n",
            "Batch: 13, Loss: 2.4410641193389893, Accuracy: 0.2119140625\n",
            "Batch: 14, Loss: 2.4625558853149414, Accuracy: 0.1845703125\n",
            "TEST Loss: 2.490642547607422, Accuracy: 0.197265625\n",
            "Batch: 16, Loss: 2.489145278930664, Accuracy: 0.1943359375\n",
            "Batch: 17, Loss: 2.5335049629211426, Accuracy: 0.181640625\n",
            "Batch: 18, Loss: 2.539783000946045, Accuracy: 0.185546875\n",
            "Batch: 19, Loss: 2.556349754333496, Accuracy: 0.1796875\n",
            "TEST Loss: 2.500469446182251, Accuracy: 0.1787109375\n",
            "Batch: 21, Loss: 2.3890819549560547, Accuracy: 0.19140625\n",
            "Batch: 22, Loss: 2.488957643508911, Accuracy: 0.1806640625\n",
            "Batch: 23, Loss: 2.57230281829834, Accuracy: 0.1875\n",
            "Batch: 24, Loss: 2.540297746658325, Accuracy: 0.173828125\n",
            "TEST Loss: 2.532938003540039, Accuracy: 0.1962890625\n",
            "Batch: 26, Loss: 2.6121649742126465, Accuracy: 0.20703125\n",
            "Batch: 27, Loss: 2.459526538848877, Accuracy: 0.2138671875\n",
            "Batch: 28, Loss: 2.4602394104003906, Accuracy: 0.2041015625\n",
            "Batch: 29, Loss: 2.5757932662963867, Accuracy: 0.1884765625\n",
            "TEST Loss: 2.475454807281494, Accuracy: 0.2041015625\n",
            "Batch: 31, Loss: 2.601893424987793, Accuracy: 0.1708984375\n",
            "Batch: 32, Loss: 2.5405898094177246, Accuracy: 0.1982421875\n",
            "Batch: 33, Loss: 2.409317970275879, Accuracy: 0.2158203125\n",
            "Batch: 34, Loss: 2.5833499431610107, Accuracy: 0.1943359375\n",
            "TEST Loss: 2.3656375408172607, Accuracy: 0.2353515625\n",
            "Batch: 36, Loss: 2.421342134475708, Accuracy: 0.20703125\n",
            "Batch: 37, Loss: 2.494425058364868, Accuracy: 0.21875\n",
            "Epoch 6/100\n",
            "Batch: 1, Loss: 2.592524528503418, Accuracy: 0.16015625\n",
            "Batch: 2, Loss: 2.5013890266418457, Accuracy: 0.1962890625\n",
            "Batch: 3, Loss: 2.543093681335449, Accuracy: 0.197265625\n",
            "Batch: 4, Loss: 2.4193990230560303, Accuracy: 0.208984375\n",
            "TEST Loss: 2.3876140117645264, Accuracy: 0.2353515625\n",
            "Batch: 6, Loss: 2.4340014457702637, Accuracy: 0.2255859375\n",
            "Batch: 7, Loss: 2.2625303268432617, Accuracy: 0.2265625\n",
            "Batch: 8, Loss: 2.4332008361816406, Accuracy: 0.1904296875\n",
            "Batch: 9, Loss: 2.4529075622558594, Accuracy: 0.1953125\n",
            "TEST Loss: 2.400683641433716, Accuracy: 0.2392578125\n",
            "Batch: 11, Loss: 2.5028281211853027, Accuracy: 0.205078125\n",
            "Batch: 12, Loss: 2.4548943042755127, Accuracy: 0.189453125\n",
            "Batch: 13, Loss: 2.40508770942688, Accuracy: 0.2119140625\n",
            "Batch: 14, Loss: 2.4065632820129395, Accuracy: 0.2080078125\n",
            "TEST Loss: 2.4307451248168945, Accuracy: 0.2041015625\n",
            "Batch: 16, Loss: 2.4629411697387695, Accuracy: 0.2236328125\n",
            "Batch: 17, Loss: 2.4886016845703125, Accuracy: 0.1923828125\n",
            "Batch: 18, Loss: 2.489597797393799, Accuracy: 0.205078125\n",
            "Batch: 19, Loss: 2.4725189208984375, Accuracy: 0.220703125\n",
            "TEST Loss: 2.43082857131958, Accuracy: 0.20703125\n",
            "Batch: 21, Loss: 2.304537296295166, Accuracy: 0.25390625\n",
            "Batch: 22, Loss: 2.3562793731689453, Accuracy: 0.224609375\n",
            "Batch: 23, Loss: 2.513388156890869, Accuracy: 0.2099609375\n",
            "Batch: 24, Loss: 2.4660658836364746, Accuracy: 0.1953125\n",
            "TEST Loss: 2.471863269805908, Accuracy: 0.20703125\n",
            "Batch: 26, Loss: 2.558624505996704, Accuracy: 0.2255859375\n",
            "Batch: 27, Loss: 2.3943514823913574, Accuracy: 0.232421875\n",
            "Batch: 28, Loss: 2.406060218811035, Accuracy: 0.2060546875\n",
            "Batch: 29, Loss: 2.52905011177063, Accuracy: 0.1982421875\n",
            "TEST Loss: 2.4381961822509766, Accuracy: 0.1953125\n",
            "Batch: 31, Loss: 2.5921900272369385, Accuracy: 0.189453125\n",
            "Batch: 32, Loss: 2.5007100105285645, Accuracy: 0.224609375\n",
            "Batch: 33, Loss: 2.3596062660217285, Accuracy: 0.2412109375\n",
            "Batch: 34, Loss: 2.4840598106384277, Accuracy: 0.208984375\n",
            "TEST Loss: 2.3198490142822266, Accuracy: 0.263671875\n",
            "Batch: 36, Loss: 2.3469395637512207, Accuracy: 0.244140625\n",
            "Batch: 37, Loss: 2.426490068435669, Accuracy: 0.21875\n",
            "Epoch 7/100\n",
            "Batch: 1, Loss: 2.5306100845336914, Accuracy: 0.1923828125\n",
            "Batch: 2, Loss: 2.4057223796844482, Accuracy: 0.236328125\n",
            "Batch: 3, Loss: 2.4818263053894043, Accuracy: 0.224609375\n",
            "Batch: 4, Loss: 2.390007257461548, Accuracy: 0.2236328125\n",
            "TEST Loss: 2.3518776893615723, Accuracy: 0.2392578125\n",
            "Batch: 6, Loss: 2.389800786972046, Accuracy: 0.2373046875\n",
            "Batch: 7, Loss: 2.199366569519043, Accuracy: 0.271484375\n",
            "Batch: 8, Loss: 2.3979854583740234, Accuracy: 0.2177734375\n",
            "Batch: 9, Loss: 2.407972812652588, Accuracy: 0.2001953125\n",
            "TEST Loss: 2.3189918994903564, Accuracy: 0.30078125\n",
            "Batch: 11, Loss: 2.4493184089660645, Accuracy: 0.212890625\n",
            "Batch: 12, Loss: 2.3961668014526367, Accuracy: 0.21484375\n",
            "Batch: 13, Loss: 2.3529696464538574, Accuracy: 0.2255859375\n",
            "Batch: 14, Loss: 2.3326950073242188, Accuracy: 0.2236328125\n",
            "TEST Loss: 2.3740906715393066, Accuracy: 0.2294921875\n",
            "Batch: 16, Loss: 2.4008820056915283, Accuracy: 0.2451171875\n",
            "Batch: 17, Loss: 2.44315242767334, Accuracy: 0.2197265625\n",
            "Batch: 18, Loss: 2.4860308170318604, Accuracy: 0.208984375\n",
            "Batch: 19, Loss: 2.4284892082214355, Accuracy: 0.224609375\n",
            "TEST Loss: 2.4011826515197754, Accuracy: 0.2158203125\n",
            "Batch: 21, Loss: 2.254338502883911, Accuracy: 0.2666015625\n",
            "Batch: 22, Loss: 2.2975077629089355, Accuracy: 0.251953125\n",
            "Batch: 23, Loss: 2.475043773651123, Accuracy: 0.2197265625\n",
            "Batch: 24, Loss: 2.4457569122314453, Accuracy: 0.2255859375\n",
            "TEST Loss: 2.438992977142334, Accuracy: 0.22265625\n",
            "Batch: 26, Loss: 2.5144078731536865, Accuracy: 0.23828125\n",
            "Batch: 27, Loss: 2.3384668827056885, Accuracy: 0.263671875\n",
            "Batch: 28, Loss: 2.339204788208008, Accuracy: 0.25\n",
            "Batch: 29, Loss: 2.48004150390625, Accuracy: 0.20703125\n",
            "TEST Loss: 2.388917922973633, Accuracy: 0.2314453125\n",
            "Batch: 31, Loss: 2.5260045528411865, Accuracy: 0.2001953125\n",
            "Batch: 32, Loss: 2.462736129760742, Accuracy: 0.2392578125\n",
            "Batch: 33, Loss: 2.304436445236206, Accuracy: 0.265625\n",
            "Batch: 34, Loss: 2.4654531478881836, Accuracy: 0.251953125\n",
            "TEST Loss: 2.240149974822998, Accuracy: 0.2998046875\n",
            "Batch: 36, Loss: 2.2879223823547363, Accuracy: 0.263671875\n",
            "Batch: 37, Loss: 2.386201858520508, Accuracy: 0.2529296875\n",
            "Epoch 8/100\n",
            "Batch: 1, Loss: 2.463397979736328, Accuracy: 0.2236328125\n",
            "Batch: 2, Loss: 2.372248649597168, Accuracy: 0.2607421875\n",
            "Batch: 3, Loss: 2.435746192932129, Accuracy: 0.248046875\n",
            "Batch: 4, Loss: 2.386256456375122, Accuracy: 0.240234375\n",
            "TEST Loss: 2.312359571456909, Accuracy: 0.2587890625\n",
            "Batch: 6, Loss: 2.3404128551483154, Accuracy: 0.255859375\n",
            "Batch: 7, Loss: 2.1649107933044434, Accuracy: 0.3037109375\n",
            "Batch: 8, Loss: 2.378605604171753, Accuracy: 0.2431640625\n",
            "Batch: 9, Loss: 2.3708930015563965, Accuracy: 0.236328125\n",
            "TEST Loss: 2.264937400817871, Accuracy: 0.2998046875\n",
            "Batch: 11, Loss: 2.4022841453552246, Accuracy: 0.22265625\n",
            "Batch: 12, Loss: 2.335709810256958, Accuracy: 0.2333984375\n",
            "Batch: 13, Loss: 2.2699356079101562, Accuracy: 0.265625\n",
            "Batch: 14, Loss: 2.2825703620910645, Accuracy: 0.271484375\n",
            "TEST Loss: 2.3149020671844482, Accuracy: 0.2578125\n",
            "Batch: 16, Loss: 2.3653955459594727, Accuracy: 0.248046875\n",
            "Batch: 17, Loss: 2.3931193351745605, Accuracy: 0.2314453125\n",
            "Batch: 18, Loss: 2.4398019313812256, Accuracy: 0.2099609375\n",
            "Batch: 19, Loss: 2.3573379516601562, Accuracy: 0.248046875\n",
            "TEST Loss: 2.360055923461914, Accuracy: 0.23828125\n",
            "Batch: 21, Loss: 2.1715235710144043, Accuracy: 0.3046875\n",
            "Batch: 22, Loss: 2.2225630283355713, Accuracy: 0.28515625\n",
            "Batch: 23, Loss: 2.4463000297546387, Accuracy: 0.2509765625\n",
            "Batch: 24, Loss: 2.38950777053833, Accuracy: 0.244140625\n",
            "TEST Loss: 2.3809144496917725, Accuracy: 0.2578125\n",
            "Batch: 26, Loss: 2.447706699371338, Accuracy: 0.251953125\n",
            "Batch: 27, Loss: 2.2468912601470947, Accuracy: 0.2783203125\n",
            "Batch: 28, Loss: 2.2806155681610107, Accuracy: 0.2705078125\n",
            "Batch: 29, Loss: 2.417914628982544, Accuracy: 0.2353515625\n",
            "TEST Loss: 2.332152843475342, Accuracy: 0.263671875\n",
            "Batch: 31, Loss: 2.467902421951294, Accuracy: 0.22265625\n",
            "Batch: 32, Loss: 2.404249429702759, Accuracy: 0.259765625\n",
            "Batch: 33, Loss: 2.214585304260254, Accuracy: 0.2939453125\n",
            "Batch: 34, Loss: 2.393711566925049, Accuracy: 0.2763671875\n",
            "TEST Loss: 2.173743963241577, Accuracy: 0.318359375\n",
            "Batch: 36, Loss: 2.236354351043701, Accuracy: 0.2783203125\n",
            "Batch: 37, Loss: 2.319039821624756, Accuracy: 0.2666015625\n",
            "Epoch 9/100\n",
            "Batch: 1, Loss: 2.4269633293151855, Accuracy: 0.2294921875\n",
            "Batch: 2, Loss: 2.2834112644195557, Accuracy: 0.2783203125\n",
            "Batch: 3, Loss: 2.380185127258301, Accuracy: 0.2490234375\n",
            "Batch: 4, Loss: 2.324706554412842, Accuracy: 0.2568359375\n",
            "TEST Loss: 2.263916015625, Accuracy: 0.2744140625\n",
            "Batch: 6, Loss: 2.2748866081237793, Accuracy: 0.275390625\n",
            "Batch: 7, Loss: 2.112382411956787, Accuracy: 0.3076171875\n",
            "Batch: 8, Loss: 2.3146121501922607, Accuracy: 0.2353515625\n",
            "Batch: 9, Loss: 2.307708740234375, Accuracy: 0.263671875\n",
            "TEST Loss: 2.1655497550964355, Accuracy: 0.3427734375\n",
            "Batch: 11, Loss: 2.325212001800537, Accuracy: 0.263671875\n",
            "Batch: 12, Loss: 2.257906198501587, Accuracy: 0.265625\n",
            "Batch: 13, Loss: 2.2136616706848145, Accuracy: 0.2744140625\n",
            "Batch: 14, Loss: 2.2315337657928467, Accuracy: 0.29296875\n",
            "TEST Loss: 2.2410168647766113, Accuracy: 0.27734375\n",
            "Batch: 16, Loss: 2.3227343559265137, Accuracy: 0.2685546875\n",
            "Batch: 17, Loss: 2.345433473587036, Accuracy: 0.248046875\n",
            "Batch: 18, Loss: 2.3818514347076416, Accuracy: 0.24609375\n",
            "Batch: 19, Loss: 2.2974114418029785, Accuracy: 0.265625\n",
            "TEST Loss: 2.318692922592163, Accuracy: 0.2529296875\n",
            "Batch: 21, Loss: 2.11226749420166, Accuracy: 0.3408203125\n",
            "Batch: 22, Loss: 2.1738414764404297, Accuracy: 0.3017578125\n",
            "Batch: 23, Loss: 2.395181179046631, Accuracy: 0.2626953125\n",
            "Batch: 24, Loss: 2.3340301513671875, Accuracy: 0.2578125\n",
            "TEST Loss: 2.3449161052703857, Accuracy: 0.2578125\n",
            "Batch: 26, Loss: 2.359147548675537, Accuracy: 0.259765625\n",
            "Batch: 27, Loss: 2.191575288772583, Accuracy: 0.3056640625\n",
            "Batch: 28, Loss: 2.187955856323242, Accuracy: 0.296875\n",
            "Batch: 29, Loss: 2.35123872756958, Accuracy: 0.255859375\n",
            "TEST Loss: 2.283973455429077, Accuracy: 0.283203125\n",
            "Batch: 31, Loss: 2.4158802032470703, Accuracy: 0.24609375\n",
            "Batch: 32, Loss: 2.334367275238037, Accuracy: 0.27734375\n",
            "Batch: 33, Loss: 2.1658382415771484, Accuracy: 0.3212890625\n",
            "Batch: 34, Loss: 2.339501142501831, Accuracy: 0.2880859375\n",
            "TEST Loss: 2.128150463104248, Accuracy: 0.3134765625\n",
            "Batch: 36, Loss: 2.1561689376831055, Accuracy: 0.291015625\n",
            "Batch: 37, Loss: 2.258073329925537, Accuracy: 0.2763671875\n",
            "Epoch 10/100\n",
            "Batch: 1, Loss: 2.3608953952789307, Accuracy: 0.2470703125\n",
            "Batch: 2, Loss: 2.238553047180176, Accuracy: 0.2998046875\n",
            "Batch: 3, Loss: 2.3309381008148193, Accuracy: 0.2626953125\n",
            "Batch: 4, Loss: 2.28505802154541, Accuracy: 0.2578125\n",
            "TEST Loss: 2.2191474437713623, Accuracy: 0.291015625\n",
            "Batch: 6, Loss: 2.2218687534332275, Accuracy: 0.2900390625\n",
            "Batch: 7, Loss: 2.0471811294555664, Accuracy: 0.3291015625\n",
            "Batch: 8, Loss: 2.265533447265625, Accuracy: 0.2646484375\n",
            "Batch: 9, Loss: 2.263153553009033, Accuracy: 0.29296875\n",
            "TEST Loss: 2.1342263221740723, Accuracy: 0.3486328125\n",
            "Batch: 11, Loss: 2.278702735900879, Accuracy: 0.2666015625\n",
            "Batch: 12, Loss: 2.200361728668213, Accuracy: 0.2626953125\n",
            "Batch: 13, Loss: 2.153809070587158, Accuracy: 0.291015625\n",
            "Batch: 14, Loss: 2.150273323059082, Accuracy: 0.328125\n",
            "TEST Loss: 2.1963515281677246, Accuracy: 0.3076171875\n",
            "Batch: 16, Loss: 2.292295217514038, Accuracy: 0.2880859375\n",
            "Batch: 17, Loss: 2.299734592437744, Accuracy: 0.259765625\n",
            "Batch: 18, Loss: 2.321188449859619, Accuracy: 0.2734375\n",
            "Batch: 19, Loss: 2.218830108642578, Accuracy: 0.2939453125\n",
            "TEST Loss: 2.2569775581359863, Accuracy: 0.287109375\n",
            "Batch: 21, Loss: 2.0328288078308105, Accuracy: 0.3486328125\n",
            "Batch: 22, Loss: 2.1240251064300537, Accuracy: 0.3046875\n",
            "Batch: 23, Loss: 2.328129768371582, Accuracy: 0.2822265625\n",
            "Batch: 24, Loss: 2.291579246520996, Accuracy: 0.2744140625\n",
            "TEST Loss: 2.283968448638916, Accuracy: 0.2724609375\n",
            "Batch: 26, Loss: 2.297520637512207, Accuracy: 0.267578125\n",
            "Batch: 27, Loss: 2.123157501220703, Accuracy: 0.3193359375\n",
            "Batch: 28, Loss: 2.1328954696655273, Accuracy: 0.3046875\n",
            "Batch: 29, Loss: 2.313741683959961, Accuracy: 0.267578125\n",
            "TEST Loss: 2.2453174591064453, Accuracy: 0.2880859375\n",
            "Batch: 31, Loss: 2.3692660331726074, Accuracy: 0.25390625\n",
            "Batch: 32, Loss: 2.2656683921813965, Accuracy: 0.296875\n",
            "Batch: 33, Loss: 2.114010810852051, Accuracy: 0.3271484375\n",
            "Batch: 34, Loss: 2.2660951614379883, Accuracy: 0.31640625\n",
            "TEST Loss: 2.0798702239990234, Accuracy: 0.3369140625\n",
            "Batch: 36, Loss: 2.111133575439453, Accuracy: 0.3154296875\n",
            "Batch: 37, Loss: 2.184329032897949, Accuracy: 0.287109375\n",
            "Saved Weights at epoch 10 to file Weights_mozart.h5\n",
            "Epoch 11/100\n",
            "Batch: 1, Loss: 2.3130722045898438, Accuracy: 0.2607421875\n",
            "Batch: 2, Loss: 2.15824818611145, Accuracy: 0.30859375\n",
            "Batch: 3, Loss: 2.272428512573242, Accuracy: 0.279296875\n",
            "Batch: 4, Loss: 2.205958843231201, Accuracy: 0.2998046875\n",
            "TEST Loss: 2.157843828201294, Accuracy: 0.30859375\n",
            "Batch: 6, Loss: 2.1748976707458496, Accuracy: 0.306640625\n",
            "Batch: 7, Loss: 1.978835105895996, Accuracy: 0.3603515625\n",
            "Batch: 8, Loss: 2.2411842346191406, Accuracy: 0.2724609375\n",
            "Batch: 9, Loss: 2.246915817260742, Accuracy: 0.2861328125\n",
            "TEST Loss: 2.0760245323181152, Accuracy: 0.373046875\n",
            "Batch: 11, Loss: 2.2077980041503906, Accuracy: 0.275390625\n",
            "Batch: 12, Loss: 2.1566989421844482, Accuracy: 0.2998046875\n",
            "Batch: 13, Loss: 2.092947483062744, Accuracy: 0.3291015625\n",
            "Batch: 14, Loss: 2.0919833183288574, Accuracy: 0.3388671875\n",
            "TEST Loss: 2.1496803760528564, Accuracy: 0.330078125\n",
            "Batch: 16, Loss: 2.249021530151367, Accuracy: 0.2900390625\n",
            "Batch: 17, Loss: 2.248912811279297, Accuracy: 0.28515625\n",
            "Batch: 18, Loss: 2.276115894317627, Accuracy: 0.2939453125\n",
            "Batch: 19, Loss: 2.1690480709075928, Accuracy: 0.3046875\n",
            "TEST Loss: 2.219512462615967, Accuracy: 0.296875\n",
            "Batch: 21, Loss: 1.9932910203933716, Accuracy: 0.3828125\n",
            "Batch: 22, Loss: 2.0651683807373047, Accuracy: 0.3408203125\n",
            "Batch: 23, Loss: 2.2619080543518066, Accuracy: 0.28515625\n",
            "Batch: 24, Loss: 2.2302305698394775, Accuracy: 0.2880859375\n",
            "TEST Loss: 2.241520881652832, Accuracy: 0.294921875\n",
            "Batch: 26, Loss: 2.2108192443847656, Accuracy: 0.3046875\n",
            "Batch: 27, Loss: 2.0735816955566406, Accuracy: 0.333984375\n",
            "Batch: 28, Loss: 2.091808319091797, Accuracy: 0.33203125\n",
            "Batch: 29, Loss: 2.231459140777588, Accuracy: 0.2900390625\n",
            "TEST Loss: 2.198519468307495, Accuracy: 0.3193359375\n",
            "Batch: 31, Loss: 2.313931941986084, Accuracy: 0.28515625\n",
            "Batch: 32, Loss: 2.191218614578247, Accuracy: 0.33203125\n",
            "Batch: 33, Loss: 2.0642995834350586, Accuracy: 0.3330078125\n",
            "Batch: 34, Loss: 2.207944393157959, Accuracy: 0.3330078125\n",
            "TEST Loss: 2.033046245574951, Accuracy: 0.34765625\n",
            "Batch: 36, Loss: 2.0689451694488525, Accuracy: 0.3291015625\n",
            "Batch: 37, Loss: 2.1161999702453613, Accuracy: 0.333984375\n",
            "Epoch 12/100\n",
            "Batch: 1, Loss: 2.2642922401428223, Accuracy: 0.2919921875\n",
            "Batch: 2, Loss: 2.139120101928711, Accuracy: 0.3095703125\n",
            "Batch: 3, Loss: 2.252100944519043, Accuracy: 0.3046875\n",
            "Batch: 4, Loss: 2.177828788757324, Accuracy: 0.302734375\n",
            "TEST Loss: 2.126591682434082, Accuracy: 0.310546875\n",
            "Batch: 6, Loss: 2.1089119911193848, Accuracy: 0.322265625\n",
            "Batch: 7, Loss: 1.9640467166900635, Accuracy: 0.3505859375\n",
            "Batch: 8, Loss: 2.20915150642395, Accuracy: 0.2783203125\n",
            "Batch: 9, Loss: 2.1750309467315674, Accuracy: 0.3251953125\n",
            "TEST Loss: 2.0229334831237793, Accuracy: 0.390625\n",
            "Batch: 11, Loss: 2.1319661140441895, Accuracy: 0.34765625\n",
            "Batch: 12, Loss: 2.100867748260498, Accuracy: 0.3125\n",
            "Batch: 13, Loss: 2.018988609313965, Accuracy: 0.35546875\n",
            "Batch: 14, Loss: 2.0355260372161865, Accuracy: 0.341796875\n",
            "TEST Loss: 2.104705810546875, Accuracy: 0.3251953125\n",
            "Batch: 16, Loss: 2.2064545154571533, Accuracy: 0.2998046875\n",
            "Batch: 17, Loss: 2.185934066772461, Accuracy: 0.310546875\n",
            "Batch: 18, Loss: 2.2271957397460938, Accuracy: 0.3017578125\n",
            "Batch: 19, Loss: 2.126072645187378, Accuracy: 0.3212890625\n",
            "TEST Loss: 2.1826131343841553, Accuracy: 0.3154296875\n",
            "Batch: 21, Loss: 1.9417985677719116, Accuracy: 0.392578125\n",
            "Batch: 22, Loss: 2.0098774433135986, Accuracy: 0.376953125\n",
            "Batch: 23, Loss: 2.2172415256500244, Accuracy: 0.302734375\n",
            "Batch: 24, Loss: 2.182906150817871, Accuracy: 0.3017578125\n",
            "TEST Loss: 2.200556993484497, Accuracy: 0.306640625\n",
            "Batch: 26, Loss: 2.13142728805542, Accuracy: 0.3291015625\n",
            "Batch: 27, Loss: 2.0161681175231934, Accuracy: 0.349609375\n",
            "Batch: 28, Loss: 2.026576519012451, Accuracy: 0.34375\n",
            "Batch: 29, Loss: 2.1666016578674316, Accuracy: 0.3076171875\n",
            "TEST Loss: 2.1502599716186523, Accuracy: 0.3125\n",
            "Batch: 31, Loss: 2.2528910636901855, Accuracy: 0.294921875\n",
            "Batch: 32, Loss: 2.11423921585083, Accuracy: 0.3671875\n",
            "Batch: 33, Loss: 2.0096347332000732, Accuracy: 0.3662109375\n",
            "Batch: 34, Loss: 2.1329383850097656, Accuracy: 0.345703125\n",
            "TEST Loss: 1.9811673164367676, Accuracy: 0.3662109375\n",
            "Batch: 36, Loss: 2.0070960521698, Accuracy: 0.3447265625\n",
            "Batch: 37, Loss: 2.0642800331115723, Accuracy: 0.3271484375\n",
            "Epoch 13/100\n",
            "Batch: 1, Loss: 2.193272352218628, Accuracy: 0.3154296875\n",
            "Batch: 2, Loss: 2.074019432067871, Accuracy: 0.3359375\n",
            "Batch: 3, Loss: 2.195054769515991, Accuracy: 0.3095703125\n",
            "Batch: 4, Loss: 2.0834407806396484, Accuracy: 0.3330078125\n",
            "TEST Loss: 2.0669667720794678, Accuracy: 0.341796875\n",
            "Batch: 6, Loss: 2.0179035663604736, Accuracy: 0.341796875\n",
            "Batch: 7, Loss: 1.892837643623352, Accuracy: 0.376953125\n",
            "Batch: 8, Loss: 2.11198353767395, Accuracy: 0.3154296875\n",
            "Batch: 9, Loss: 2.105149745941162, Accuracy: 0.333984375\n",
            "TEST Loss: 1.9783568382263184, Accuracy: 0.4111328125\n",
            "Batch: 11, Loss: 2.120492696762085, Accuracy: 0.3408203125\n",
            "Batch: 12, Loss: 2.023202657699585, Accuracy: 0.3388671875\n",
            "Batch: 13, Loss: 1.9497826099395752, Accuracy: 0.375\n",
            "Batch: 14, Loss: 1.9673194885253906, Accuracy: 0.3798828125\n",
            "TEST Loss: 2.057976484298706, Accuracy: 0.345703125\n",
            "Batch: 16, Loss: 2.14332914352417, Accuracy: 0.330078125\n",
            "Batch: 17, Loss: 2.1538121700286865, Accuracy: 0.3134765625\n",
            "Batch: 18, Loss: 2.1817357540130615, Accuracy: 0.3212890625\n",
            "Batch: 19, Loss: 2.038567543029785, Accuracy: 0.3486328125\n",
            "TEST Loss: 2.1646926403045654, Accuracy: 0.314453125\n",
            "Batch: 21, Loss: 1.9063353538513184, Accuracy: 0.3818359375\n",
            "Batch: 22, Loss: 1.988133430480957, Accuracy: 0.3642578125\n",
            "Batch: 23, Loss: 2.1491775512695312, Accuracy: 0.330078125\n",
            "Batch: 24, Loss: 2.1417598724365234, Accuracy: 0.322265625\n",
            "TEST Loss: 2.1616342067718506, Accuracy: 0.333984375\n",
            "Batch: 26, Loss: 2.0769100189208984, Accuracy: 0.3544921875\n",
            "Batch: 27, Loss: 1.986533284187317, Accuracy: 0.3564453125\n",
            "Batch: 28, Loss: 1.9921241998672485, Accuracy: 0.36328125\n",
            "Batch: 29, Loss: 2.1038031578063965, Accuracy: 0.35546875\n",
            "TEST Loss: 2.1026062965393066, Accuracy: 0.3388671875\n",
            "Batch: 31, Loss: 2.192786931991577, Accuracy: 0.328125\n",
            "Batch: 32, Loss: 2.047504425048828, Accuracy: 0.3701171875\n",
            "Batch: 33, Loss: 1.947987675666809, Accuracy: 0.3916015625\n",
            "Batch: 34, Loss: 2.066885471343994, Accuracy: 0.365234375\n",
            "TEST Loss: 1.9429601430892944, Accuracy: 0.380859375\n",
            "Batch: 36, Loss: 1.9525480270385742, Accuracy: 0.3681640625\n",
            "Batch: 37, Loss: 1.9984750747680664, Accuracy: 0.3798828125\n",
            "Epoch 14/100\n",
            "Batch: 1, Loss: 2.1330957412719727, Accuracy: 0.33203125\n",
            "Batch: 2, Loss: 2.0185258388519287, Accuracy: 0.361328125\n",
            "Batch: 3, Loss: 2.1406846046447754, Accuracy: 0.345703125\n",
            "Batch: 4, Loss: 2.0518555641174316, Accuracy: 0.3486328125\n",
            "TEST Loss: 2.008899688720703, Accuracy: 0.3642578125\n",
            "Batch: 6, Loss: 2.0125718116760254, Accuracy: 0.33203125\n",
            "Batch: 7, Loss: 1.879607915878296, Accuracy: 0.373046875\n",
            "Batch: 8, Loss: 2.0620875358581543, Accuracy: 0.3310546875\n",
            "Batch: 9, Loss: 2.0656819343566895, Accuracy: 0.3505859375\n",
            "TEST Loss: 1.9273308515548706, Accuracy: 0.4169921875\n",
            "Batch: 11, Loss: 2.056194305419922, Accuracy: 0.361328125\n",
            "Batch: 12, Loss: 1.9483001232147217, Accuracy: 0.359375\n",
            "Batch: 13, Loss: 1.8945611715316772, Accuracy: 0.388671875\n",
            "Batch: 14, Loss: 1.8974719047546387, Accuracy: 0.400390625\n",
            "TEST Loss: 2.017758846282959, Accuracy: 0.3642578125\n",
            "Batch: 16, Loss: 2.097259521484375, Accuracy: 0.34375\n",
            "Batch: 17, Loss: 2.0990943908691406, Accuracy: 0.3359375\n",
            "Batch: 18, Loss: 2.092304229736328, Accuracy: 0.3447265625\n",
            "Batch: 19, Loss: 1.988773226737976, Accuracy: 0.3779296875\n",
            "TEST Loss: 2.116422653198242, Accuracy: 0.3359375\n",
            "Batch: 21, Loss: 1.8412587642669678, Accuracy: 0.4326171875\n",
            "Batch: 22, Loss: 1.9058856964111328, Accuracy: 0.3779296875\n",
            "Batch: 23, Loss: 2.0747926235198975, Accuracy: 0.361328125\n",
            "Batch: 24, Loss: 2.0554635524749756, Accuracy: 0.3564453125\n",
            "TEST Loss: 2.1130475997924805, Accuracy: 0.3427734375\n",
            "Batch: 26, Loss: 1.9752460718154907, Accuracy: 0.3818359375\n",
            "Batch: 27, Loss: 1.8792126178741455, Accuracy: 0.4111328125\n",
            "Batch: 28, Loss: 1.9139467477798462, Accuracy: 0.3828125\n",
            "Batch: 29, Loss: 2.0460782051086426, Accuracy: 0.34765625\n",
            "TEST Loss: 2.051269054412842, Accuracy: 0.33984375\n",
            "Batch: 31, Loss: 2.1149404048919678, Accuracy: 0.361328125\n",
            "Batch: 32, Loss: 1.9676647186279297, Accuracy: 0.4052734375\n",
            "Batch: 33, Loss: 1.921761393547058, Accuracy: 0.392578125\n",
            "Batch: 34, Loss: 2.002558469772339, Accuracy: 0.3916015625\n",
            "TEST Loss: 1.883060336112976, Accuracy: 0.400390625\n",
            "Batch: 36, Loss: 1.8664668798446655, Accuracy: 0.396484375\n",
            "Batch: 37, Loss: 1.95693039894104, Accuracy: 0.375\n",
            "Epoch 15/100\n",
            "Batch: 1, Loss: 2.0557613372802734, Accuracy: 0.3662109375\n",
            "Batch: 2, Loss: 1.9141409397125244, Accuracy: 0.39453125\n",
            "Batch: 3, Loss: 2.081134796142578, Accuracy: 0.35546875\n",
            "Batch: 4, Loss: 1.9909696578979492, Accuracy: 0.37109375\n",
            "TEST Loss: 1.9790074825286865, Accuracy: 0.37109375\n",
            "Batch: 6, Loss: 1.9404637813568115, Accuracy: 0.37109375\n",
            "Batch: 7, Loss: 1.7995367050170898, Accuracy: 0.412109375\n",
            "Batch: 8, Loss: 1.9955118894577026, Accuracy: 0.3486328125\n",
            "Batch: 9, Loss: 1.9961930513381958, Accuracy: 0.376953125\n",
            "TEST Loss: 1.878988265991211, Accuracy: 0.431640625\n",
            "Batch: 11, Loss: 1.966951847076416, Accuracy: 0.3798828125\n",
            "Batch: 12, Loss: 1.8959672451019287, Accuracy: 0.376953125\n",
            "Batch: 13, Loss: 1.781870722770691, Accuracy: 0.421875\n",
            "Batch: 14, Loss: 1.8370704650878906, Accuracy: 0.4150390625\n",
            "TEST Loss: 1.9655401706695557, Accuracy: 0.3818359375\n",
            "Batch: 16, Loss: 2.036086082458496, Accuracy: 0.3681640625\n",
            "Batch: 17, Loss: 2.0409772396087646, Accuracy: 0.353515625\n",
            "Batch: 18, Loss: 2.0856456756591797, Accuracy: 0.3486328125\n",
            "Batch: 19, Loss: 1.9155833721160889, Accuracy: 0.400390625\n",
            "TEST Loss: 2.1063265800476074, Accuracy: 0.337890625\n",
            "Batch: 21, Loss: 1.7508089542388916, Accuracy: 0.4462890625\n",
            "Batch: 22, Loss: 1.8669650554656982, Accuracy: 0.4169921875\n",
            "Batch: 23, Loss: 2.031921863555908, Accuracy: 0.3623046875\n",
            "Batch: 24, Loss: 2.0096659660339355, Accuracy: 0.365234375\n",
            "TEST Loss: 2.066526174545288, Accuracy: 0.3623046875\n",
            "Batch: 26, Loss: 1.9021888971328735, Accuracy: 0.4072265625\n",
            "Batch: 27, Loss: 1.8227357864379883, Accuracy: 0.423828125\n",
            "Batch: 28, Loss: 1.8594785928726196, Accuracy: 0.412109375\n",
            "Batch: 29, Loss: 1.976118803024292, Accuracy: 0.3779296875\n",
            "TEST Loss: 2.0202927589416504, Accuracy: 0.357421875\n",
            "Batch: 31, Loss: 2.0588767528533936, Accuracy: 0.353515625\n",
            "Batch: 32, Loss: 1.9237523078918457, Accuracy: 0.423828125\n",
            "Batch: 33, Loss: 1.8442034721374512, Accuracy: 0.4150390625\n",
            "Batch: 34, Loss: 1.9505670070648193, Accuracy: 0.4052734375\n",
            "TEST Loss: 1.8199994564056396, Accuracy: 0.4248046875\n",
            "Batch: 36, Loss: 1.8314509391784668, Accuracy: 0.400390625\n",
            "Batch: 37, Loss: 1.8683350086212158, Accuracy: 0.40234375\n",
            "Epoch 16/100\n",
            "Batch: 1, Loss: 2.012753486633301, Accuracy: 0.3720703125\n",
            "Batch: 2, Loss: 1.8892316818237305, Accuracy: 0.4111328125\n",
            "Batch: 3, Loss: 2.0203115940093994, Accuracy: 0.36328125\n",
            "Batch: 4, Loss: 1.905529260635376, Accuracy: 0.376953125\n",
            "TEST Loss: 1.921005368232727, Accuracy: 0.400390625\n",
            "Batch: 6, Loss: 1.8756091594696045, Accuracy: 0.3955078125\n",
            "Batch: 7, Loss: 1.7556196451187134, Accuracy: 0.408203125\n",
            "Batch: 8, Loss: 1.934314250946045, Accuracy: 0.3828125\n",
            "Batch: 9, Loss: 1.9697322845458984, Accuracy: 0.384765625\n",
            "TEST Loss: 1.810389518737793, Accuracy: 0.4482421875\n",
            "Batch: 11, Loss: 1.9271633625030518, Accuracy: 0.388671875\n",
            "Batch: 12, Loss: 1.8184469938278198, Accuracy: 0.419921875\n",
            "Batch: 13, Loss: 1.7475749254226685, Accuracy: 0.44921875\n",
            "Batch: 14, Loss: 1.794187068939209, Accuracy: 0.4443359375\n",
            "TEST Loss: 1.9087646007537842, Accuracy: 0.4013671875\n",
            "Batch: 16, Loss: 1.950897455215454, Accuracy: 0.38671875\n",
            "Batch: 17, Loss: 1.9691240787506104, Accuracy: 0.380859375\n",
            "Batch: 18, Loss: 1.9872827529907227, Accuracy: 0.3896484375\n",
            "Batch: 19, Loss: 1.8710297346115112, Accuracy: 0.4052734375\n",
            "TEST Loss: 2.0544509887695312, Accuracy: 0.3486328125\n",
            "Batch: 21, Loss: 1.7001769542694092, Accuracy: 0.466796875\n",
            "Batch: 22, Loss: 1.8136203289031982, Accuracy: 0.4228515625\n",
            "Batch: 23, Loss: 1.9338951110839844, Accuracy: 0.3984375\n",
            "Batch: 24, Loss: 1.9546480178833008, Accuracy: 0.380859375\n",
            "TEST Loss: 2.0305514335632324, Accuracy: 0.3740234375\n",
            "Batch: 26, Loss: 1.8262356519699097, Accuracy: 0.4306640625\n",
            "Batch: 27, Loss: 1.72853422164917, Accuracy: 0.46875\n",
            "Batch: 28, Loss: 1.82572603225708, Accuracy: 0.4140625\n",
            "Batch: 29, Loss: 1.8993902206420898, Accuracy: 0.3876953125\n",
            "TEST Loss: 1.9793641567230225, Accuracy: 0.375\n",
            "Batch: 31, Loss: 1.9702337980270386, Accuracy: 0.3759765625\n",
            "Batch: 32, Loss: 1.8743870258331299, Accuracy: 0.4306640625\n",
            "Batch: 33, Loss: 1.7780367136001587, Accuracy: 0.435546875\n",
            "Batch: 34, Loss: 1.8633999824523926, Accuracy: 0.4130859375\n",
            "TEST Loss: 1.7874479293823242, Accuracy: 0.4296875\n",
            "Batch: 36, Loss: 1.7477812767028809, Accuracy: 0.4306640625\n",
            "Batch: 37, Loss: 1.8212066888809204, Accuracy: 0.41015625\n",
            "Epoch 17/100\n",
            "Batch: 1, Loss: 1.9499900341033936, Accuracy: 0.392578125\n",
            "Batch: 2, Loss: 1.786340594291687, Accuracy: 0.4443359375\n",
            "Batch: 3, Loss: 1.9428092241287231, Accuracy: 0.4052734375\n",
            "Batch: 4, Loss: 1.8419537544250488, Accuracy: 0.400390625\n",
            "TEST Loss: 1.8879988193511963, Accuracy: 0.416015625\n",
            "Batch: 6, Loss: 1.8252583742141724, Accuracy: 0.4248046875\n",
            "Batch: 7, Loss: 1.7006953954696655, Accuracy: 0.447265625\n",
            "Batch: 8, Loss: 1.8614438772201538, Accuracy: 0.3984375\n",
            "Batch: 9, Loss: 1.866072654724121, Accuracy: 0.423828125\n",
            "TEST Loss: 1.7868291139602661, Accuracy: 0.4677734375\n",
            "Batch: 11, Loss: 1.8281795978546143, Accuracy: 0.416015625\n",
            "Batch: 12, Loss: 1.7569668292999268, Accuracy: 0.431640625\n",
            "Batch: 13, Loss: 1.7021124362945557, Accuracy: 0.4482421875\n",
            "Batch: 14, Loss: 1.692997932434082, Accuracy: 0.4736328125\n",
            "TEST Loss: 1.8612957000732422, Accuracy: 0.42578125\n",
            "Batch: 16, Loss: 1.9057762622833252, Accuracy: 0.3837890625\n",
            "Batch: 17, Loss: 1.9310355186462402, Accuracy: 0.3759765625\n",
            "Batch: 18, Loss: 1.9334425926208496, Accuracy: 0.400390625\n",
            "Batch: 19, Loss: 1.8100957870483398, Accuracy: 0.4306640625\n",
            "TEST Loss: 2.0222599506378174, Accuracy: 0.361328125\n",
            "Batch: 21, Loss: 1.6343951225280762, Accuracy: 0.4853515625\n",
            "Batch: 22, Loss: 1.760321855545044, Accuracy: 0.4619140625\n",
            "Batch: 23, Loss: 1.902367353439331, Accuracy: 0.4169921875\n",
            "Batch: 24, Loss: 1.8728747367858887, Accuracy: 0.4150390625\n",
            "TEST Loss: 1.9879217147827148, Accuracy: 0.3759765625\n",
            "Batch: 26, Loss: 1.7559175491333008, Accuracy: 0.4384765625\n",
            "Batch: 27, Loss: 1.7081936597824097, Accuracy: 0.46484375\n",
            "Batch: 28, Loss: 1.7263213396072388, Accuracy: 0.4365234375\n",
            "Batch: 29, Loss: 1.8221591711044312, Accuracy: 0.4189453125\n",
            "TEST Loss: 1.928044080734253, Accuracy: 0.3935546875\n",
            "Batch: 31, Loss: 1.8926379680633545, Accuracy: 0.4267578125\n",
            "Batch: 32, Loss: 1.7744596004486084, Accuracy: 0.4501953125\n",
            "Batch: 33, Loss: 1.7231683731079102, Accuracy: 0.4638671875\n",
            "Batch: 34, Loss: 1.7917262315750122, Accuracy: 0.4580078125\n",
            "TEST Loss: 1.7313780784606934, Accuracy: 0.4521484375\n",
            "Batch: 36, Loss: 1.694502592086792, Accuracy: 0.4609375\n",
            "Batch: 37, Loss: 1.7504761219024658, Accuracy: 0.44140625\n",
            "Epoch 18/100\n",
            "Batch: 1, Loss: 1.9138882160186768, Accuracy: 0.4052734375\n",
            "Batch: 2, Loss: 1.784358263015747, Accuracy: 0.41796875\n",
            "Batch: 3, Loss: 1.90533447265625, Accuracy: 0.4130859375\n",
            "Batch: 4, Loss: 1.8182313442230225, Accuracy: 0.416015625\n",
            "TEST Loss: 1.850736141204834, Accuracy: 0.4189453125\n",
            "Batch: 6, Loss: 1.7779262065887451, Accuracy: 0.416015625\n",
            "Batch: 7, Loss: 1.6511211395263672, Accuracy: 0.4677734375\n",
            "Batch: 8, Loss: 1.7957459688186646, Accuracy: 0.4111328125\n",
            "Batch: 9, Loss: 1.7910244464874268, Accuracy: 0.4443359375\n",
            "TEST Loss: 1.7328993082046509, Accuracy: 0.470703125\n",
            "Batch: 11, Loss: 1.7715598344802856, Accuracy: 0.453125\n",
            "Batch: 12, Loss: 1.7094695568084717, Accuracy: 0.451171875\n",
            "Batch: 13, Loss: 1.6136122941970825, Accuracy: 0.4794921875\n",
            "Batch: 14, Loss: 1.6324522495269775, Accuracy: 0.482421875\n",
            "TEST Loss: 1.842041015625, Accuracy: 0.423828125\n",
            "Batch: 16, Loss: 1.8282361030578613, Accuracy: 0.41796875\n",
            "Batch: 17, Loss: 1.8706550598144531, Accuracy: 0.40625\n",
            "Batch: 18, Loss: 1.8612912893295288, Accuracy: 0.4228515625\n",
            "Batch: 19, Loss: 1.7306864261627197, Accuracy: 0.4423828125\n",
            "TEST Loss: 1.9963898658752441, Accuracy: 0.3720703125\n",
            "Batch: 21, Loss: 1.599389910697937, Accuracy: 0.4990234375\n",
            "Batch: 22, Loss: 1.6935877799987793, Accuracy: 0.4775390625\n",
            "Batch: 23, Loss: 1.8164286613464355, Accuracy: 0.4345703125\n",
            "Batch: 24, Loss: 1.8096487522125244, Accuracy: 0.4345703125\n",
            "TEST Loss: 1.9449312686920166, Accuracy: 0.388671875\n",
            "Batch: 26, Loss: 1.669710636138916, Accuracy: 0.46875\n",
            "Batch: 27, Loss: 1.6228675842285156, Accuracy: 0.4794921875\n",
            "Batch: 28, Loss: 1.6721103191375732, Accuracy: 0.4609375\n",
            "Batch: 29, Loss: 1.7737196683883667, Accuracy: 0.43359375\n",
            "TEST Loss: 1.867573618888855, Accuracy: 0.423828125\n",
            "Batch: 31, Loss: 1.8072116374969482, Accuracy: 0.4296875\n",
            "Batch: 32, Loss: 1.687849521636963, Accuracy: 0.4765625\n",
            "Batch: 33, Loss: 1.6629984378814697, Accuracy: 0.4765625\n",
            "Batch: 34, Loss: 1.7444411516189575, Accuracy: 0.458984375\n",
            "TEST Loss: 1.694453477859497, Accuracy: 0.455078125\n",
            "Batch: 36, Loss: 1.6335541009902954, Accuracy: 0.4697265625\n",
            "Batch: 37, Loss: 1.6848725080490112, Accuracy: 0.47265625\n",
            "Epoch 19/100\n",
            "Batch: 1, Loss: 1.8148629665374756, Accuracy: 0.43359375\n",
            "Batch: 2, Loss: 1.6829005479812622, Accuracy: 0.4697265625\n",
            "Batch: 3, Loss: 1.8233327865600586, Accuracy: 0.4453125\n",
            "Batch: 4, Loss: 1.7028942108154297, Accuracy: 0.46484375\n",
            "TEST Loss: 1.778053879737854, Accuracy: 0.4521484375\n",
            "Batch: 6, Loss: 1.6953907012939453, Accuracy: 0.4443359375\n",
            "Batch: 7, Loss: 1.5804176330566406, Accuracy: 0.4765625\n",
            "Batch: 8, Loss: 1.7104374170303345, Accuracy: 0.4453125\n",
            "Batch: 9, Loss: 1.709758996963501, Accuracy: 0.4677734375\n",
            "TEST Loss: 1.7049410343170166, Accuracy: 0.4921875\n",
            "Batch: 11, Loss: 1.7202049493789673, Accuracy: 0.455078125\n",
            "Batch: 12, Loss: 1.6315370798110962, Accuracy: 0.4755859375\n",
            "Batch: 13, Loss: 1.5307674407958984, Accuracy: 0.5029296875\n",
            "Batch: 14, Loss: 1.5826702117919922, Accuracy: 0.4853515625\n",
            "TEST Loss: 1.7865674495697021, Accuracy: 0.435546875\n",
            "Batch: 16, Loss: 1.7607367038726807, Accuracy: 0.4462890625\n",
            "Batch: 17, Loss: 1.784956932067871, Accuracy: 0.439453125\n",
            "Batch: 18, Loss: 1.815725564956665, Accuracy: 0.4365234375\n",
            "Batch: 19, Loss: 1.6386172771453857, Accuracy: 0.486328125\n",
            "TEST Loss: 1.974962592124939, Accuracy: 0.3857421875\n",
            "Batch: 21, Loss: 1.51993727684021, Accuracy: 0.5068359375\n",
            "Batch: 22, Loss: 1.6155458688735962, Accuracy: 0.486328125\n",
            "Batch: 23, Loss: 1.7620093822479248, Accuracy: 0.4501953125\n",
            "Batch: 24, Loss: 1.7442749738693237, Accuracy: 0.4501953125\n",
            "TEST Loss: 1.9306020736694336, Accuracy: 0.4130859375\n",
            "Batch: 26, Loss: 1.6050429344177246, Accuracy: 0.486328125\n",
            "Batch: 27, Loss: 1.5479974746704102, Accuracy: 0.509765625\n",
            "Batch: 28, Loss: 1.6013147830963135, Accuracy: 0.4912109375\n",
            "Batch: 29, Loss: 1.6761319637298584, Accuracy: 0.466796875\n",
            "TEST Loss: 1.8166053295135498, Accuracy: 0.4384765625\n",
            "Batch: 31, Loss: 1.719639539718628, Accuracy: 0.470703125\n",
            "Batch: 32, Loss: 1.6130294799804688, Accuracy: 0.4970703125\n",
            "Batch: 33, Loss: 1.5903130769729614, Accuracy: 0.4951171875\n",
            "Batch: 34, Loss: 1.6528161764144897, Accuracy: 0.5009765625\n",
            "TEST Loss: 1.6741092205047607, Accuracy: 0.45703125\n",
            "Batch: 36, Loss: 1.5550484657287598, Accuracy: 0.5029296875\n",
            "Batch: 37, Loss: 1.6290802955627441, Accuracy: 0.48046875\n",
            "Epoch 20/100\n",
            "Batch: 1, Loss: 1.783977746963501, Accuracy: 0.4345703125\n",
            "Batch: 2, Loss: 1.6006536483764648, Accuracy: 0.4931640625\n",
            "Batch: 3, Loss: 1.7555468082427979, Accuracy: 0.4501953125\n",
            "Batch: 4, Loss: 1.6412949562072754, Accuracy: 0.4619140625\n",
            "TEST Loss: 1.7593357563018799, Accuracy: 0.4560546875\n",
            "Batch: 6, Loss: 1.6530756950378418, Accuracy: 0.47265625\n",
            "Batch: 7, Loss: 1.533719778060913, Accuracy: 0.4970703125\n",
            "Batch: 8, Loss: 1.6465929746627808, Accuracy: 0.4658203125\n",
            "Batch: 9, Loss: 1.704881191253662, Accuracy: 0.45703125\n",
            "TEST Loss: 1.6611604690551758, Accuracy: 0.517578125\n",
            "Batch: 11, Loss: 1.64863920211792, Accuracy: 0.490234375\n",
            "Batch: 12, Loss: 1.578566551208496, Accuracy: 0.4833984375\n",
            "Batch: 13, Loss: 1.4803779125213623, Accuracy: 0.525390625\n",
            "Batch: 14, Loss: 1.5067760944366455, Accuracy: 0.5322265625\n",
            "TEST Loss: 1.7540783882141113, Accuracy: 0.4638671875\n",
            "Batch: 16, Loss: 1.7023015022277832, Accuracy: 0.453125\n",
            "Batch: 17, Loss: 1.7172151803970337, Accuracy: 0.451171875\n",
            "Batch: 18, Loss: 1.7436754703521729, Accuracy: 0.4453125\n",
            "Batch: 19, Loss: 1.596691608428955, Accuracy: 0.50390625\n",
            "TEST Loss: 1.9518063068389893, Accuracy: 0.3984375\n",
            "Batch: 21, Loss: 1.4834177494049072, Accuracy: 0.529296875\n",
            "Batch: 22, Loss: 1.5932488441467285, Accuracy: 0.5009765625\n",
            "Batch: 23, Loss: 1.6862187385559082, Accuracy: 0.4736328125\n",
            "Batch: 24, Loss: 1.6597135066986084, Accuracy: 0.4755859375\n",
            "TEST Loss: 1.8470120429992676, Accuracy: 0.419921875\n",
            "Batch: 26, Loss: 1.5317533016204834, Accuracy: 0.515625\n",
            "Batch: 27, Loss: 1.5113475322723389, Accuracy: 0.537109375\n",
            "Batch: 28, Loss: 1.534785509109497, Accuracy: 0.5068359375\n",
            "Batch: 29, Loss: 1.5880334377288818, Accuracy: 0.5048828125\n",
            "TEST Loss: 1.7739973068237305, Accuracy: 0.4599609375\n",
            "Batch: 31, Loss: 1.6656520366668701, Accuracy: 0.482421875\n",
            "Batch: 32, Loss: 1.51922607421875, Accuracy: 0.5537109375\n",
            "Batch: 33, Loss: 1.5355634689331055, Accuracy: 0.5068359375\n",
            "Batch: 34, Loss: 1.6024565696716309, Accuracy: 0.5107421875\n",
            "TEST Loss: 1.552003026008606, Accuracy: 0.498046875\n",
            "Batch: 36, Loss: 1.5086989402770996, Accuracy: 0.513671875\n",
            "Batch: 37, Loss: 1.5291905403137207, Accuracy: 0.5029296875\n",
            "Saved Weights at epoch 20 to file Weights_mozart.h5\n",
            "Epoch 21/100\n",
            "Batch: 1, Loss: 1.7122704982757568, Accuracy: 0.4931640625\n",
            "Batch: 2, Loss: 1.536268949508667, Accuracy: 0.5185546875\n",
            "Batch: 3, Loss: 1.7115907669067383, Accuracy: 0.46875\n",
            "Batch: 4, Loss: 1.6159716844558716, Accuracy: 0.4775390625\n",
            "TEST Loss: 1.7282092571258545, Accuracy: 0.46875\n",
            "Batch: 6, Loss: 1.6096065044403076, Accuracy: 0.4736328125\n",
            "Batch: 7, Loss: 1.4719717502593994, Accuracy: 0.5341796875\n",
            "Batch: 8, Loss: 1.5795156955718994, Accuracy: 0.4833984375\n",
            "Batch: 9, Loss: 1.5852545499801636, Accuracy: 0.49609375\n",
            "TEST Loss: 1.6451783180236816, Accuracy: 0.51171875\n",
            "Batch: 11, Loss: 1.563758373260498, Accuracy: 0.5166015625\n",
            "Batch: 12, Loss: 1.5007340908050537, Accuracy: 0.5087890625\n",
            "Batch: 13, Loss: 1.435728907585144, Accuracy: 0.5341796875\n",
            "Batch: 14, Loss: 1.4563252925872803, Accuracy: 0.5205078125\n",
            "TEST Loss: 1.7196297645568848, Accuracy: 0.4873046875\n",
            "Batch: 16, Loss: 1.6207194328308105, Accuracy: 0.490234375\n",
            "Batch: 17, Loss: 1.6304991245269775, Accuracy: 0.4892578125\n",
            "Batch: 18, Loss: 1.6819370985031128, Accuracy: 0.4755859375\n",
            "Batch: 19, Loss: 1.548682451248169, Accuracy: 0.521484375\n",
            "TEST Loss: 1.91387140750885, Accuracy: 0.412109375\n",
            "Batch: 21, Loss: 1.4507317543029785, Accuracy: 0.533203125\n",
            "Batch: 22, Loss: 1.5326402187347412, Accuracy: 0.517578125\n",
            "Batch: 23, Loss: 1.6194376945495605, Accuracy: 0.498046875\n",
            "Batch: 24, Loss: 1.6051172018051147, Accuracy: 0.5126953125\n",
            "TEST Loss: 1.8161756992340088, Accuracy: 0.4326171875\n",
            "Batch: 26, Loss: 1.4453856945037842, Accuracy: 0.5341796875\n",
            "Batch: 27, Loss: 1.4556750059127808, Accuracy: 0.5224609375\n",
            "Batch: 28, Loss: 1.4278761148452759, Accuracy: 0.5556640625\n",
            "Batch: 29, Loss: 1.5394749641418457, Accuracy: 0.5166015625\n",
            "TEST Loss: 1.7156704664230347, Accuracy: 0.4755859375\n",
            "Batch: 31, Loss: 1.5565619468688965, Accuracy: 0.5166015625\n",
            "Batch: 32, Loss: 1.4649332761764526, Accuracy: 0.556640625\n",
            "Batch: 33, Loss: 1.421337604522705, Accuracy: 0.556640625\n",
            "Batch: 34, Loss: 1.5064889192581177, Accuracy: 0.53515625\n",
            "TEST Loss: 1.495721459388733, Accuracy: 0.5126953125\n",
            "Batch: 36, Loss: 1.4342279434204102, Accuracy: 0.533203125\n",
            "Batch: 37, Loss: 1.4744088649749756, Accuracy: 0.5361328125\n",
            "Epoch 22/100\n",
            "Batch: 1, Loss: 1.637669324874878, Accuracy: 0.4892578125\n",
            "Batch: 2, Loss: 1.4652363061904907, Accuracy: 0.5458984375\n",
            "Batch: 3, Loss: 1.608092188835144, Accuracy: 0.5263671875\n",
            "Batch: 4, Loss: 1.5063045024871826, Accuracy: 0.5078125\n",
            "TEST Loss: 1.6637380123138428, Accuracy: 0.494140625\n",
            "Batch: 6, Loss: 1.4779328107833862, Accuracy: 0.515625\n",
            "Batch: 7, Loss: 1.3960953950881958, Accuracy: 0.546875\n",
            "Batch: 8, Loss: 1.480778455734253, Accuracy: 0.5283203125\n",
            "Batch: 9, Loss: 1.5274009704589844, Accuracy: 0.5185546875\n",
            "TEST Loss: 1.578758955001831, Accuracy: 0.54296875\n",
            "Batch: 11, Loss: 1.5076031684875488, Accuracy: 0.5302734375\n",
            "Batch: 12, Loss: 1.4550917148590088, Accuracy: 0.5224609375\n",
            "Batch: 13, Loss: 1.3397834300994873, Accuracy: 0.5712890625\n",
            "Batch: 14, Loss: 1.3794275522232056, Accuracy: 0.5576171875\n",
            "TEST Loss: 1.6804699897766113, Accuracy: 0.490234375\n",
            "Batch: 16, Loss: 1.5482323169708252, Accuracy: 0.513671875\n",
            "Batch: 17, Loss: 1.6103651523590088, Accuracy: 0.513671875\n",
            "Batch: 18, Loss: 1.606007695198059, Accuracy: 0.5029296875\n",
            "Batch: 19, Loss: 1.4383559226989746, Accuracy: 0.5498046875\n",
            "TEST Loss: 1.8586914539337158, Accuracy: 0.4267578125\n",
            "Batch: 21, Loss: 1.3401823043823242, Accuracy: 0.57421875\n",
            "Batch: 22, Loss: 1.4847567081451416, Accuracy: 0.5126953125\n",
            "Batch: 23, Loss: 1.5423524379730225, Accuracy: 0.517578125\n",
            "Batch: 24, Loss: 1.5254154205322266, Accuracy: 0.501953125\n",
            "TEST Loss: 1.7912437915802002, Accuracy: 0.4521484375\n",
            "Batch: 26, Loss: 1.3683953285217285, Accuracy: 0.5615234375\n",
            "Batch: 27, Loss: 1.3652737140655518, Accuracy: 0.5625\n",
            "Batch: 28, Loss: 1.3960853815078735, Accuracy: 0.548828125\n",
            "Batch: 29, Loss: 1.4491908550262451, Accuracy: 0.5439453125\n",
            "TEST Loss: 1.7024863958358765, Accuracy: 0.4833984375\n",
            "Batch: 31, Loss: 1.4799301624298096, Accuracy: 0.5322265625\n",
            "Batch: 32, Loss: 1.4133235216140747, Accuracy: 0.5546875\n",
            "Batch: 33, Loss: 1.3943229913711548, Accuracy: 0.55078125\n",
            "Batch: 34, Loss: 1.4582315683364868, Accuracy: 0.5498046875\n",
            "TEST Loss: 1.4438408613204956, Accuracy: 0.5556640625\n",
            "Batch: 36, Loss: 1.3633921146392822, Accuracy: 0.5615234375\n",
            "Batch: 37, Loss: 1.3829710483551025, Accuracy: 0.5732421875\n",
            "Epoch 23/100\n",
            "Batch: 1, Loss: 1.562068223953247, Accuracy: 0.5234375\n",
            "Batch: 2, Loss: 1.413564920425415, Accuracy: 0.556640625\n",
            "Batch: 3, Loss: 1.5252299308776855, Accuracy: 0.515625\n",
            "Batch: 4, Loss: 1.4323279857635498, Accuracy: 0.5322265625\n",
            "TEST Loss: 1.5952234268188477, Accuracy: 0.505859375\n",
            "Batch: 6, Loss: 1.4393014907836914, Accuracy: 0.53125\n",
            "Batch: 7, Loss: 1.2989916801452637, Accuracy: 0.5830078125\n",
            "Batch: 8, Loss: 1.3816444873809814, Accuracy: 0.5537109375\n",
            "Batch: 9, Loss: 1.4772529602050781, Accuracy: 0.54296875\n",
            "TEST Loss: 1.551353931427002, Accuracy: 0.548828125\n",
            "Batch: 11, Loss: 1.4415605068206787, Accuracy: 0.53515625\n",
            "Batch: 12, Loss: 1.3591430187225342, Accuracy: 0.54296875\n",
            "Batch: 13, Loss: 1.2674975395202637, Accuracy: 0.5966796875\n",
            "Batch: 14, Loss: 1.303091049194336, Accuracy: 0.5703125\n",
            "TEST Loss: 1.6373252868652344, Accuracy: 0.5009765625\n",
            "Batch: 16, Loss: 1.4708354473114014, Accuracy: 0.5380859375\n",
            "Batch: 17, Loss: 1.5230458974838257, Accuracy: 0.5205078125\n",
            "Batch: 18, Loss: 1.5477347373962402, Accuracy: 0.525390625\n",
            "Batch: 19, Loss: 1.3511850833892822, Accuracy: 0.5595703125\n",
            "TEST Loss: 1.8460888862609863, Accuracy: 0.4501953125\n",
            "Batch: 21, Loss: 1.2723476886749268, Accuracy: 0.595703125\n",
            "Batch: 22, Loss: 1.3990468978881836, Accuracy: 0.56640625\n",
            "Batch: 23, Loss: 1.4835883378982544, Accuracy: 0.5419921875\n",
            "Batch: 24, Loss: 1.4521803855895996, Accuracy: 0.5478515625\n",
            "TEST Loss: 1.751093864440918, Accuracy: 0.455078125\n",
            "Batch: 26, Loss: 1.310276746749878, Accuracy: 0.5634765625\n",
            "Batch: 27, Loss: 1.3251330852508545, Accuracy: 0.5810546875\n",
            "Batch: 28, Loss: 1.2955495119094849, Accuracy: 0.583984375\n",
            "Batch: 29, Loss: 1.3815605640411377, Accuracy: 0.546875\n",
            "TEST Loss: 1.6315841674804688, Accuracy: 0.501953125\n",
            "Batch: 31, Loss: 1.4102239608764648, Accuracy: 0.56640625\n",
            "Batch: 32, Loss: 1.3230419158935547, Accuracy: 0.578125\n",
            "Batch: 33, Loss: 1.2806593179702759, Accuracy: 0.58203125\n",
            "Batch: 34, Loss: 1.399390459060669, Accuracy: 0.5673828125\n",
            "TEST Loss: 1.4058525562286377, Accuracy: 0.552734375\n",
            "Batch: 36, Loss: 1.2999331951141357, Accuracy: 0.5849609375\n",
            "Batch: 37, Loss: 1.3784857988357544, Accuracy: 0.5576171875\n",
            "Epoch 24/100\n",
            "Batch: 1, Loss: 1.5364034175872803, Accuracy: 0.5380859375\n",
            "Batch: 2, Loss: 1.3588809967041016, Accuracy: 0.5771484375\n",
            "Batch: 3, Loss: 1.512933373451233, Accuracy: 0.5244140625\n",
            "Batch: 4, Loss: 1.3736804723739624, Accuracy: 0.5673828125\n",
            "TEST Loss: 1.607473611831665, Accuracy: 0.509765625\n",
            "Batch: 6, Loss: 1.3800394535064697, Accuracy: 0.548828125\n",
            "Batch: 7, Loss: 1.2730834484100342, Accuracy: 0.5908203125\n",
            "Batch: 8, Loss: 1.3858022689819336, Accuracy: 0.5615234375\n",
            "Batch: 9, Loss: 1.412376880645752, Accuracy: 0.5634765625\n",
            "TEST Loss: 1.526045322418213, Accuracy: 0.5654296875\n",
            "Batch: 11, Loss: 1.3741986751556396, Accuracy: 0.5625\n",
            "Batch: 12, Loss: 1.3164012432098389, Accuracy: 0.5732421875\n",
            "Batch: 13, Loss: 1.2243013381958008, Accuracy: 0.615234375\n",
            "Batch: 14, Loss: 1.283185362815857, Accuracy: 0.59765625\n",
            "TEST Loss: 1.5851914882659912, Accuracy: 0.52734375\n",
            "Batch: 16, Loss: 1.374873161315918, Accuracy: 0.5791015625\n",
            "Batch: 17, Loss: 1.4341192245483398, Accuracy: 0.5556640625\n",
            "Batch: 18, Loss: 1.5044479370117188, Accuracy: 0.529296875\n",
            "Batch: 19, Loss: 1.3260958194732666, Accuracy: 0.5849609375\n",
            "TEST Loss: 1.800325870513916, Accuracy: 0.4736328125\n",
            "Batch: 21, Loss: 1.2424079179763794, Accuracy: 0.609375\n",
            "Batch: 22, Loss: 1.376500129699707, Accuracy: 0.5751953125\n",
            "Batch: 23, Loss: 1.4394094944000244, Accuracy: 0.552734375\n",
            "Batch: 24, Loss: 1.3942137956619263, Accuracy: 0.568359375\n",
            "TEST Loss: 1.6985588073730469, Accuracy: 0.484375\n",
            "Batch: 26, Loss: 1.236727237701416, Accuracy: 0.59765625\n",
            "Batch: 27, Loss: 1.249327301979065, Accuracy: 0.5947265625\n",
            "Batch: 28, Loss: 1.2694401741027832, Accuracy: 0.58984375\n",
            "Batch: 29, Loss: 1.2938551902770996, Accuracy: 0.5888671875\n",
            "TEST Loss: 1.6568481922149658, Accuracy: 0.484375\n",
            "Batch: 31, Loss: 1.3362820148468018, Accuracy: 0.5673828125\n",
            "Batch: 32, Loss: 1.233130693435669, Accuracy: 0.6103515625\n",
            "Batch: 33, Loss: 1.2355151176452637, Accuracy: 0.595703125\n",
            "Batch: 34, Loss: 1.2975261211395264, Accuracy: 0.5771484375\n",
            "TEST Loss: 1.3635871410369873, Accuracy: 0.5810546875\n",
            "Batch: 36, Loss: 1.208128571510315, Accuracy: 0.603515625\n",
            "Batch: 37, Loss: 1.2953301668167114, Accuracy: 0.595703125\n",
            "Epoch 25/100\n",
            "Batch: 1, Loss: 1.4172872304916382, Accuracy: 0.57421875\n",
            "Batch: 2, Loss: 1.294332504272461, Accuracy: 0.6005859375\n",
            "Batch: 3, Loss: 1.4212807416915894, Accuracy: 0.5615234375\n",
            "Batch: 4, Loss: 1.3024553060531616, Accuracy: 0.5869140625\n",
            "TEST Loss: 1.5699604749679565, Accuracy: 0.5234375\n",
            "Batch: 6, Loss: 1.296327829360962, Accuracy: 0.572265625\n",
            "Batch: 7, Loss: 1.1937785148620605, Accuracy: 0.6123046875\n",
            "Batch: 8, Loss: 1.3139044046401978, Accuracy: 0.5908203125\n",
            "Batch: 9, Loss: 1.3351225852966309, Accuracy: 0.59375\n",
            "TEST Loss: 1.5168423652648926, Accuracy: 0.5673828125\n",
            "Batch: 11, Loss: 1.3053836822509766, Accuracy: 0.5810546875\n",
            "Batch: 12, Loss: 1.2754356861114502, Accuracy: 0.583984375\n",
            "Batch: 13, Loss: 1.1892940998077393, Accuracy: 0.603515625\n",
            "Batch: 14, Loss: 1.1974778175354004, Accuracy: 0.607421875\n",
            "TEST Loss: 1.5334196090698242, Accuracy: 0.537109375\n",
            "Batch: 16, Loss: 1.338318109512329, Accuracy: 0.5751953125\n",
            "Batch: 17, Loss: 1.437628149986267, Accuracy: 0.5615234375\n",
            "Batch: 18, Loss: 1.4270544052124023, Accuracy: 0.5517578125\n",
            "Batch: 19, Loss: 1.2481703758239746, Accuracy: 0.6015625\n",
            "TEST Loss: 1.7549537420272827, Accuracy: 0.494140625\n",
            "Batch: 21, Loss: 1.1771700382232666, Accuracy: 0.625\n",
            "Batch: 22, Loss: 1.2843139171600342, Accuracy: 0.59765625\n",
            "Batch: 23, Loss: 1.3375941514968872, Accuracy: 0.560546875\n",
            "Batch: 24, Loss: 1.3589270114898682, Accuracy: 0.58984375\n",
            "TEST Loss: 1.675275444984436, Accuracy: 0.4794921875\n",
            "Batch: 26, Loss: 1.1894586086273193, Accuracy: 0.6279296875\n",
            "Batch: 27, Loss: 1.1909353733062744, Accuracy: 0.62109375\n",
            "Batch: 28, Loss: 1.1916170120239258, Accuracy: 0.615234375\n",
            "Batch: 29, Loss: 1.2450352907180786, Accuracy: 0.609375\n",
            "TEST Loss: 1.5601633787155151, Accuracy: 0.54296875\n",
            "Batch: 31, Loss: 1.2752788066864014, Accuracy: 0.6005859375\n",
            "Batch: 32, Loss: 1.1873466968536377, Accuracy: 0.63671875\n",
            "Batch: 33, Loss: 1.185680866241455, Accuracy: 0.6025390625\n",
            "Batch: 34, Loss: 1.2326712608337402, Accuracy: 0.609375\n",
            "TEST Loss: 1.3057376146316528, Accuracy: 0.5908203125\n",
            "Batch: 36, Loss: 1.2002578973770142, Accuracy: 0.6142578125\n",
            "Batch: 37, Loss: 1.245431661605835, Accuracy: 0.6064453125\n",
            "Epoch 26/100\n",
            "Batch: 1, Loss: 1.3724160194396973, Accuracy: 0.5947265625\n",
            "Batch: 2, Loss: 1.221348524093628, Accuracy: 0.6337890625\n",
            "Batch: 3, Loss: 1.3857392072677612, Accuracy: 0.578125\n",
            "Batch: 4, Loss: 1.2297083139419556, Accuracy: 0.607421875\n",
            "TEST Loss: 1.5351308584213257, Accuracy: 0.52734375\n",
            "Batch: 6, Loss: 1.2363979816436768, Accuracy: 0.595703125\n",
            "Batch: 7, Loss: 1.1417889595031738, Accuracy: 0.6357421875\n",
            "Batch: 8, Loss: 1.2345443964004517, Accuracy: 0.6259765625\n",
            "Batch: 9, Loss: 1.2690198421478271, Accuracy: 0.5966796875\n",
            "TEST Loss: 1.4769508838653564, Accuracy: 0.58203125\n",
            "Batch: 11, Loss: 1.2580279111862183, Accuracy: 0.6005859375\n",
            "Batch: 12, Loss: 1.220852017402649, Accuracy: 0.603515625\n",
            "Batch: 13, Loss: 1.1153309345245361, Accuracy: 0.634765625\n",
            "Batch: 14, Loss: 1.1143684387207031, Accuracy: 0.642578125\n",
            "TEST Loss: 1.5323364734649658, Accuracy: 0.5546875\n",
            "Batch: 16, Loss: 1.257781744003296, Accuracy: 0.5908203125\n",
            "Batch: 17, Loss: 1.3466993570327759, Accuracy: 0.5830078125\n",
            "Batch: 18, Loss: 1.358884334564209, Accuracy: 0.57421875\n",
            "Batch: 19, Loss: 1.1519954204559326, Accuracy: 0.6396484375\n",
            "TEST Loss: 1.735045075416565, Accuracy: 0.4990234375\n",
            "Batch: 21, Loss: 1.1424633264541626, Accuracy: 0.642578125\n",
            "Batch: 22, Loss: 1.2667295932769775, Accuracy: 0.615234375\n",
            "Batch: 23, Loss: 1.3127585649490356, Accuracy: 0.5908203125\n",
            "Batch: 24, Loss: 1.2990293502807617, Accuracy: 0.580078125\n",
            "TEST Loss: 1.6777193546295166, Accuracy: 0.5068359375\n",
            "Batch: 26, Loss: 1.1046066284179688, Accuracy: 0.6728515625\n",
            "Batch: 27, Loss: 1.1173076629638672, Accuracy: 0.646484375\n",
            "Batch: 28, Loss: 1.124332308769226, Accuracy: 0.6484375\n",
            "Batch: 29, Loss: 1.2146363258361816, Accuracy: 0.626953125\n",
            "TEST Loss: 1.5001226663589478, Accuracy: 0.5380859375\n",
            "Batch: 31, Loss: 1.218618631362915, Accuracy: 0.619140625\n",
            "Batch: 32, Loss: 1.118870735168457, Accuracy: 0.6533203125\n",
            "Batch: 33, Loss: 1.080689549446106, Accuracy: 0.6513671875\n",
            "Batch: 34, Loss: 1.1629698276519775, Accuracy: 0.62109375\n",
            "TEST Loss: 1.2309458255767822, Accuracy: 0.623046875\n",
            "Batch: 36, Loss: 1.141114592552185, Accuracy: 0.6396484375\n",
            "Batch: 37, Loss: 1.1638078689575195, Accuracy: 0.6494140625\n",
            "Epoch 27/100\n",
            "Batch: 1, Loss: 1.3033528327941895, Accuracy: 0.6123046875\n",
            "Batch: 2, Loss: 1.1505374908447266, Accuracy: 0.650390625\n",
            "Batch: 3, Loss: 1.283874750137329, Accuracy: 0.60546875\n",
            "Batch: 4, Loss: 1.1744340658187866, Accuracy: 0.623046875\n",
            "TEST Loss: 1.5102297067642212, Accuracy: 0.5419921875\n",
            "Batch: 6, Loss: 1.1590347290039062, Accuracy: 0.6220703125\n",
            "Batch: 7, Loss: 1.1063034534454346, Accuracy: 0.64453125\n",
            "Batch: 8, Loss: 1.1380951404571533, Accuracy: 0.650390625\n",
            "Batch: 9, Loss: 1.1765609979629517, Accuracy: 0.6376953125\n",
            "TEST Loss: 1.4115588665008545, Accuracy: 0.6083984375\n",
            "Batch: 11, Loss: 1.2120707035064697, Accuracy: 0.6181640625\n",
            "Batch: 12, Loss: 1.161183476448059, Accuracy: 0.6142578125\n",
            "Batch: 13, Loss: 1.0198602676391602, Accuracy: 0.6884765625\n",
            "Batch: 14, Loss: 1.0636440515518188, Accuracy: 0.6572265625\n",
            "TEST Loss: 1.4753820896148682, Accuracy: 0.5419921875\n",
            "Batch: 16, Loss: 1.2054150104522705, Accuracy: 0.607421875\n",
            "Batch: 17, Loss: 1.2813812494277954, Accuracy: 0.5869140625\n",
            "Batch: 18, Loss: 1.3108489513397217, Accuracy: 0.595703125\n",
            "Batch: 19, Loss: 1.1589832305908203, Accuracy: 0.6328125\n",
            "TEST Loss: 1.7189996242523193, Accuracy: 0.5009765625\n",
            "Batch: 21, Loss: 1.0958855152130127, Accuracy: 0.6396484375\n",
            "Batch: 22, Loss: 1.1664514541625977, Accuracy: 0.650390625\n",
            "Batch: 23, Loss: 1.1932486295700073, Accuracy: 0.62109375\n",
            "Batch: 24, Loss: 1.2322474718093872, Accuracy: 0.599609375\n",
            "TEST Loss: 1.6287121772766113, Accuracy: 0.509765625\n",
            "Batch: 26, Loss: 1.0311592817306519, Accuracy: 0.6640625\n",
            "Batch: 27, Loss: 1.0566298961639404, Accuracy: 0.6689453125\n",
            "Batch: 28, Loss: 1.0602949857711792, Accuracy: 0.6552734375\n",
            "Batch: 29, Loss: 1.1067335605621338, Accuracy: 0.650390625\n",
            "TEST Loss: 1.4896395206451416, Accuracy: 0.572265625\n",
            "Batch: 31, Loss: 1.1264944076538086, Accuracy: 0.65234375\n",
            "Batch: 32, Loss: 1.0364047288894653, Accuracy: 0.6708984375\n",
            "Batch: 33, Loss: 1.0662490129470825, Accuracy: 0.66015625\n",
            "Batch: 34, Loss: 1.131334900856018, Accuracy: 0.6240234375\n",
            "TEST Loss: 1.193416714668274, Accuracy: 0.6484375\n",
            "Batch: 36, Loss: 1.0295782089233398, Accuracy: 0.6650390625\n",
            "Batch: 37, Loss: 1.0642560720443726, Accuracy: 0.6748046875\n",
            "Epoch 28/100\n",
            "Batch: 1, Loss: 1.2349425554275513, Accuracy: 0.6513671875\n",
            "Batch: 2, Loss: 1.053214430809021, Accuracy: 0.6943359375\n",
            "Batch: 3, Loss: 1.2513585090637207, Accuracy: 0.6064453125\n",
            "Batch: 4, Loss: 1.1016128063201904, Accuracy: 0.640625\n",
            "TEST Loss: 1.4438395500183105, Accuracy: 0.568359375\n",
            "Batch: 6, Loss: 1.1053287982940674, Accuracy: 0.6513671875\n",
            "Batch: 7, Loss: 1.041218876838684, Accuracy: 0.671875\n",
            "Batch: 8, Loss: 1.0912731885910034, Accuracy: 0.65625\n",
            "Batch: 9, Loss: 1.1205331087112427, Accuracy: 0.6357421875\n",
            "TEST Loss: 1.3868491649627686, Accuracy: 0.611328125\n",
            "Batch: 11, Loss: 1.1275768280029297, Accuracy: 0.64453125\n",
            "Batch: 12, Loss: 1.0976123809814453, Accuracy: 0.6435546875\n",
            "Batch: 13, Loss: 0.9883667230606079, Accuracy: 0.6943359375\n",
            "Batch: 14, Loss: 1.0306243896484375, Accuracy: 0.66796875\n",
            "TEST Loss: 1.4194117784500122, Accuracy: 0.580078125\n",
            "Batch: 16, Loss: 1.1191980838775635, Accuracy: 0.650390625\n",
            "Batch: 17, Loss: 1.2184581756591797, Accuracy: 0.6240234375\n",
            "Batch: 18, Loss: 1.207471489906311, Accuracy: 0.6298828125\n",
            "Batch: 19, Loss: 1.1098527908325195, Accuracy: 0.65234375\n",
            "TEST Loss: 1.6962980031967163, Accuracy: 0.5078125\n",
            "Batch: 21, Loss: 1.000727653503418, Accuracy: 0.6728515625\n",
            "Batch: 22, Loss: 1.1490485668182373, Accuracy: 0.6396484375\n",
            "Batch: 23, Loss: 1.182535171508789, Accuracy: 0.64453125\n",
            "Batch: 24, Loss: 1.1979634761810303, Accuracy: 0.61328125\n",
            "TEST Loss: 1.6117253303527832, Accuracy: 0.5146484375\n",
            "Batch: 26, Loss: 0.9823092222213745, Accuracy: 0.7001953125\n",
            "Batch: 27, Loss: 1.0133458375930786, Accuracy: 0.685546875\n",
            "Batch: 28, Loss: 0.9894508719444275, Accuracy: 0.701171875\n",
            "Batch: 29, Loss: 1.0685651302337646, Accuracy: 0.6611328125\n",
            "TEST Loss: 1.4479637145996094, Accuracy: 0.5712890625\n",
            "Batch: 31, Loss: 1.0384421348571777, Accuracy: 0.68359375\n",
            "Batch: 32, Loss: 0.988689661026001, Accuracy: 0.6845703125\n",
            "Batch: 33, Loss: 0.9976090788841248, Accuracy: 0.6748046875\n",
            "Batch: 34, Loss: 1.0512256622314453, Accuracy: 0.6708984375\n",
            "TEST Loss: 1.1500343084335327, Accuracy: 0.666015625\n",
            "Batch: 36, Loss: 1.0178043842315674, Accuracy: 0.66796875\n",
            "Batch: 37, Loss: 1.022078037261963, Accuracy: 0.6826171875\n",
            "Epoch 29/100\n",
            "Batch: 1, Loss: 1.2006537914276123, Accuracy: 0.6328125\n",
            "Batch: 2, Loss: 0.9889916181564331, Accuracy: 0.701171875\n",
            "Batch: 3, Loss: 1.1380276679992676, Accuracy: 0.64453125\n",
            "Batch: 4, Loss: 1.048024296760559, Accuracy: 0.6923828125\n",
            "TEST Loss: 1.4733803272247314, Accuracy: 0.5771484375\n",
            "Batch: 6, Loss: 1.060450553894043, Accuracy: 0.65625\n",
            "Batch: 7, Loss: 0.9829431176185608, Accuracy: 0.6796875\n",
            "Batch: 8, Loss: 1.0564634799957275, Accuracy: 0.669921875\n",
            "Batch: 9, Loss: 1.068708896636963, Accuracy: 0.66796875\n",
            "TEST Loss: 1.3817659616470337, Accuracy: 0.6240234375\n",
            "Batch: 11, Loss: 1.0891227722167969, Accuracy: 0.6669921875\n",
            "Batch: 12, Loss: 1.025052785873413, Accuracy: 0.68359375\n",
            "Batch: 13, Loss: 0.9291480183601379, Accuracy: 0.71875\n",
            "Batch: 14, Loss: 0.9971550703048706, Accuracy: 0.67578125\n",
            "TEST Loss: 1.3959860801696777, Accuracy: 0.603515625\n",
            "Batch: 16, Loss: 1.0565903186798096, Accuracy: 0.6669921875\n",
            "Batch: 17, Loss: 1.1844305992126465, Accuracy: 0.62109375\n",
            "Batch: 18, Loss: 1.2015032768249512, Accuracy: 0.6123046875\n",
            "Batch: 19, Loss: 1.0005778074264526, Accuracy: 0.6884765625\n",
            "TEST Loss: 1.6743483543395996, Accuracy: 0.5263671875\n",
            "Batch: 21, Loss: 0.9699602723121643, Accuracy: 0.6923828125\n",
            "Batch: 22, Loss: 1.0878901481628418, Accuracy: 0.669921875\n",
            "Batch: 23, Loss: 1.1640092134475708, Accuracy: 0.6240234375\n",
            "Batch: 24, Loss: 1.1300108432769775, Accuracy: 0.646484375\n",
            "TEST Loss: 1.5449180603027344, Accuracy: 0.5576171875\n",
            "Batch: 26, Loss: 0.9743475914001465, Accuracy: 0.6953125\n",
            "Batch: 27, Loss: 0.9676633477210999, Accuracy: 0.693359375\n",
            "Batch: 28, Loss: 0.9733067750930786, Accuracy: 0.712890625\n",
            "Batch: 29, Loss: 1.0039138793945312, Accuracy: 0.6826171875\n",
            "TEST Loss: 1.3924732208251953, Accuracy: 0.5947265625\n",
            "Batch: 31, Loss: 0.9761934280395508, Accuracy: 0.7001953125\n",
            "Batch: 32, Loss: 0.9316422343254089, Accuracy: 0.7138671875\n",
            "Batch: 33, Loss: 0.9732632637023926, Accuracy: 0.6875\n",
            "Batch: 34, Loss: 1.0364207029342651, Accuracy: 0.681640625\n",
            "TEST Loss: 1.1152305603027344, Accuracy: 0.6708984375\n",
            "Batch: 36, Loss: 0.9481288194656372, Accuracy: 0.7041015625\n",
            "Batch: 37, Loss: 0.9972468614578247, Accuracy: 0.69140625\n",
            "Epoch 30/100\n",
            "Batch: 1, Loss: 1.1472587585449219, Accuracy: 0.65234375\n",
            "Batch: 2, Loss: 0.9576963186264038, Accuracy: 0.7060546875\n",
            "Batch: 3, Loss: 1.1053279638290405, Accuracy: 0.646484375\n",
            "Batch: 4, Loss: 1.0005300045013428, Accuracy: 0.6982421875\n",
            "TEST Loss: 1.4733713865280151, Accuracy: 0.5966796875\n",
            "Batch: 6, Loss: 1.0034023523330688, Accuracy: 0.68359375\n",
            "Batch: 7, Loss: 0.9566859006881714, Accuracy: 0.7080078125\n",
            "Batch: 8, Loss: 1.0057129859924316, Accuracy: 0.6953125\n",
            "Batch: 9, Loss: 1.027377963066101, Accuracy: 0.6796875\n",
            "TEST Loss: 1.3731437921524048, Accuracy: 0.6201171875\n",
            "Batch: 11, Loss: 1.0356378555297852, Accuracy: 0.6826171875\n",
            "Batch: 12, Loss: 0.9848088026046753, Accuracy: 0.68359375\n",
            "Batch: 13, Loss: 0.8825016021728516, Accuracy: 0.7373046875\n",
            "Batch: 14, Loss: 0.9515394568443298, Accuracy: 0.705078125\n",
            "TEST Loss: 1.3852611780166626, Accuracy: 0.6083984375\n",
            "Batch: 16, Loss: 1.0006259679794312, Accuracy: 0.69140625\n",
            "Batch: 17, Loss: 1.1323002576828003, Accuracy: 0.62890625\n",
            "Batch: 18, Loss: 1.1688593626022339, Accuracy: 0.630859375\n",
            "Batch: 19, Loss: 1.0129468441009521, Accuracy: 0.6748046875\n",
            "TEST Loss: 1.621415615081787, Accuracy: 0.5322265625\n",
            "Batch: 21, Loss: 0.9264674186706543, Accuracy: 0.716796875\n",
            "Batch: 22, Loss: 1.011831521987915, Accuracy: 0.6845703125\n",
            "Batch: 23, Loss: 1.066811203956604, Accuracy: 0.6650390625\n",
            "Batch: 24, Loss: 1.0644078254699707, Accuracy: 0.6630859375\n",
            "TEST Loss: 1.5663079023361206, Accuracy: 0.5439453125\n",
            "Batch: 26, Loss: 0.9304866194725037, Accuracy: 0.708984375\n",
            "Batch: 27, Loss: 0.9210057258605957, Accuracy: 0.6962890625\n",
            "Batch: 28, Loss: 0.9247892498970032, Accuracy: 0.7109375\n",
            "Batch: 29, Loss: 0.9682936072349548, Accuracy: 0.7041015625\n",
            "TEST Loss: 1.413924217224121, Accuracy: 0.5947265625\n",
            "Batch: 31, Loss: 0.9617787599563599, Accuracy: 0.7138671875\n",
            "Batch: 32, Loss: 0.8979554176330566, Accuracy: 0.7265625\n",
            "Batch: 33, Loss: 0.9643563032150269, Accuracy: 0.701171875\n",
            "Batch: 34, Loss: 0.9747287631034851, Accuracy: 0.6884765625\n",
            "TEST Loss: 1.1462738513946533, Accuracy: 0.6435546875\n",
            "Batch: 36, Loss: 0.962790310382843, Accuracy: 0.685546875\n",
            "Batch: 37, Loss: 0.9535765051841736, Accuracy: 0.7119140625\n",
            "Saved Weights at epoch 30 to file Weights_mozart.h5\n",
            "Epoch 31/100\n",
            "Batch: 1, Loss: 1.1148223876953125, Accuracy: 0.66015625\n",
            "Batch: 2, Loss: 0.935141921043396, Accuracy: 0.7109375\n",
            "Batch: 3, Loss: 1.054802417755127, Accuracy: 0.6650390625\n",
            "Batch: 4, Loss: 1.0037628412246704, Accuracy: 0.685546875\n",
            "TEST Loss: 1.4419975280761719, Accuracy: 0.58984375\n",
            "Batch: 6, Loss: 1.006485939025879, Accuracy: 0.6708984375\n",
            "Batch: 7, Loss: 0.8925260305404663, Accuracy: 0.716796875\n",
            "Batch: 8, Loss: 0.9791312217712402, Accuracy: 0.6728515625\n",
            "Batch: 9, Loss: 1.0027390718460083, Accuracy: 0.6796875\n",
            "TEST Loss: 1.3593804836273193, Accuracy: 0.6220703125\n",
            "Batch: 11, Loss: 1.0781400203704834, Accuracy: 0.6669921875\n",
            "Batch: 12, Loss: 1.00056791305542, Accuracy: 0.68359375\n",
            "Batch: 13, Loss: 0.8767493963241577, Accuracy: 0.736328125\n",
            "Batch: 14, Loss: 0.9287317395210266, Accuracy: 0.70703125\n",
            "TEST Loss: 1.3368360996246338, Accuracy: 0.6142578125\n",
            "Batch: 16, Loss: 0.9588478803634644, Accuracy: 0.7041015625\n",
            "Batch: 17, Loss: 1.103111982345581, Accuracy: 0.65625\n",
            "Batch: 18, Loss: 1.0788285732269287, Accuracy: 0.654296875\n",
            "Batch: 19, Loss: 0.9465473890304565, Accuracy: 0.6982421875\n",
            "TEST Loss: 1.6373367309570312, Accuracy: 0.5478515625\n",
            "Batch: 21, Loss: 0.9074192047119141, Accuracy: 0.7060546875\n",
            "Batch: 22, Loss: 1.0401803255081177, Accuracy: 0.6787109375\n",
            "Batch: 23, Loss: 1.0427145957946777, Accuracy: 0.6748046875\n",
            "Batch: 24, Loss: 1.0718919038772583, Accuracy: 0.6689453125\n",
            "TEST Loss: 1.552690029144287, Accuracy: 0.5595703125\n",
            "Batch: 26, Loss: 0.8834060430526733, Accuracy: 0.7216796875\n",
            "Batch: 27, Loss: 0.9048516154289246, Accuracy: 0.7216796875\n",
            "Batch: 28, Loss: 0.8891971111297607, Accuracy: 0.7255859375\n",
            "Batch: 29, Loss: 0.9616678953170776, Accuracy: 0.6982421875\n",
            "TEST Loss: 1.3596620559692383, Accuracy: 0.6201171875\n",
            "Batch: 31, Loss: 0.9179695248603821, Accuracy: 0.69921875\n",
            "Batch: 32, Loss: 0.8792006969451904, Accuracy: 0.7255859375\n",
            "Batch: 33, Loss: 0.8966335654258728, Accuracy: 0.7080078125\n",
            "Batch: 34, Loss: 0.939501941204071, Accuracy: 0.7060546875\n",
            "TEST Loss: 1.0835647583007812, Accuracy: 0.6708984375\n",
            "Batch: 36, Loss: 0.8616214990615845, Accuracy: 0.7255859375\n",
            "Batch: 37, Loss: 0.8854371309280396, Accuracy: 0.7470703125\n",
            "Epoch 32/100\n",
            "Batch: 1, Loss: 1.0182349681854248, Accuracy: 0.7060546875\n",
            "Batch: 2, Loss: 0.9417710304260254, Accuracy: 0.705078125\n",
            "Batch: 3, Loss: 1.0356884002685547, Accuracy: 0.6669921875\n",
            "Batch: 4, Loss: 0.9100829362869263, Accuracy: 0.720703125\n",
            "TEST Loss: 1.387549877166748, Accuracy: 0.6083984375\n",
            "Batch: 6, Loss: 0.9448198080062866, Accuracy: 0.6982421875\n",
            "Batch: 7, Loss: 0.8380957245826721, Accuracy: 0.7314453125\n",
            "Batch: 8, Loss: 0.9123260378837585, Accuracy: 0.7216796875\n",
            "Batch: 9, Loss: 0.9026937484741211, Accuracy: 0.7265625\n",
            "TEST Loss: 1.3228336572647095, Accuracy: 0.638671875\n",
            "Batch: 11, Loss: 0.9636708498001099, Accuracy: 0.6767578125\n",
            "Batch: 12, Loss: 0.8953688740730286, Accuracy: 0.70703125\n",
            "Batch: 13, Loss: 0.8580567836761475, Accuracy: 0.73046875\n",
            "Batch: 14, Loss: 0.888364851474762, Accuracy: 0.7216796875\n",
            "TEST Loss: 1.2964756488800049, Accuracy: 0.626953125\n",
            "Batch: 16, Loss: 0.9000394344329834, Accuracy: 0.7216796875\n",
            "Batch: 17, Loss: 1.0242303609848022, Accuracy: 0.6669921875\n",
            "Batch: 18, Loss: 1.0212383270263672, Accuracy: 0.6767578125\n",
            "Batch: 19, Loss: 0.9052307605743408, Accuracy: 0.7138671875\n",
            "TEST Loss: 1.6103193759918213, Accuracy: 0.5537109375\n",
            "Batch: 21, Loss: 0.888872504234314, Accuracy: 0.720703125\n",
            "Batch: 22, Loss: 0.9369066953659058, Accuracy: 0.708984375\n",
            "Batch: 23, Loss: 0.9533425569534302, Accuracy: 0.7001953125\n",
            "Batch: 24, Loss: 0.9865622520446777, Accuracy: 0.689453125\n",
            "TEST Loss: 1.5074999332427979, Accuracy: 0.5751953125\n",
            "Batch: 26, Loss: 0.8269025683403015, Accuracy: 0.72265625\n",
            "Batch: 27, Loss: 0.8164273500442505, Accuracy: 0.7509765625\n",
            "Batch: 28, Loss: 0.8109193444252014, Accuracy: 0.751953125\n",
            "Batch: 29, Loss: 0.8191064596176147, Accuracy: 0.7587890625\n",
            "TEST Loss: 1.3227483034133911, Accuracy: 0.625\n",
            "Batch: 31, Loss: 0.8488520383834839, Accuracy: 0.7392578125\n",
            "Batch: 32, Loss: 0.7874871492385864, Accuracy: 0.7724609375\n",
            "Batch: 33, Loss: 0.8042217493057251, Accuracy: 0.7373046875\n",
            "Batch: 34, Loss: 0.8717441558837891, Accuracy: 0.71484375\n",
            "TEST Loss: 1.0179120302200317, Accuracy: 0.7001953125\n",
            "Batch: 36, Loss: 0.8174901008605957, Accuracy: 0.751953125\n",
            "Batch: 37, Loss: 0.8195092678070068, Accuracy: 0.7607421875\n",
            "Epoch 33/100\n",
            "Batch: 1, Loss: 0.9789985418319702, Accuracy: 0.7001953125\n",
            "Batch: 2, Loss: 0.837188184261322, Accuracy: 0.748046875\n",
            "Batch: 3, Loss: 0.9745866060256958, Accuracy: 0.6884765625\n",
            "Batch: 4, Loss: 0.8745965957641602, Accuracy: 0.7197265625\n",
            "TEST Loss: 1.4015676975250244, Accuracy: 0.5986328125\n",
            "Batch: 6, Loss: 0.91748046875, Accuracy: 0.7158203125\n",
            "Batch: 7, Loss: 0.8027803897857666, Accuracy: 0.73828125\n",
            "Batch: 8, Loss: 0.8651537299156189, Accuracy: 0.7373046875\n",
            "Batch: 9, Loss: 0.8980157971382141, Accuracy: 0.716796875\n",
            "TEST Loss: 1.3094624280929565, Accuracy: 0.634765625\n",
            "Batch: 11, Loss: 0.8974506855010986, Accuracy: 0.72265625\n",
            "Batch: 12, Loss: 0.8598376512527466, Accuracy: 0.728515625\n",
            "Batch: 13, Loss: 0.7858865261077881, Accuracy: 0.7548828125\n",
            "Batch: 14, Loss: 0.8105340003967285, Accuracy: 0.73046875\n",
            "TEST Loss: 1.2957537174224854, Accuracy: 0.6513671875\n",
            "Batch: 16, Loss: 0.8853082656860352, Accuracy: 0.7314453125\n",
            "Batch: 17, Loss: 1.0101768970489502, Accuracy: 0.6796875\n",
            "Batch: 18, Loss: 0.9862655401229858, Accuracy: 0.69140625\n",
            "Batch: 19, Loss: 0.8420000672340393, Accuracy: 0.74609375\n",
            "TEST Loss: 1.5741231441497803, Accuracy: 0.578125\n",
            "Batch: 21, Loss: 0.7813715934753418, Accuracy: 0.75\n",
            "Batch: 22, Loss: 0.8957509994506836, Accuracy: 0.7158203125\n",
            "Batch: 23, Loss: 0.9052013158798218, Accuracy: 0.7197265625\n",
            "Batch: 24, Loss: 0.9214469790458679, Accuracy: 0.708984375\n",
            "TEST Loss: 1.5241082906723022, Accuracy: 0.56640625\n",
            "Batch: 26, Loss: 0.8072863817214966, Accuracy: 0.7373046875\n",
            "Batch: 27, Loss: 0.8512319922447205, Accuracy: 0.7236328125\n",
            "Batch: 28, Loss: 0.7889325022697449, Accuracy: 0.7490234375\n",
            "Batch: 29, Loss: 0.8223365545272827, Accuracy: 0.75\n",
            "TEST Loss: 1.3070147037506104, Accuracy: 0.6416015625\n",
            "Batch: 31, Loss: 0.8038906455039978, Accuracy: 0.748046875\n",
            "Batch: 32, Loss: 0.747786283493042, Accuracy: 0.77734375\n",
            "Batch: 33, Loss: 0.7919942140579224, Accuracy: 0.7490234375\n",
            "Batch: 34, Loss: 0.8481621742248535, Accuracy: 0.732421875\n",
            "TEST Loss: 1.0259618759155273, Accuracy: 0.71484375\n",
            "Batch: 36, Loss: 0.7750718593597412, Accuracy: 0.7548828125\n",
            "Batch: 37, Loss: 0.8081051111221313, Accuracy: 0.7626953125\n",
            "Epoch 34/100\n",
            "Batch: 1, Loss: 0.9773703217506409, Accuracy: 0.7236328125\n",
            "Batch: 2, Loss: 0.8127179145812988, Accuracy: 0.7626953125\n",
            "Batch: 3, Loss: 0.9024207592010498, Accuracy: 0.720703125\n",
            "Batch: 4, Loss: 0.8207537531852722, Accuracy: 0.7412109375\n",
            "TEST Loss: 1.32535719871521, Accuracy: 0.634765625\n",
            "Batch: 6, Loss: 0.827507495880127, Accuracy: 0.7333984375\n",
            "Batch: 7, Loss: 0.7871997952461243, Accuracy: 0.7548828125\n",
            "Batch: 8, Loss: 0.8193587064743042, Accuracy: 0.74609375\n",
            "Batch: 9, Loss: 0.8569679260253906, Accuracy: 0.7265625\n",
            "TEST Loss: 1.2721033096313477, Accuracy: 0.666015625\n",
            "Batch: 11, Loss: 0.8823647499084473, Accuracy: 0.7119140625\n",
            "Batch: 12, Loss: 0.794304370880127, Accuracy: 0.755859375\n",
            "Batch: 13, Loss: 0.7546054124832153, Accuracy: 0.7724609375\n",
            "Batch: 14, Loss: 0.7997009754180908, Accuracy: 0.7392578125\n",
            "TEST Loss: 1.2960398197174072, Accuracy: 0.6279296875\n",
            "Batch: 16, Loss: 0.8227235078811646, Accuracy: 0.7607421875\n",
            "Batch: 17, Loss: 0.9382871389389038, Accuracy: 0.7001953125\n",
            "Batch: 18, Loss: 0.9450452327728271, Accuracy: 0.6982421875\n",
            "Batch: 19, Loss: 0.789733350276947, Accuracy: 0.7666015625\n",
            "TEST Loss: 1.5594955682754517, Accuracy: 0.5556640625\n",
            "Batch: 21, Loss: 0.7633069753646851, Accuracy: 0.7548828125\n",
            "Batch: 22, Loss: 0.842025876045227, Accuracy: 0.744140625\n",
            "Batch: 23, Loss: 0.8862007856369019, Accuracy: 0.7333984375\n",
            "Batch: 24, Loss: 0.8982418179512024, Accuracy: 0.7041015625\n",
            "TEST Loss: 1.438388466835022, Accuracy: 0.5986328125\n",
            "Batch: 26, Loss: 0.7431829571723938, Accuracy: 0.765625\n",
            "Batch: 27, Loss: 0.7535697221755981, Accuracy: 0.7646484375\n",
            "Batch: 28, Loss: 0.7304596304893494, Accuracy: 0.7783203125\n",
            "Batch: 29, Loss: 0.7764976620674133, Accuracy: 0.75390625\n",
            "TEST Loss: 1.2601168155670166, Accuracy: 0.640625\n",
            "Batch: 31, Loss: 0.8059040307998657, Accuracy: 0.74609375\n",
            "Batch: 32, Loss: 0.6941937804222107, Accuracy: 0.791015625\n",
            "Batch: 33, Loss: 0.7257765531539917, Accuracy: 0.771484375\n",
            "Batch: 34, Loss: 0.7951325178146362, Accuracy: 0.748046875\n",
            "TEST Loss: 0.9574671983718872, Accuracy: 0.716796875\n",
            "Batch: 36, Loss: 0.7335418462753296, Accuracy: 0.7607421875\n",
            "Batch: 37, Loss: 0.7184718251228333, Accuracy: 0.78125\n",
            "Epoch 35/100\n",
            "Batch: 1, Loss: 0.9036141633987427, Accuracy: 0.744140625\n",
            "Batch: 2, Loss: 0.7473857402801514, Accuracy: 0.77734375\n",
            "Batch: 3, Loss: 0.8656293153762817, Accuracy: 0.7333984375\n",
            "Batch: 4, Loss: 0.76926589012146, Accuracy: 0.7626953125\n",
            "TEST Loss: 1.3293633460998535, Accuracy: 0.634765625\n",
            "Batch: 6, Loss: 0.8207950592041016, Accuracy: 0.732421875\n",
            "Batch: 7, Loss: 0.7442446351051331, Accuracy: 0.7705078125\n",
            "Batch: 8, Loss: 0.8154569268226624, Accuracy: 0.7353515625\n",
            "Batch: 9, Loss: 0.8149365782737732, Accuracy: 0.734375\n",
            "TEST Loss: 1.2704873085021973, Accuracy: 0.646484375\n",
            "Batch: 11, Loss: 0.8763184547424316, Accuracy: 0.72265625\n",
            "Batch: 12, Loss: 0.7777276039123535, Accuracy: 0.755859375\n",
            "Batch: 13, Loss: 0.7124284505844116, Accuracy: 0.7705078125\n",
            "Batch: 14, Loss: 0.7706717252731323, Accuracy: 0.75390625\n",
            "TEST Loss: 1.2302958965301514, Accuracy: 0.6669921875\n",
            "Batch: 16, Loss: 0.7329258918762207, Accuracy: 0.7705078125\n",
            "Batch: 17, Loss: 0.8847553133964539, Accuracy: 0.724609375\n",
            "Batch: 18, Loss: 0.9148370027542114, Accuracy: 0.712890625\n",
            "Batch: 19, Loss: 0.7851135730743408, Accuracy: 0.76953125\n",
            "TEST Loss: 1.5040370225906372, Accuracy: 0.595703125\n",
            "Batch: 21, Loss: 0.742273211479187, Accuracy: 0.7490234375\n",
            "Batch: 22, Loss: 0.7786833047866821, Accuracy: 0.771484375\n",
            "Batch: 23, Loss: 0.8515739440917969, Accuracy: 0.7294921875\n",
            "Batch: 24, Loss: 0.831994891166687, Accuracy: 0.736328125\n",
            "TEST Loss: 1.444746732711792, Accuracy: 0.6064453125\n",
            "Batch: 26, Loss: 0.6932191252708435, Accuracy: 0.7861328125\n",
            "Batch: 27, Loss: 0.6711745262145996, Accuracy: 0.7978515625\n",
            "Batch: 28, Loss: 0.6895831823348999, Accuracy: 0.787109375\n",
            "Batch: 29, Loss: 0.7500166893005371, Accuracy: 0.7646484375\n",
            "TEST Loss: 1.251251220703125, Accuracy: 0.6611328125\n",
            "Batch: 31, Loss: 0.7301418781280518, Accuracy: 0.7705078125\n",
            "Batch: 32, Loss: 0.6937015056610107, Accuracy: 0.783203125\n",
            "Batch: 33, Loss: 0.6823076605796814, Accuracy: 0.7880859375\n",
            "Batch: 34, Loss: 0.7763620615005493, Accuracy: 0.7509765625\n",
            "TEST Loss: 0.976419985294342, Accuracy: 0.7197265625\n",
            "Batch: 36, Loss: 0.6789829730987549, Accuracy: 0.78125\n",
            "Batch: 37, Loss: 0.7044286131858826, Accuracy: 0.798828125\n",
            "Epoch 36/100\n",
            "Batch: 1, Loss: 0.8656672239303589, Accuracy: 0.744140625\n",
            "Batch: 2, Loss: 0.7579882740974426, Accuracy: 0.76953125\n",
            "Batch: 3, Loss: 0.8701633214950562, Accuracy: 0.7216796875\n",
            "Batch: 4, Loss: 0.7171594500541687, Accuracy: 0.78125\n",
            "TEST Loss: 1.314875841140747, Accuracy: 0.6396484375\n",
            "Batch: 6, Loss: 0.7550026774406433, Accuracy: 0.75\n",
            "Batch: 7, Loss: 0.7080925703048706, Accuracy: 0.7822265625\n",
            "Batch: 8, Loss: 0.7092956304550171, Accuracy: 0.78125\n",
            "Batch: 9, Loss: 0.7639596462249756, Accuracy: 0.76171875\n",
            "TEST Loss: 1.2561324834823608, Accuracy: 0.6630859375\n",
            "Batch: 11, Loss: 0.7931402921676636, Accuracy: 0.7529296875\n",
            "Batch: 12, Loss: 0.7201073169708252, Accuracy: 0.779296875\n",
            "Batch: 13, Loss: 0.6769879460334778, Accuracy: 0.779296875\n",
            "Batch: 14, Loss: 0.6827117800712585, Accuracy: 0.7861328125\n",
            "TEST Loss: 1.2416523694992065, Accuracy: 0.6630859375\n",
            "Batch: 16, Loss: 0.7372605800628662, Accuracy: 0.7646484375\n",
            "Batch: 17, Loss: 0.8785901665687561, Accuracy: 0.7255859375\n",
            "Batch: 18, Loss: 0.8243745565414429, Accuracy: 0.75\n",
            "Batch: 19, Loss: 0.746549129486084, Accuracy: 0.76953125\n",
            "TEST Loss: 1.5285894870758057, Accuracy: 0.595703125\n",
            "Batch: 21, Loss: 0.6726940870285034, Accuracy: 0.7822265625\n",
            "Batch: 22, Loss: 0.7405850887298584, Accuracy: 0.7783203125\n",
            "Batch: 23, Loss: 0.782116174697876, Accuracy: 0.7490234375\n",
            "Batch: 24, Loss: 0.8141592144966125, Accuracy: 0.7392578125\n",
            "TEST Loss: 1.5255287885665894, Accuracy: 0.5849609375\n",
            "Batch: 26, Loss: 0.6629619598388672, Accuracy: 0.794921875\n",
            "Batch: 27, Loss: 0.6725199222564697, Accuracy: 0.7802734375\n",
            "Batch: 28, Loss: 0.6423569917678833, Accuracy: 0.8095703125\n",
            "Batch: 29, Loss: 0.7125521898269653, Accuracy: 0.78515625\n",
            "TEST Loss: 1.210999846458435, Accuracy: 0.666015625\n",
            "Batch: 31, Loss: 0.7095859050750732, Accuracy: 0.775390625\n",
            "Batch: 32, Loss: 0.6703675985336304, Accuracy: 0.798828125\n",
            "Batch: 33, Loss: 0.6561703681945801, Accuracy: 0.80078125\n",
            "Batch: 34, Loss: 0.7572241425514221, Accuracy: 0.7470703125\n",
            "TEST Loss: 0.9558347463607788, Accuracy: 0.7197265625\n",
            "Batch: 36, Loss: 0.6269832253456116, Accuracy: 0.818359375\n",
            "Batch: 37, Loss: 0.6496177911758423, Accuracy: 0.806640625\n",
            "Epoch 37/100\n",
            "Batch: 1, Loss: 0.8034157156944275, Accuracy: 0.771484375\n",
            "Batch: 2, Loss: 0.7084020972251892, Accuracy: 0.783203125\n",
            "Batch: 3, Loss: 0.8215466737747192, Accuracy: 0.7373046875\n",
            "Batch: 4, Loss: 0.6947015523910522, Accuracy: 0.783203125\n",
            "TEST Loss: 1.3220229148864746, Accuracy: 0.6357421875\n",
            "Batch: 6, Loss: 0.7119320631027222, Accuracy: 0.7666015625\n",
            "Batch: 7, Loss: 0.6472281217575073, Accuracy: 0.7919921875\n",
            "Batch: 8, Loss: 0.6997143030166626, Accuracy: 0.783203125\n",
            "Batch: 9, Loss: 0.7220088243484497, Accuracy: 0.7822265625\n",
            "TEST Loss: 1.2404390573501587, Accuracy: 0.669921875\n",
            "Batch: 11, Loss: 0.7540713548660278, Accuracy: 0.7568359375\n",
            "Batch: 12, Loss: 0.6816478967666626, Accuracy: 0.77734375\n",
            "Batch: 13, Loss: 0.6278605461120605, Accuracy: 0.814453125\n",
            "Batch: 14, Loss: 0.6543047428131104, Accuracy: 0.7919921875\n",
            "TEST Loss: 1.1984553337097168, Accuracy: 0.6845703125\n",
            "Batch: 16, Loss: 0.655001163482666, Accuracy: 0.806640625\n",
            "Batch: 17, Loss: 0.7961845397949219, Accuracy: 0.755859375\n",
            "Batch: 18, Loss: 0.8071811199188232, Accuracy: 0.744140625\n",
            "Batch: 19, Loss: 0.6772703528404236, Accuracy: 0.7802734375\n",
            "TEST Loss: 1.4530047178268433, Accuracy: 0.6171875\n",
            "Batch: 21, Loss: 0.649956226348877, Accuracy: 0.7978515625\n",
            "Batch: 22, Loss: 0.7331225872039795, Accuracy: 0.775390625\n",
            "Batch: 23, Loss: 0.7731156349182129, Accuracy: 0.7578125\n",
            "Batch: 24, Loss: 0.7571602463722229, Accuracy: 0.75390625\n",
            "TEST Loss: 1.4972931146621704, Accuracy: 0.6005859375\n",
            "Batch: 26, Loss: 0.654427707195282, Accuracy: 0.80078125\n",
            "Batch: 27, Loss: 0.6309148073196411, Accuracy: 0.8037109375\n",
            "Batch: 28, Loss: 0.6473286151885986, Accuracy: 0.80078125\n",
            "Batch: 29, Loss: 0.6844816207885742, Accuracy: 0.7763671875\n",
            "TEST Loss: 1.1839205026626587, Accuracy: 0.669921875\n",
            "Batch: 31, Loss: 0.678124189376831, Accuracy: 0.7978515625\n",
            "Batch: 32, Loss: 0.5761618614196777, Accuracy: 0.83203125\n",
            "Batch: 33, Loss: 0.6190601587295532, Accuracy: 0.802734375\n",
            "Batch: 34, Loss: 0.7158951759338379, Accuracy: 0.7626953125\n",
            "TEST Loss: 0.9548981189727783, Accuracy: 0.7255859375\n",
            "Batch: 36, Loss: 0.6603343486785889, Accuracy: 0.7841796875\n",
            "Batch: 37, Loss: 0.6952841877937317, Accuracy: 0.7890625\n",
            "Epoch 38/100\n",
            "Batch: 1, Loss: 0.8189383745193481, Accuracy: 0.7666015625\n",
            "Batch: 2, Loss: 0.6608806252479553, Accuracy: 0.802734375\n",
            "Batch: 3, Loss: 0.7288738489151001, Accuracy: 0.767578125\n",
            "Batch: 4, Loss: 0.7124369144439697, Accuracy: 0.7802734375\n",
            "TEST Loss: 1.3341941833496094, Accuracy: 0.6240234375\n",
            "Batch: 6, Loss: 0.6957265138626099, Accuracy: 0.7783203125\n",
            "Batch: 7, Loss: 0.6748287677764893, Accuracy: 0.783203125\n",
            "Batch: 8, Loss: 0.6909584999084473, Accuracy: 0.794921875\n",
            "Batch: 9, Loss: 0.691004753112793, Accuracy: 0.783203125\n",
            "TEST Loss: 1.1963472366333008, Accuracy: 0.685546875\n",
            "Batch: 11, Loss: 0.766616702079773, Accuracy: 0.755859375\n",
            "Batch: 12, Loss: 0.6718560457229614, Accuracy: 0.7705078125\n",
            "Batch: 13, Loss: 0.6049778461456299, Accuracy: 0.8046875\n",
            "Batch: 14, Loss: 0.629667341709137, Accuracy: 0.7900390625\n",
            "TEST Loss: 1.2051548957824707, Accuracy: 0.6845703125\n",
            "Batch: 16, Loss: 0.6478756666183472, Accuracy: 0.8046875\n",
            "Batch: 17, Loss: 0.751999020576477, Accuracy: 0.76171875\n",
            "Batch: 18, Loss: 0.7992939949035645, Accuracy: 0.744140625\n",
            "Batch: 19, Loss: 0.6724197864532471, Accuracy: 0.78125\n",
            "TEST Loss: 1.480158805847168, Accuracy: 0.619140625\n",
            "Batch: 21, Loss: 0.62112957239151, Accuracy: 0.7939453125\n",
            "Batch: 22, Loss: 0.7034256458282471, Accuracy: 0.77734375\n",
            "Batch: 23, Loss: 0.7180936336517334, Accuracy: 0.7744140625\n",
            "Batch: 24, Loss: 0.7753689289093018, Accuracy: 0.7490234375\n",
            "TEST Loss: 1.4801583290100098, Accuracy: 0.6142578125\n",
            "Batch: 26, Loss: 0.6106952428817749, Accuracy: 0.8046875\n",
            "Batch: 27, Loss: 0.6523271203041077, Accuracy: 0.787109375\n",
            "Batch: 28, Loss: 0.600361704826355, Accuracy: 0.8134765625\n",
            "Batch: 29, Loss: 0.6879132986068726, Accuracy: 0.7880859375\n",
            "TEST Loss: 1.2283580303192139, Accuracy: 0.6640625\n",
            "Batch: 31, Loss: 0.6434689164161682, Accuracy: 0.80078125\n",
            "Batch: 32, Loss: 0.588553786277771, Accuracy: 0.8291015625\n",
            "Batch: 33, Loss: 0.6190469264984131, Accuracy: 0.806640625\n",
            "Batch: 34, Loss: 0.6559298038482666, Accuracy: 0.78515625\n",
            "TEST Loss: 0.9262093305587769, Accuracy: 0.7421875\n",
            "Batch: 36, Loss: 0.5937579274177551, Accuracy: 0.818359375\n",
            "Batch: 37, Loss: 0.6300235390663147, Accuracy: 0.8037109375\n",
            "Epoch 39/100\n",
            "Batch: 1, Loss: 0.7725234031677246, Accuracy: 0.7783203125\n",
            "Batch: 2, Loss: 0.6446762681007385, Accuracy: 0.8046875\n",
            "Batch: 3, Loss: 0.7480055093765259, Accuracy: 0.7587890625\n",
            "Batch: 4, Loss: 0.63597571849823, Accuracy: 0.798828125\n",
            "TEST Loss: 1.3287920951843262, Accuracy: 0.6376953125\n",
            "Batch: 6, Loss: 0.6412361264228821, Accuracy: 0.7978515625\n",
            "Batch: 7, Loss: 0.6379855871200562, Accuracy: 0.7998046875\n",
            "Batch: 8, Loss: 0.6612149477005005, Accuracy: 0.78515625\n",
            "Batch: 9, Loss: 0.6654375791549683, Accuracy: 0.7919921875\n",
            "TEST Loss: 1.22444486618042, Accuracy: 0.6787109375\n",
            "Batch: 11, Loss: 0.7338824272155762, Accuracy: 0.765625\n",
            "Batch: 12, Loss: 0.6332492828369141, Accuracy: 0.802734375\n",
            "Batch: 13, Loss: 0.5927954912185669, Accuracy: 0.814453125\n",
            "Batch: 14, Loss: 0.619228720664978, Accuracy: 0.7880859375\n",
            "TEST Loss: 1.168729543685913, Accuracy: 0.693359375\n",
            "Batch: 16, Loss: 0.6267510056495667, Accuracy: 0.7919921875\n",
            "Batch: 17, Loss: 0.7313370108604431, Accuracy: 0.765625\n",
            "Batch: 18, Loss: 0.7494828701019287, Accuracy: 0.7685546875\n",
            "Batch: 19, Loss: 0.6282811164855957, Accuracy: 0.814453125\n",
            "TEST Loss: 1.489774465560913, Accuracy: 0.62109375\n",
            "Batch: 21, Loss: 0.5845576524734497, Accuracy: 0.8232421875\n",
            "Batch: 22, Loss: 0.6424245834350586, Accuracy: 0.806640625\n",
            "Batch: 23, Loss: 0.7121068835258484, Accuracy: 0.7705078125\n",
            "Batch: 24, Loss: 0.6938178539276123, Accuracy: 0.7822265625\n",
            "TEST Loss: 1.460422396659851, Accuracy: 0.6201171875\n",
            "Batch: 26, Loss: 0.5982098579406738, Accuracy: 0.81640625\n",
            "Batch: 27, Loss: 0.5957556366920471, Accuracy: 0.8037109375\n",
            "Batch: 28, Loss: 0.6020126342773438, Accuracy: 0.8203125\n",
            "Batch: 29, Loss: 0.6359462141990662, Accuracy: 0.810546875\n",
            "TEST Loss: 1.1870397329330444, Accuracy: 0.697265625\n",
            "Batch: 31, Loss: 0.6351420879364014, Accuracy: 0.791015625\n",
            "Batch: 32, Loss: 0.566423237323761, Accuracy: 0.82421875\n",
            "Batch: 33, Loss: 0.6007776260375977, Accuracy: 0.8017578125\n",
            "Batch: 34, Loss: 0.6337493658065796, Accuracy: 0.7841796875\n",
            "TEST Loss: 0.8809442520141602, Accuracy: 0.7470703125\n",
            "Batch: 36, Loss: 0.5549085140228271, Accuracy: 0.806640625\n",
            "Batch: 37, Loss: 0.6035637855529785, Accuracy: 0.810546875\n",
            "Epoch 40/100\n",
            "Batch: 1, Loss: 0.7383821606636047, Accuracy: 0.79296875\n",
            "Batch: 2, Loss: 0.6066931486129761, Accuracy: 0.80078125\n",
            "Batch: 3, Loss: 0.7200241088867188, Accuracy: 0.7724609375\n",
            "Batch: 4, Loss: 0.6044674515724182, Accuracy: 0.8193359375\n",
            "TEST Loss: 1.3605635166168213, Accuracy: 0.638671875\n",
            "Batch: 6, Loss: 0.5806766152381897, Accuracy: 0.8115234375\n",
            "Batch: 7, Loss: 0.5997783541679382, Accuracy: 0.8056640625\n",
            "Batch: 8, Loss: 0.6264007687568665, Accuracy: 0.8134765625\n",
            "Batch: 9, Loss: 0.6210191249847412, Accuracy: 0.802734375\n",
            "TEST Loss: 1.2095695734024048, Accuracy: 0.69140625\n",
            "Batch: 11, Loss: 0.6830534934997559, Accuracy: 0.787109375\n",
            "Batch: 12, Loss: 0.5976934432983398, Accuracy: 0.8203125\n",
            "Batch: 13, Loss: 0.5541365146636963, Accuracy: 0.8271484375\n",
            "Batch: 14, Loss: 0.6133480072021484, Accuracy: 0.7958984375\n",
            "TEST Loss: 1.1061394214630127, Accuracy: 0.7060546875\n",
            "Batch: 16, Loss: 0.5978965759277344, Accuracy: 0.8193359375\n",
            "Batch: 17, Loss: 0.7202898859977722, Accuracy: 0.7744140625\n",
            "Batch: 18, Loss: 0.7212589383125305, Accuracy: 0.7568359375\n",
            "Batch: 19, Loss: 0.6207596063613892, Accuracy: 0.8095703125\n",
            "TEST Loss: 1.43757963180542, Accuracy: 0.634765625\n",
            "Batch: 21, Loss: 0.5512298941612244, Accuracy: 0.8212890625\n",
            "Batch: 22, Loss: 0.6341260671615601, Accuracy: 0.8017578125\n",
            "Batch: 23, Loss: 0.6692839860916138, Accuracy: 0.7900390625\n",
            "Batch: 24, Loss: 0.707998514175415, Accuracy: 0.759765625\n",
            "TEST Loss: 1.406141757965088, Accuracy: 0.638671875\n",
            "Batch: 26, Loss: 0.5630945563316345, Accuracy: 0.8193359375\n",
            "Batch: 27, Loss: 0.5816271305084229, Accuracy: 0.8134765625\n",
            "Batch: 28, Loss: 0.5612846612930298, Accuracy: 0.8251953125\n",
            "Batch: 29, Loss: 0.6059110164642334, Accuracy: 0.8193359375\n",
            "TEST Loss: 1.1740922927856445, Accuracy: 0.7021484375\n",
            "Batch: 31, Loss: 0.5857583284378052, Accuracy: 0.8154296875\n",
            "Batch: 32, Loss: 0.5386931300163269, Accuracy: 0.833984375\n",
            "Batch: 33, Loss: 0.5660626292228699, Accuracy: 0.8212890625\n",
            "Batch: 34, Loss: 0.6423216462135315, Accuracy: 0.794921875\n",
            "TEST Loss: 0.8844171166419983, Accuracy: 0.7548828125\n",
            "Batch: 36, Loss: 0.5481107234954834, Accuracy: 0.826171875\n",
            "Batch: 37, Loss: 0.5536160469055176, Accuracy: 0.8203125\n",
            "Saved Weights at epoch 40 to file Weights_mozart.h5\n",
            "Epoch 41/100\n",
            "Batch: 1, Loss: 0.7345232963562012, Accuracy: 0.7900390625\n",
            "Batch: 2, Loss: 0.5803402662277222, Accuracy: 0.8134765625\n",
            "Batch: 3, Loss: 0.6689052581787109, Accuracy: 0.802734375\n",
            "Batch: 4, Loss: 0.6337507963180542, Accuracy: 0.8017578125\n",
            "TEST Loss: 1.2956292629241943, Accuracy: 0.669921875\n",
            "Batch: 6, Loss: 0.6197918653488159, Accuracy: 0.7880859375\n",
            "Batch: 7, Loss: 0.5595073699951172, Accuracy: 0.82421875\n",
            "Batch: 8, Loss: 0.5673744678497314, Accuracy: 0.8251953125\n",
            "Batch: 9, Loss: 0.6003484725952148, Accuracy: 0.8115234375\n",
            "TEST Loss: 1.1936067342758179, Accuracy: 0.6875\n",
            "Batch: 11, Loss: 0.6715864539146423, Accuracy: 0.78515625\n",
            "Batch: 12, Loss: 0.6093746423721313, Accuracy: 0.81640625\n",
            "Batch: 13, Loss: 0.5147404074668884, Accuracy: 0.84375\n",
            "Batch: 14, Loss: 0.5593675374984741, Accuracy: 0.8349609375\n",
            "TEST Loss: 1.1222407817840576, Accuracy: 0.71875\n",
            "Batch: 16, Loss: 0.542194664478302, Accuracy: 0.8408203125\n",
            "Batch: 17, Loss: 0.6566876173019409, Accuracy: 0.7939453125\n",
            "Batch: 18, Loss: 0.6335391998291016, Accuracy: 0.80078125\n",
            "Batch: 19, Loss: 0.5521697998046875, Accuracy: 0.828125\n",
            "TEST Loss: 1.4150257110595703, Accuracy: 0.63671875\n",
            "Batch: 21, Loss: 0.5943612456321716, Accuracy: 0.80859375\n",
            "Batch: 22, Loss: 0.5714343190193176, Accuracy: 0.822265625\n",
            "Batch: 23, Loss: 0.6573018431663513, Accuracy: 0.791015625\n",
            "Batch: 24, Loss: 0.6319476962089539, Accuracy: 0.79296875\n",
            "TEST Loss: 1.4199656248092651, Accuracy: 0.6416015625\n",
            "Batch: 26, Loss: 0.5323627591133118, Accuracy: 0.8427734375\n",
            "Batch: 27, Loss: 0.5045312643051147, Accuracy: 0.857421875\n",
            "Batch: 28, Loss: 0.5072842240333557, Accuracy: 0.849609375\n",
            "Batch: 29, Loss: 0.5395776629447937, Accuracy: 0.8369140625\n",
            "TEST Loss: 1.1685742139816284, Accuracy: 0.7001953125\n",
            "Batch: 31, Loss: 0.5211555361747742, Accuracy: 0.84375\n",
            "Batch: 32, Loss: 0.5292542576789856, Accuracy: 0.841796875\n",
            "Batch: 33, Loss: 0.5641770362854004, Accuracy: 0.810546875\n",
            "Batch: 34, Loss: 0.5689586400985718, Accuracy: 0.814453125\n",
            "TEST Loss: 0.8466163873672485, Accuracy: 0.7578125\n",
            "Batch: 36, Loss: 0.50857013463974, Accuracy: 0.84375\n",
            "Batch: 37, Loss: 0.5135177373886108, Accuracy: 0.8486328125\n",
            "Epoch 42/100\n",
            "Batch: 1, Loss: 0.6797735691070557, Accuracy: 0.8115234375\n",
            "Batch: 2, Loss: 0.5741500854492188, Accuracy: 0.826171875\n",
            "Batch: 3, Loss: 0.6180926561355591, Accuracy: 0.80859375\n",
            "Batch: 4, Loss: 0.5831190347671509, Accuracy: 0.8291015625\n",
            "TEST Loss: 1.3327922821044922, Accuracy: 0.6533203125\n",
            "Batch: 6, Loss: 0.5703396797180176, Accuracy: 0.822265625\n",
            "Batch: 7, Loss: 0.5538530945777893, Accuracy: 0.806640625\n",
            "Batch: 8, Loss: 0.5445818901062012, Accuracy: 0.8369140625\n",
            "Batch: 9, Loss: 0.5470209121704102, Accuracy: 0.828125\n",
            "TEST Loss: 1.1958086490631104, Accuracy: 0.703125\n",
            "Batch: 11, Loss: 0.5952491760253906, Accuracy: 0.818359375\n",
            "Batch: 12, Loss: 0.5984581708908081, Accuracy: 0.8125\n",
            "Batch: 13, Loss: 0.4984196424484253, Accuracy: 0.841796875\n",
            "Batch: 14, Loss: 0.5437986850738525, Accuracy: 0.818359375\n",
            "TEST Loss: 1.1526455879211426, Accuracy: 0.7197265625\n",
            "Batch: 16, Loss: 0.5333375930786133, Accuracy: 0.841796875\n",
            "Batch: 17, Loss: 0.6323467493057251, Accuracy: 0.810546875\n",
            "Batch: 18, Loss: 0.6083588600158691, Accuracy: 0.81640625\n",
            "Batch: 19, Loss: 0.5191926956176758, Accuracy: 0.845703125\n",
            "TEST Loss: 1.4076658487319946, Accuracy: 0.64453125\n",
            "Batch: 21, Loss: 0.47354090213775635, Accuracy: 0.861328125\n",
            "Batch: 22, Loss: 0.5724081993103027, Accuracy: 0.8173828125\n",
            "Batch: 23, Loss: 0.605873703956604, Accuracy: 0.810546875\n",
            "Batch: 24, Loss: 0.5859624147415161, Accuracy: 0.806640625\n",
            "TEST Loss: 1.390960931777954, Accuracy: 0.640625\n",
            "Batch: 26, Loss: 0.5308741331100464, Accuracy: 0.84375\n",
            "Batch: 27, Loss: 0.4985480308532715, Accuracy: 0.8525390625\n",
            "Batch: 28, Loss: 0.49749234318733215, Accuracy: 0.85546875\n",
            "Batch: 29, Loss: 0.4986446499824524, Accuracy: 0.8408203125\n",
            "TEST Loss: 1.095220923423767, Accuracy: 0.7099609375\n",
            "Batch: 31, Loss: 0.5104997158050537, Accuracy: 0.849609375\n",
            "Batch: 32, Loss: 0.45976948738098145, Accuracy: 0.8662109375\n",
            "Batch: 33, Loss: 0.48511040210723877, Accuracy: 0.8427734375\n",
            "Batch: 34, Loss: 0.5588757991790771, Accuracy: 0.8291015625\n",
            "TEST Loss: 0.8031364679336548, Accuracy: 0.78125\n",
            "Batch: 36, Loss: 0.47608649730682373, Accuracy: 0.8544921875\n",
            "Batch: 37, Loss: 0.46861234307289124, Accuracy: 0.859375\n",
            "Epoch 43/100\n",
            "Batch: 1, Loss: 0.6368659734725952, Accuracy: 0.8193359375\n",
            "Batch: 2, Loss: 0.520174503326416, Accuracy: 0.837890625\n",
            "Batch: 3, Loss: 0.6026079654693604, Accuracy: 0.830078125\n",
            "Batch: 4, Loss: 0.5056437253952026, Accuracy: 0.849609375\n",
            "TEST Loss: 1.3077131509780884, Accuracy: 0.666015625\n",
            "Batch: 6, Loss: 0.5168477296829224, Accuracy: 0.830078125\n",
            "Batch: 7, Loss: 0.49254411458969116, Accuracy: 0.8427734375\n",
            "Batch: 8, Loss: 0.5209476947784424, Accuracy: 0.83984375\n",
            "Batch: 9, Loss: 0.5277467370033264, Accuracy: 0.833984375\n",
            "TEST Loss: 1.18565833568573, Accuracy: 0.7216796875\n",
            "Batch: 11, Loss: 0.6028681993484497, Accuracy: 0.8056640625\n",
            "Batch: 12, Loss: 0.5599299669265747, Accuracy: 0.83203125\n",
            "Batch: 13, Loss: 0.5052295923233032, Accuracy: 0.84765625\n",
            "Batch: 14, Loss: 0.5138070583343506, Accuracy: 0.828125\n",
            "TEST Loss: 1.1116870641708374, Accuracy: 0.736328125\n",
            "Batch: 16, Loss: 0.4583503305912018, Accuracy: 0.87890625\n",
            "Batch: 17, Loss: 0.619813859462738, Accuracy: 0.80078125\n",
            "Batch: 18, Loss: 0.595697283744812, Accuracy: 0.8125\n",
            "Batch: 19, Loss: 0.5138205885887146, Accuracy: 0.841796875\n",
            "TEST Loss: 1.3970451354980469, Accuracy: 0.654296875\n",
            "Batch: 21, Loss: 0.4781079888343811, Accuracy: 0.8525390625\n",
            "Batch: 22, Loss: 0.5557560920715332, Accuracy: 0.8330078125\n",
            "Batch: 23, Loss: 0.5522276163101196, Accuracy: 0.8330078125\n",
            "Batch: 24, Loss: 0.5344152450561523, Accuracy: 0.826171875\n",
            "TEST Loss: 1.367633581161499, Accuracy: 0.65625\n",
            "Batch: 26, Loss: 0.5268598198890686, Accuracy: 0.8330078125\n",
            "Batch: 27, Loss: 0.4466242790222168, Accuracy: 0.861328125\n",
            "Batch: 28, Loss: 0.4801677465438843, Accuracy: 0.8505859375\n",
            "Batch: 29, Loss: 0.4708809554576874, Accuracy: 0.8671875\n",
            "TEST Loss: 1.0990982055664062, Accuracy: 0.724609375\n",
            "Batch: 31, Loss: 0.4940785765647888, Accuracy: 0.8447265625\n",
            "Batch: 32, Loss: 0.45899155735969543, Accuracy: 0.8544921875\n",
            "Batch: 33, Loss: 0.4681122601032257, Accuracy: 0.8603515625\n",
            "Batch: 34, Loss: 0.5621175765991211, Accuracy: 0.8251953125\n",
            "TEST Loss: 0.7725381851196289, Accuracy: 0.7919921875\n",
            "Batch: 36, Loss: 0.44702768325805664, Accuracy: 0.8623046875\n",
            "Batch: 37, Loss: 0.45409396290779114, Accuracy: 0.849609375\n",
            "Epoch 44/100\n",
            "Batch: 1, Loss: 0.5854504704475403, Accuracy: 0.826171875\n",
            "Batch: 2, Loss: 0.48303741216659546, Accuracy: 0.8486328125\n",
            "Batch: 3, Loss: 0.5660824775695801, Accuracy: 0.8310546875\n",
            "Batch: 4, Loss: 0.4765717387199402, Accuracy: 0.8525390625\n",
            "TEST Loss: 1.2987427711486816, Accuracy: 0.6767578125\n",
            "Batch: 6, Loss: 0.5136856436729431, Accuracy: 0.8310546875\n",
            "Batch: 7, Loss: 0.46701133251190186, Accuracy: 0.8505859375\n",
            "Batch: 8, Loss: 0.5182772874832153, Accuracy: 0.8408203125\n",
            "Batch: 9, Loss: 0.5243126749992371, Accuracy: 0.8271484375\n",
            "TEST Loss: 1.171608567237854, Accuracy: 0.7177734375\n",
            "Batch: 11, Loss: 0.5549643635749817, Accuracy: 0.818359375\n",
            "Batch: 12, Loss: 0.5028538703918457, Accuracy: 0.84765625\n",
            "Batch: 13, Loss: 0.4427943229675293, Accuracy: 0.873046875\n",
            "Batch: 14, Loss: 0.5120075941085815, Accuracy: 0.83984375\n",
            "TEST Loss: 1.0784556865692139, Accuracy: 0.7412109375\n",
            "Batch: 16, Loss: 0.4458949863910675, Accuracy: 0.8623046875\n",
            "Batch: 17, Loss: 0.524052619934082, Accuracy: 0.8408203125\n",
            "Batch: 18, Loss: 0.5437084436416626, Accuracy: 0.8359375\n",
            "Batch: 19, Loss: 0.48497551679611206, Accuracy: 0.859375\n",
            "TEST Loss: 1.3821382522583008, Accuracy: 0.6728515625\n",
            "Batch: 21, Loss: 0.44689375162124634, Accuracy: 0.8671875\n",
            "Batch: 22, Loss: 0.5279111862182617, Accuracy: 0.8359375\n",
            "Batch: 23, Loss: 0.5262558460235596, Accuracy: 0.828125\n",
            "Batch: 24, Loss: 0.5712751746177673, Accuracy: 0.8193359375\n",
            "TEST Loss: 1.3753321170806885, Accuracy: 0.6767578125\n",
            "Batch: 26, Loss: 0.49157947301864624, Accuracy: 0.8369140625\n",
            "Batch: 27, Loss: 0.4238158166408539, Accuracy: 0.86328125\n",
            "Batch: 28, Loss: 0.43977123498916626, Accuracy: 0.8603515625\n",
            "Batch: 29, Loss: 0.4571399986743927, Accuracy: 0.8740234375\n",
            "TEST Loss: 1.1136748790740967, Accuracy: 0.732421875\n",
            "Batch: 31, Loss: 0.46858054399490356, Accuracy: 0.873046875\n",
            "Batch: 32, Loss: 0.48210111260414124, Accuracy: 0.8427734375\n",
            "Batch: 33, Loss: 0.459588885307312, Accuracy: 0.8466796875\n",
            "Batch: 34, Loss: 0.4945449233055115, Accuracy: 0.8408203125\n",
            "TEST Loss: 0.7824767827987671, Accuracy: 0.78515625\n",
            "Batch: 36, Loss: 0.4447464942932129, Accuracy: 0.8505859375\n",
            "Batch: 37, Loss: 0.4397592544555664, Accuracy: 0.8662109375\n",
            "Epoch 45/100\n",
            "Batch: 1, Loss: 0.5830164551734924, Accuracy: 0.826171875\n",
            "Batch: 2, Loss: 0.5088209509849548, Accuracy: 0.83984375\n",
            "Batch: 3, Loss: 0.5874813795089722, Accuracy: 0.806640625\n",
            "Batch: 4, Loss: 0.4543799161911011, Accuracy: 0.8583984375\n",
            "TEST Loss: 1.3170053958892822, Accuracy: 0.6806640625\n",
            "Batch: 6, Loss: 0.4915294051170349, Accuracy: 0.83984375\n",
            "Batch: 7, Loss: 0.47398215532302856, Accuracy: 0.8466796875\n",
            "Batch: 8, Loss: 0.4726470112800598, Accuracy: 0.8671875\n",
            "Batch: 9, Loss: 0.4905126690864563, Accuracy: 0.849609375\n",
            "TEST Loss: 1.1491409540176392, Accuracy: 0.7314453125\n",
            "Batch: 11, Loss: 0.5356585383415222, Accuracy: 0.8330078125\n",
            "Batch: 12, Loss: 0.4850393533706665, Accuracy: 0.837890625\n",
            "Batch: 13, Loss: 0.4312978982925415, Accuracy: 0.8671875\n",
            "Batch: 14, Loss: 0.4542652666568756, Accuracy: 0.859375\n",
            "TEST Loss: 1.1350188255310059, Accuracy: 0.736328125\n",
            "Batch: 16, Loss: 0.4696573317050934, Accuracy: 0.8564453125\n",
            "Batch: 17, Loss: 0.555321216583252, Accuracy: 0.8212890625\n",
            "Batch: 18, Loss: 0.5362523794174194, Accuracy: 0.828125\n",
            "Batch: 19, Loss: 0.437746524810791, Accuracy: 0.8671875\n",
            "TEST Loss: 1.4086438417434692, Accuracy: 0.6630859375\n",
            "Batch: 21, Loss: 0.44249504804611206, Accuracy: 0.8701171875\n",
            "Batch: 22, Loss: 0.49493977427482605, Accuracy: 0.8544921875\n",
            "Batch: 23, Loss: 0.5203610062599182, Accuracy: 0.8466796875\n",
            "Batch: 24, Loss: 0.5285306572914124, Accuracy: 0.837890625\n",
            "TEST Loss: 1.3443210124969482, Accuracy: 0.69140625\n",
            "Batch: 26, Loss: 0.45426470041275024, Accuracy: 0.859375\n",
            "Batch: 27, Loss: 0.4186602234840393, Accuracy: 0.873046875\n",
            "Batch: 28, Loss: 0.4325096011161804, Accuracy: 0.865234375\n",
            "Batch: 29, Loss: 0.4444260895252228, Accuracy: 0.8701171875\n",
            "TEST Loss: 1.1083678007125854, Accuracy: 0.73828125\n",
            "Batch: 31, Loss: 0.43975943326950073, Accuracy: 0.861328125\n",
            "Batch: 32, Loss: 0.4411192834377289, Accuracy: 0.873046875\n",
            "Batch: 33, Loss: 0.4692264795303345, Accuracy: 0.84765625\n",
            "Batch: 34, Loss: 0.48473137617111206, Accuracy: 0.8505859375\n",
            "TEST Loss: 0.7867397665977478, Accuracy: 0.779296875\n",
            "Batch: 36, Loss: 0.4092094898223877, Accuracy: 0.876953125\n",
            "Batch: 37, Loss: 0.40739279985427856, Accuracy: 0.8759765625\n",
            "Epoch 46/100\n",
            "Batch: 1, Loss: 0.5065963864326477, Accuracy: 0.8544921875\n",
            "Batch: 2, Loss: 0.4379955530166626, Accuracy: 0.859375\n",
            "Batch: 3, Loss: 0.5415955781936646, Accuracy: 0.8505859375\n",
            "Batch: 4, Loss: 0.45278483629226685, Accuracy: 0.857421875\n",
            "TEST Loss: 1.2953910827636719, Accuracy: 0.6796875\n",
            "Batch: 6, Loss: 0.4790549874305725, Accuracy: 0.83984375\n",
            "Batch: 7, Loss: 0.45726096630096436, Accuracy: 0.8701171875\n",
            "Batch: 8, Loss: 0.45655369758605957, Accuracy: 0.857421875\n",
            "Batch: 9, Loss: 0.49329254031181335, Accuracy: 0.84375\n",
            "TEST Loss: 1.1478209495544434, Accuracy: 0.7373046875\n",
            "Batch: 11, Loss: 0.537574291229248, Accuracy: 0.8291015625\n",
            "Batch: 12, Loss: 0.46892380714416504, Accuracy: 0.8525390625\n",
            "Batch: 13, Loss: 0.4108050465583801, Accuracy: 0.8798828125\n",
            "Batch: 14, Loss: 0.43165069818496704, Accuracy: 0.8671875\n",
            "TEST Loss: 1.0924570560455322, Accuracy: 0.7421875\n",
            "Batch: 16, Loss: 0.42334455251693726, Accuracy: 0.8642578125\n",
            "Batch: 17, Loss: 0.502596378326416, Accuracy: 0.845703125\n",
            "Batch: 18, Loss: 0.5323284864425659, Accuracy: 0.8388671875\n",
            "Batch: 19, Loss: 0.46071696281433105, Accuracy: 0.8564453125\n",
            "TEST Loss: 1.3921152353286743, Accuracy: 0.6767578125\n",
            "Batch: 21, Loss: 0.4310833215713501, Accuracy: 0.853515625\n",
            "Batch: 22, Loss: 0.4845278561115265, Accuracy: 0.8388671875\n",
            "Batch: 23, Loss: 0.5158249139785767, Accuracy: 0.8330078125\n",
            "Batch: 24, Loss: 0.46431663632392883, Accuracy: 0.861328125\n",
            "TEST Loss: 1.3472042083740234, Accuracy: 0.6845703125\n",
            "Batch: 26, Loss: 0.43311572074890137, Accuracy: 0.8642578125\n",
            "Batch: 27, Loss: 0.3714437782764435, Accuracy: 0.8916015625\n",
            "Batch: 28, Loss: 0.40103644132614136, Accuracy: 0.8935546875\n",
            "Batch: 29, Loss: 0.4444785714149475, Accuracy: 0.8759765625\n",
            "TEST Loss: 1.112202525138855, Accuracy: 0.724609375\n",
            "Batch: 31, Loss: 0.40532582998275757, Accuracy: 0.8896484375\n",
            "Batch: 32, Loss: 0.3937269449234009, Accuracy: 0.875\n",
            "Batch: 33, Loss: 0.4381631016731262, Accuracy: 0.8671875\n",
            "Batch: 34, Loss: 0.47460177540779114, Accuracy: 0.845703125\n",
            "TEST Loss: 0.789840579032898, Accuracy: 0.791015625\n",
            "Batch: 36, Loss: 0.38910791277885437, Accuracy: 0.8779296875\n",
            "Batch: 37, Loss: 0.4111849069595337, Accuracy: 0.8759765625\n",
            "Epoch 47/100\n",
            "Batch: 1, Loss: 0.5106911659240723, Accuracy: 0.84375\n",
            "Batch: 2, Loss: 0.42187219858169556, Accuracy: 0.8720703125\n",
            "Batch: 3, Loss: 0.5380057096481323, Accuracy: 0.8466796875\n",
            "Batch: 4, Loss: 0.4205295443534851, Accuracy: 0.8740234375\n",
            "TEST Loss: 1.342648983001709, Accuracy: 0.6640625\n",
            "Batch: 6, Loss: 0.4803272485733032, Accuracy: 0.8447265625\n",
            "Batch: 7, Loss: 0.43698859214782715, Accuracy: 0.8564453125\n",
            "Batch: 8, Loss: 0.4337782561779022, Accuracy: 0.8720703125\n",
            "Batch: 9, Loss: 0.48059821128845215, Accuracy: 0.8447265625\n",
            "TEST Loss: 1.135071039199829, Accuracy: 0.734375\n",
            "Batch: 11, Loss: 0.48154911398887634, Accuracy: 0.8486328125\n",
            "Batch: 12, Loss: 0.45945554971694946, Accuracy: 0.8564453125\n",
            "Batch: 13, Loss: 0.4128423035144806, Accuracy: 0.8642578125\n",
            "Batch: 14, Loss: 0.4423242211341858, Accuracy: 0.861328125\n",
            "TEST Loss: 1.1132758855819702, Accuracy: 0.75390625\n",
            "Batch: 16, Loss: 0.40972504019737244, Accuracy: 0.8896484375\n",
            "Batch: 17, Loss: 0.4890556335449219, Accuracy: 0.84375\n",
            "Batch: 18, Loss: 0.5381029844284058, Accuracy: 0.83203125\n",
            "Batch: 19, Loss: 0.4691471755504608, Accuracy: 0.861328125\n",
            "TEST Loss: 1.3685088157653809, Accuracy: 0.6982421875\n",
            "Batch: 21, Loss: 0.40048325061798096, Accuracy: 0.8828125\n",
            "Batch: 22, Loss: 0.45983800292015076, Accuracy: 0.849609375\n",
            "Batch: 23, Loss: 0.4805856943130493, Accuracy: 0.857421875\n",
            "Batch: 24, Loss: 0.5012446045875549, Accuracy: 0.841796875\n",
            "TEST Loss: 1.3918077945709229, Accuracy: 0.6748046875\n",
            "Batch: 26, Loss: 0.45639634132385254, Accuracy: 0.8662109375\n",
            "Batch: 27, Loss: 0.37802672386169434, Accuracy: 0.8740234375\n",
            "Batch: 28, Loss: 0.3630916476249695, Accuracy: 0.8955078125\n",
            "Batch: 29, Loss: 0.3979378044605255, Accuracy: 0.8740234375\n",
            "TEST Loss: 1.0717060565948486, Accuracy: 0.7451171875\n",
            "Batch: 31, Loss: 0.41068002581596375, Accuracy: 0.87890625\n",
            "Batch: 32, Loss: 0.355233371257782, Accuracy: 0.890625\n",
            "Batch: 33, Loss: 0.4021167755126953, Accuracy: 0.8759765625\n",
            "Batch: 34, Loss: 0.4539489150047302, Accuracy: 0.869140625\n",
            "TEST Loss: 0.7867109179496765, Accuracy: 0.8056640625\n",
            "Batch: 36, Loss: 0.41932421922683716, Accuracy: 0.873046875\n",
            "Batch: 37, Loss: 0.4082358777523041, Accuracy: 0.8720703125\n",
            "Epoch 48/100\n",
            "Batch: 1, Loss: 0.5355705618858337, Accuracy: 0.8544921875\n",
            "Batch: 2, Loss: 0.427345871925354, Accuracy: 0.8642578125\n",
            "Batch: 3, Loss: 0.5072826147079468, Accuracy: 0.83203125\n",
            "Batch: 4, Loss: 0.41193684935569763, Accuracy: 0.8779296875\n",
            "TEST Loss: 1.2956526279449463, Accuracy: 0.6884765625\n",
            "Batch: 6, Loss: 0.4287921190261841, Accuracy: 0.8681640625\n",
            "Batch: 7, Loss: 0.3968745172023773, Accuracy: 0.890625\n",
            "Batch: 8, Loss: 0.4487478733062744, Accuracy: 0.857421875\n",
            "Batch: 9, Loss: 0.436774879693985, Accuracy: 0.85546875\n",
            "TEST Loss: 1.1481778621673584, Accuracy: 0.73046875\n",
            "Batch: 11, Loss: 0.47616028785705566, Accuracy: 0.845703125\n",
            "Batch: 12, Loss: 0.420135498046875, Accuracy: 0.87109375\n",
            "Batch: 13, Loss: 0.3884398937225342, Accuracy: 0.8798828125\n",
            "Batch: 14, Loss: 0.3910529613494873, Accuracy: 0.876953125\n",
            "TEST Loss: 1.1271185874938965, Accuracy: 0.73828125\n",
            "Batch: 16, Loss: 0.4070588946342468, Accuracy: 0.8798828125\n",
            "Batch: 17, Loss: 0.4695756733417511, Accuracy: 0.853515625\n",
            "Batch: 18, Loss: 0.5264531373977661, Accuracy: 0.8466796875\n",
            "Batch: 19, Loss: 0.4446868896484375, Accuracy: 0.8623046875\n",
            "TEST Loss: 1.4042673110961914, Accuracy: 0.6796875\n",
            "Batch: 21, Loss: 0.3955574631690979, Accuracy: 0.8818359375\n",
            "Batch: 22, Loss: 0.4331148862838745, Accuracy: 0.873046875\n",
            "Batch: 23, Loss: 0.4588162302970886, Accuracy: 0.8544921875\n",
            "Batch: 24, Loss: 0.4360632598400116, Accuracy: 0.8671875\n",
            "TEST Loss: 1.3624169826507568, Accuracy: 0.6865234375\n",
            "Batch: 26, Loss: 0.38060176372528076, Accuracy: 0.8876953125\n",
            "Batch: 27, Loss: 0.3616766333580017, Accuracy: 0.8994140625\n",
            "Batch: 28, Loss: 0.36105385422706604, Accuracy: 0.900390625\n",
            "Batch: 29, Loss: 0.4045617878437042, Accuracy: 0.875\n",
            "TEST Loss: 1.0656871795654297, Accuracy: 0.740234375\n",
            "Batch: 31, Loss: 0.4032261073589325, Accuracy: 0.8916015625\n",
            "Batch: 32, Loss: 0.3866037130355835, Accuracy: 0.8984375\n",
            "Batch: 33, Loss: 0.399189293384552, Accuracy: 0.87890625\n",
            "Batch: 34, Loss: 0.4410134553909302, Accuracy: 0.8662109375\n",
            "TEST Loss: 0.7740683555603027, Accuracy: 0.7998046875\n",
            "Batch: 36, Loss: 0.36146220564842224, Accuracy: 0.8828125\n",
            "Batch: 37, Loss: 0.40295690298080444, Accuracy: 0.8740234375\n",
            "Epoch 49/100\n",
            "Batch: 1, Loss: 0.5307865142822266, Accuracy: 0.845703125\n",
            "Batch: 2, Loss: 0.400202214717865, Accuracy: 0.861328125\n",
            "Batch: 3, Loss: 0.4292869567871094, Accuracy: 0.8828125\n",
            "Batch: 4, Loss: 0.4103427231311798, Accuracy: 0.8876953125\n",
            "TEST Loss: 1.3144687414169312, Accuracy: 0.6904296875\n",
            "Batch: 6, Loss: 0.4046740233898163, Accuracy: 0.8701171875\n",
            "Batch: 7, Loss: 0.41181284189224243, Accuracy: 0.8662109375\n",
            "Batch: 8, Loss: 0.42319533228874207, Accuracy: 0.86328125\n",
            "Batch: 9, Loss: 0.4363837242126465, Accuracy: 0.8642578125\n",
            "TEST Loss: 1.1177465915679932, Accuracy: 0.736328125\n",
            "Batch: 11, Loss: 0.4712563753128052, Accuracy: 0.85546875\n",
            "Batch: 12, Loss: 0.4040340781211853, Accuracy: 0.875\n",
            "Batch: 13, Loss: 0.35911503434181213, Accuracy: 0.890625\n",
            "Batch: 14, Loss: 0.39540374279022217, Accuracy: 0.86328125\n",
            "TEST Loss: 1.0821079015731812, Accuracy: 0.76171875\n",
            "Batch: 16, Loss: 0.3860644996166229, Accuracy: 0.890625\n",
            "Batch: 17, Loss: 0.44321274757385254, Accuracy: 0.8662109375\n",
            "Batch: 18, Loss: 0.4733951687812805, Accuracy: 0.85546875\n",
            "Batch: 19, Loss: 0.4299202561378479, Accuracy: 0.8701171875\n",
            "TEST Loss: 1.3875670433044434, Accuracy: 0.693359375\n",
            "Batch: 21, Loss: 0.3981582820415497, Accuracy: 0.873046875\n",
            "Batch: 22, Loss: 0.40429574251174927, Accuracy: 0.880859375\n",
            "Batch: 23, Loss: 0.4509998559951782, Accuracy: 0.8525390625\n",
            "Batch: 24, Loss: 0.4501386284828186, Accuracy: 0.86328125\n",
            "TEST Loss: 1.353724718093872, Accuracy: 0.6962890625\n",
            "Batch: 26, Loss: 0.3701876401901245, Accuracy: 0.90234375\n",
            "Batch: 27, Loss: 0.35214006900787354, Accuracy: 0.900390625\n",
            "Batch: 28, Loss: 0.37461036443710327, Accuracy: 0.8857421875\n",
            "Batch: 29, Loss: 0.3733406066894531, Accuracy: 0.8935546875\n",
            "TEST Loss: 1.0891132354736328, Accuracy: 0.7578125\n",
            "Batch: 31, Loss: 0.392002135515213, Accuracy: 0.8779296875\n",
            "Batch: 32, Loss: 0.3387637734413147, Accuracy: 0.90625\n",
            "Batch: 33, Loss: 0.35132235288619995, Accuracy: 0.890625\n",
            "Batch: 34, Loss: 0.4219130873680115, Accuracy: 0.8681640625\n",
            "TEST Loss: 0.785565972328186, Accuracy: 0.796875\n",
            "Batch: 36, Loss: 0.33130529522895813, Accuracy: 0.892578125\n",
            "Batch: 37, Loss: 0.35974371433258057, Accuracy: 0.888671875\n",
            "Epoch 50/100\n",
            "Batch: 1, Loss: 0.4769318401813507, Accuracy: 0.857421875\n",
            "Batch: 2, Loss: 0.3871963918209076, Accuracy: 0.873046875\n",
            "Batch: 3, Loss: 0.4362463653087616, Accuracy: 0.875\n",
            "Batch: 4, Loss: 0.35352107882499695, Accuracy: 0.896484375\n",
            "TEST Loss: 1.337255835533142, Accuracy: 0.67578125\n",
            "Batch: 6, Loss: 0.4275909662246704, Accuracy: 0.8701171875\n",
            "Batch: 7, Loss: 0.39644378423690796, Accuracy: 0.8720703125\n",
            "Batch: 8, Loss: 0.3723691701889038, Accuracy: 0.8896484375\n",
            "Batch: 9, Loss: 0.4184451103210449, Accuracy: 0.87109375\n",
            "TEST Loss: 1.1492953300476074, Accuracy: 0.71875\n",
            "Batch: 11, Loss: 0.44761568307876587, Accuracy: 0.8525390625\n",
            "Batch: 12, Loss: 0.41542401909828186, Accuracy: 0.8623046875\n",
            "Batch: 13, Loss: 0.3546507954597473, Accuracy: 0.8828125\n",
            "Batch: 14, Loss: 0.37219613790512085, Accuracy: 0.880859375\n",
            "TEST Loss: 1.0465162992477417, Accuracy: 0.767578125\n",
            "Batch: 16, Loss: 0.38284072279930115, Accuracy: 0.8779296875\n",
            "Batch: 17, Loss: 0.44843465089797974, Accuracy: 0.859375\n",
            "Batch: 18, Loss: 0.4587467908859253, Accuracy: 0.8544921875\n",
            "Batch: 19, Loss: 0.3731006383895874, Accuracy: 0.8837890625\n",
            "TEST Loss: 1.3652465343475342, Accuracy: 0.703125\n",
            "Batch: 21, Loss: 0.3300541639328003, Accuracy: 0.8955078125\n",
            "Batch: 22, Loss: 0.4101928472518921, Accuracy: 0.8798828125\n",
            "Batch: 23, Loss: 0.4214944541454315, Accuracy: 0.87890625\n",
            "Batch: 24, Loss: 0.4205120801925659, Accuracy: 0.8662109375\n",
            "TEST Loss: 1.3583911657333374, Accuracy: 0.69140625\n",
            "Batch: 26, Loss: 0.3524971008300781, Accuracy: 0.896484375\n",
            "Batch: 27, Loss: 0.3367438316345215, Accuracy: 0.9052734375\n",
            "Batch: 28, Loss: 0.34572526812553406, Accuracy: 0.9052734375\n",
            "Batch: 29, Loss: 0.35858964920043945, Accuracy: 0.9013671875\n",
            "TEST Loss: 1.0435810089111328, Accuracy: 0.763671875\n",
            "Batch: 31, Loss: 0.3533218502998352, Accuracy: 0.8876953125\n",
            "Batch: 32, Loss: 0.3162814676761627, Accuracy: 0.9189453125\n",
            "Batch: 33, Loss: 0.36405932903289795, Accuracy: 0.8740234375\n",
            "Batch: 34, Loss: 0.3925560414791107, Accuracy: 0.88671875\n",
            "TEST Loss: 0.7621009349822998, Accuracy: 0.810546875\n",
            "Batch: 36, Loss: 0.32779553532600403, Accuracy: 0.8994140625\n",
            "Batch: 37, Loss: 0.3478326201438904, Accuracy: 0.8955078125\n",
            "Saved Weights at epoch 50 to file Weights_mozart.h5\n",
            "Epoch 51/100\n",
            "Batch: 1, Loss: 0.43929487466812134, Accuracy: 0.8798828125\n",
            "Batch: 2, Loss: 0.3776978850364685, Accuracy: 0.8759765625\n",
            "Batch: 3, Loss: 0.4218367636203766, Accuracy: 0.8720703125\n",
            "Batch: 4, Loss: 0.34623628854751587, Accuracy: 0.9033203125\n",
            "TEST Loss: 1.348897933959961, Accuracy: 0.689453125\n",
            "Batch: 6, Loss: 0.38662582635879517, Accuracy: 0.873046875\n",
            "Batch: 7, Loss: 0.3600902557373047, Accuracy: 0.8916015625\n",
            "Batch: 8, Loss: 0.3968895375728607, Accuracy: 0.87109375\n",
            "Batch: 9, Loss: 0.4081841707229614, Accuracy: 0.8603515625\n",
            "TEST Loss: 1.1599526405334473, Accuracy: 0.7392578125\n",
            "Batch: 11, Loss: 0.43239712715148926, Accuracy: 0.859375\n",
            "Batch: 12, Loss: 0.42904090881347656, Accuracy: 0.8603515625\n",
            "Batch: 13, Loss: 0.3475204110145569, Accuracy: 0.89453125\n",
            "Batch: 14, Loss: 0.3582588732242584, Accuracy: 0.888671875\n",
            "TEST Loss: 1.040888786315918, Accuracy: 0.77734375\n",
            "Batch: 16, Loss: 0.3105353116989136, Accuracy: 0.9189453125\n",
            "Batch: 17, Loss: 0.41818928718566895, Accuracy: 0.87890625\n",
            "Batch: 18, Loss: 0.42317163944244385, Accuracy: 0.8564453125\n",
            "Batch: 19, Loss: 0.37967124581336975, Accuracy: 0.89453125\n",
            "TEST Loss: 1.363501787185669, Accuracy: 0.7060546875\n",
            "Batch: 21, Loss: 0.30237311124801636, Accuracy: 0.90234375\n",
            "Batch: 22, Loss: 0.35863369703292847, Accuracy: 0.8955078125\n",
            "Batch: 23, Loss: 0.4203643202781677, Accuracy: 0.8720703125\n",
            "Batch: 24, Loss: 0.42159754037857056, Accuracy: 0.880859375\n",
            "TEST Loss: 1.366025686264038, Accuracy: 0.7138671875\n",
            "Batch: 26, Loss: 0.35493552684783936, Accuracy: 0.8857421875\n",
            "Batch: 27, Loss: 0.33920806646347046, Accuracy: 0.8955078125\n",
            "Batch: 28, Loss: 0.3183915317058563, Accuracy: 0.900390625\n",
            "Batch: 29, Loss: 0.3423568308353424, Accuracy: 0.900390625\n",
            "TEST Loss: 1.0623810291290283, Accuracy: 0.7578125\n",
            "Batch: 31, Loss: 0.387431800365448, Accuracy: 0.8798828125\n",
            "Batch: 32, Loss: 0.345573365688324, Accuracy: 0.904296875\n",
            "Batch: 33, Loss: 0.3525148630142212, Accuracy: 0.89453125\n",
            "Batch: 34, Loss: 0.38856080174446106, Accuracy: 0.876953125\n",
            "TEST Loss: 0.757179856300354, Accuracy: 0.8134765625\n",
            "Batch: 36, Loss: 0.3210686445236206, Accuracy: 0.8984375\n",
            "Batch: 37, Loss: 0.3836454153060913, Accuracy: 0.8642578125\n",
            "Epoch 52/100\n",
            "Batch: 1, Loss: 0.4313634932041168, Accuracy: 0.8740234375\n",
            "Batch: 2, Loss: 0.36973679065704346, Accuracy: 0.8896484375\n",
            "Batch: 3, Loss: 0.4006863236427307, Accuracy: 0.8779296875\n",
            "Batch: 4, Loss: 0.3391241431236267, Accuracy: 0.9013671875\n",
            "TEST Loss: 1.3393023014068604, Accuracy: 0.6806640625\n",
            "Batch: 6, Loss: 0.37316882610321045, Accuracy: 0.8818359375\n",
            "Batch: 7, Loss: 0.36748719215393066, Accuracy: 0.8876953125\n",
            "Batch: 8, Loss: 0.365433007478714, Accuracy: 0.880859375\n",
            "Batch: 9, Loss: 0.38774529099464417, Accuracy: 0.876953125\n",
            "TEST Loss: 1.1323652267456055, Accuracy: 0.75\n",
            "Batch: 11, Loss: 0.437347948551178, Accuracy: 0.873046875\n",
            "Batch: 12, Loss: 0.38056570291519165, Accuracy: 0.888671875\n",
            "Batch: 13, Loss: 0.3152211308479309, Accuracy: 0.9052734375\n",
            "Batch: 14, Loss: 0.37288349866867065, Accuracy: 0.876953125\n",
            "TEST Loss: 1.0973304510116577, Accuracy: 0.7578125\n",
            "Batch: 16, Loss: 0.35584405064582825, Accuracy: 0.8935546875\n",
            "Batch: 17, Loss: 0.43653085827827454, Accuracy: 0.87890625\n",
            "Batch: 18, Loss: 0.3905121684074402, Accuracy: 0.87109375\n",
            "Batch: 19, Loss: 0.3599647283554077, Accuracy: 0.8837890625\n",
            "TEST Loss: 1.37981379032135, Accuracy: 0.7041015625\n",
            "Batch: 21, Loss: 0.32017549872398376, Accuracy: 0.9111328125\n",
            "Batch: 22, Loss: 0.3692223131656647, Accuracy: 0.8818359375\n",
            "Batch: 23, Loss: 0.4073386490345001, Accuracy: 0.8720703125\n",
            "Batch: 24, Loss: 0.37301790714263916, Accuracy: 0.880859375\n",
            "TEST Loss: 1.3761190176010132, Accuracy: 0.7177734375\n",
            "Batch: 26, Loss: 0.34312814474105835, Accuracy: 0.9033203125\n",
            "Batch: 27, Loss: 0.3277279734611511, Accuracy: 0.90625\n",
            "Batch: 28, Loss: 0.31240344047546387, Accuracy: 0.90625\n",
            "Batch: 29, Loss: 0.3528122305870056, Accuracy: 0.890625\n",
            "TEST Loss: 1.0163084268569946, Accuracy: 0.76953125\n",
            "Batch: 31, Loss: 0.3053053617477417, Accuracy: 0.9208984375\n",
            "Batch: 32, Loss: 0.297642320394516, Accuracy: 0.9130859375\n",
            "Batch: 33, Loss: 0.34489166736602783, Accuracy: 0.8935546875\n",
            "Batch: 34, Loss: 0.4139995276927948, Accuracy: 0.861328125\n",
            "TEST Loss: 0.7526085376739502, Accuracy: 0.8017578125\n",
            "Batch: 36, Loss: 0.3410852551460266, Accuracy: 0.8974609375\n",
            "Batch: 37, Loss: 0.31410109996795654, Accuracy: 0.8974609375\n",
            "Epoch 53/100\n",
            "Batch: 1, Loss: 0.425950825214386, Accuracy: 0.87109375\n",
            "Batch: 2, Loss: 0.3286236524581909, Accuracy: 0.89453125\n",
            "Batch: 3, Loss: 0.4123442769050598, Accuracy: 0.869140625\n",
            "Batch: 4, Loss: 0.3155803084373474, Accuracy: 0.9189453125\n",
            "TEST Loss: 1.4037532806396484, Accuracy: 0.6875\n",
            "Batch: 6, Loss: 0.40157032012939453, Accuracy: 0.8759765625\n",
            "Batch: 7, Loss: 0.3168913424015045, Accuracy: 0.90625\n",
            "Batch: 8, Loss: 0.370898962020874, Accuracy: 0.876953125\n",
            "Batch: 9, Loss: 0.3545794188976288, Accuracy: 0.88671875\n",
            "TEST Loss: 1.1250001192092896, Accuracy: 0.7509765625\n",
            "Batch: 11, Loss: 0.41048043966293335, Accuracy: 0.8662109375\n",
            "Batch: 12, Loss: 0.37758708000183105, Accuracy: 0.892578125\n",
            "Batch: 13, Loss: 0.31087934970855713, Accuracy: 0.900390625\n",
            "Batch: 14, Loss: 0.33768323063850403, Accuracy: 0.8916015625\n",
            "TEST Loss: 1.0477192401885986, Accuracy: 0.7900390625\n",
            "Batch: 16, Loss: 0.3062314987182617, Accuracy: 0.9072265625\n",
            "Batch: 17, Loss: 0.37616196274757385, Accuracy: 0.88671875\n",
            "Batch: 18, Loss: 0.3719836473464966, Accuracy: 0.8955078125\n",
            "Batch: 19, Loss: 0.33105871081352234, Accuracy: 0.892578125\n",
            "TEST Loss: 1.361953854560852, Accuracy: 0.7216796875\n",
            "Batch: 21, Loss: 0.31878662109375, Accuracy: 0.9208984375\n",
            "Batch: 22, Loss: 0.36686402559280396, Accuracy: 0.884765625\n",
            "Batch: 23, Loss: 0.38326382637023926, Accuracy: 0.8798828125\n",
            "Batch: 24, Loss: 0.39798659086227417, Accuracy: 0.8720703125\n",
            "TEST Loss: 1.3314518928527832, Accuracy: 0.71484375\n",
            "Batch: 26, Loss: 0.2947641611099243, Accuracy: 0.9091796875\n",
            "Batch: 27, Loss: 0.27800488471984863, Accuracy: 0.9228515625\n",
            "Batch: 28, Loss: 0.3143186569213867, Accuracy: 0.900390625\n",
            "Batch: 29, Loss: 0.3191222548484802, Accuracy: 0.904296875\n",
            "TEST Loss: 1.1046555042266846, Accuracy: 0.7646484375\n",
            "Batch: 31, Loss: 0.3204943537712097, Accuracy: 0.9013671875\n",
            "Batch: 32, Loss: 0.31614023447036743, Accuracy: 0.9111328125\n",
            "Batch: 33, Loss: 0.32106301188468933, Accuracy: 0.896484375\n",
            "Batch: 34, Loss: 0.34627872705459595, Accuracy: 0.8896484375\n",
            "TEST Loss: 0.7385464310646057, Accuracy: 0.81640625\n",
            "Batch: 36, Loss: 0.30852675437927246, Accuracy: 0.900390625\n",
            "Batch: 37, Loss: 0.30204272270202637, Accuracy: 0.9091796875\n",
            "Epoch 54/100\n",
            "Batch: 1, Loss: 0.43409228324890137, Accuracy: 0.8720703125\n",
            "Batch: 2, Loss: 0.33918237686157227, Accuracy: 0.890625\n",
            "Batch: 3, Loss: 0.39820414781570435, Accuracy: 0.880859375\n",
            "Batch: 4, Loss: 0.30932140350341797, Accuracy: 0.912109375\n",
            "TEST Loss: 1.3078770637512207, Accuracy: 0.69921875\n",
            "Batch: 6, Loss: 0.359175443649292, Accuracy: 0.88671875\n",
            "Batch: 7, Loss: 0.3188765347003937, Accuracy: 0.904296875\n",
            "Batch: 8, Loss: 0.33982282876968384, Accuracy: 0.8916015625\n",
            "Batch: 9, Loss: 0.37837034463882446, Accuracy: 0.8818359375\n",
            "TEST Loss: 1.1286135911941528, Accuracy: 0.75\n",
            "Batch: 11, Loss: 0.4358205199241638, Accuracy: 0.8447265625\n",
            "Batch: 12, Loss: 0.3421233892440796, Accuracy: 0.890625\n",
            "Batch: 13, Loss: 0.28413957357406616, Accuracy: 0.9072265625\n",
            "Batch: 14, Loss: 0.30763888359069824, Accuracy: 0.904296875\n",
            "TEST Loss: 1.0810115337371826, Accuracy: 0.791015625\n",
            "Batch: 16, Loss: 0.3112636208534241, Accuracy: 0.912109375\n",
            "Batch: 17, Loss: 0.38325658440589905, Accuracy: 0.8828125\n",
            "Batch: 18, Loss: 0.36041587591171265, Accuracy: 0.8759765625\n",
            "Batch: 19, Loss: 0.31335335969924927, Accuracy: 0.9033203125\n",
            "TEST Loss: 1.418962836265564, Accuracy: 0.7021484375\n",
            "Batch: 21, Loss: 0.31565994024276733, Accuracy: 0.90625\n",
            "Batch: 22, Loss: 0.36725518107414246, Accuracy: 0.8798828125\n",
            "Batch: 23, Loss: 0.3690548837184906, Accuracy: 0.880859375\n",
            "Batch: 24, Loss: 0.3559867739677429, Accuracy: 0.89453125\n",
            "TEST Loss: 1.3759063482284546, Accuracy: 0.7080078125\n",
            "Batch: 26, Loss: 0.3488765060901642, Accuracy: 0.888671875\n",
            "Batch: 27, Loss: 0.2516505718231201, Accuracy: 0.9296875\n",
            "Batch: 28, Loss: 0.33451181650161743, Accuracy: 0.8876953125\n",
            "Batch: 29, Loss: 0.3310279846191406, Accuracy: 0.904296875\n",
            "TEST Loss: 1.043570876121521, Accuracy: 0.7880859375\n",
            "Batch: 31, Loss: 0.299471914768219, Accuracy: 0.9072265625\n",
            "Batch: 32, Loss: 0.27546995878219604, Accuracy: 0.921875\n",
            "Batch: 33, Loss: 0.29994529485702515, Accuracy: 0.9072265625\n",
            "Batch: 34, Loss: 0.37584471702575684, Accuracy: 0.8916015625\n",
            "TEST Loss: 0.7494969367980957, Accuracy: 0.814453125\n",
            "Batch: 36, Loss: 0.3203611373901367, Accuracy: 0.8984375\n",
            "Batch: 37, Loss: 0.32745182514190674, Accuracy: 0.900390625\n",
            "Epoch 55/100\n",
            "Batch: 1, Loss: 0.4045575261116028, Accuracy: 0.884765625\n",
            "Batch: 2, Loss: 0.31727439165115356, Accuracy: 0.8994140625\n",
            "Batch: 3, Loss: 0.3671794533729553, Accuracy: 0.890625\n",
            "Batch: 4, Loss: 0.33261966705322266, Accuracy: 0.8935546875\n",
            "TEST Loss: 1.3692023754119873, Accuracy: 0.689453125\n",
            "Batch: 6, Loss: 0.34184831380844116, Accuracy: 0.884765625\n",
            "Batch: 7, Loss: 0.3041459023952484, Accuracy: 0.9033203125\n",
            "Batch: 8, Loss: 0.32462605834007263, Accuracy: 0.90234375\n",
            "Batch: 9, Loss: 0.33371371030807495, Accuracy: 0.8984375\n",
            "TEST Loss: 1.1243994235992432, Accuracy: 0.7548828125\n",
            "Batch: 11, Loss: 0.3911052346229553, Accuracy: 0.8798828125\n",
            "Batch: 12, Loss: 0.34003233909606934, Accuracy: 0.89453125\n",
            "Batch: 13, Loss: 0.28698021173477173, Accuracy: 0.916015625\n",
            "Batch: 14, Loss: 0.2997918426990509, Accuracy: 0.90625\n",
            "TEST Loss: 1.0957565307617188, Accuracy: 0.771484375\n",
            "Batch: 16, Loss: 0.3004568815231323, Accuracy: 0.904296875\n",
            "Batch: 17, Loss: 0.35230928659439087, Accuracy: 0.8857421875\n",
            "Batch: 18, Loss: 0.342875599861145, Accuracy: 0.8974609375\n",
            "Batch: 19, Loss: 0.31345388293266296, Accuracy: 0.91015625\n",
            "TEST Loss: 1.36444890499115, Accuracy: 0.7373046875\n",
            "Batch: 21, Loss: 0.3005557060241699, Accuracy: 0.908203125\n",
            "Batch: 22, Loss: 0.317754328250885, Accuracy: 0.8994140625\n",
            "Batch: 23, Loss: 0.36043161153793335, Accuracy: 0.888671875\n",
            "Batch: 24, Loss: 0.3724486827850342, Accuracy: 0.8896484375\n",
            "TEST Loss: 1.3914624452590942, Accuracy: 0.7041015625\n",
            "Batch: 26, Loss: 0.31847071647644043, Accuracy: 0.90234375\n",
            "Batch: 27, Loss: 0.28302693367004395, Accuracy: 0.91796875\n",
            "Batch: 28, Loss: 0.2775259017944336, Accuracy: 0.921875\n",
            "Batch: 29, Loss: 0.33524081110954285, Accuracy: 0.8896484375\n",
            "TEST Loss: 1.0540430545806885, Accuracy: 0.7783203125\n",
            "Batch: 31, Loss: 0.28560522198677063, Accuracy: 0.91796875\n",
            "Batch: 32, Loss: 0.26407670974731445, Accuracy: 0.93359375\n",
            "Batch: 33, Loss: 0.28410470485687256, Accuracy: 0.9189453125\n",
            "Batch: 34, Loss: 0.34680837392807007, Accuracy: 0.8935546875\n",
            "TEST Loss: 0.7477041482925415, Accuracy: 0.806640625\n",
            "Batch: 36, Loss: 0.2919904887676239, Accuracy: 0.904296875\n",
            "Batch: 37, Loss: 0.2615475058555603, Accuracy: 0.9228515625\n",
            "Epoch 56/100\n",
            "Batch: 1, Loss: 0.37161320447921753, Accuracy: 0.896484375\n",
            "Batch: 2, Loss: 0.2982558012008667, Accuracy: 0.9072265625\n",
            "Batch: 3, Loss: 0.33767351508140564, Accuracy: 0.9013671875\n",
            "Batch: 4, Loss: 0.28360897302627563, Accuracy: 0.921875\n",
            "TEST Loss: 1.3593549728393555, Accuracy: 0.7099609375\n",
            "Batch: 6, Loss: 0.31932303309440613, Accuracy: 0.8896484375\n",
            "Batch: 7, Loss: 0.30835089087486267, Accuracy: 0.9091796875\n",
            "Batch: 8, Loss: 0.29903164505958557, Accuracy: 0.904296875\n",
            "Batch: 9, Loss: 0.3172566592693329, Accuracy: 0.90234375\n",
            "TEST Loss: 1.126222014427185, Accuracy: 0.7568359375\n",
            "Batch: 11, Loss: 0.35561603307724, Accuracy: 0.8818359375\n",
            "Batch: 12, Loss: 0.31709903478622437, Accuracy: 0.9013671875\n",
            "Batch: 13, Loss: 0.2934574484825134, Accuracy: 0.9033203125\n",
            "Batch: 14, Loss: 0.29925447702407837, Accuracy: 0.9072265625\n",
            "TEST Loss: 1.0695371627807617, Accuracy: 0.7841796875\n",
            "Batch: 16, Loss: 0.2859008312225342, Accuracy: 0.9130859375\n",
            "Batch: 17, Loss: 0.3588908314704895, Accuracy: 0.8857421875\n",
            "Batch: 18, Loss: 0.3293508291244507, Accuracy: 0.9013671875\n",
            "Batch: 19, Loss: 0.32867828011512756, Accuracy: 0.90625\n",
            "TEST Loss: 1.3310661315917969, Accuracy: 0.7333984375\n",
            "Batch: 21, Loss: 0.2715471386909485, Accuracy: 0.9169921875\n",
            "Batch: 22, Loss: 0.3095211982727051, Accuracy: 0.908203125\n",
            "Batch: 23, Loss: 0.337607204914093, Accuracy: 0.89453125\n",
            "Batch: 24, Loss: 0.3534747362136841, Accuracy: 0.8916015625\n",
            "TEST Loss: 1.3671847581863403, Accuracy: 0.71484375\n",
            "Batch: 26, Loss: 0.30141955614089966, Accuracy: 0.89453125\n",
            "Batch: 27, Loss: 0.25241905450820923, Accuracy: 0.9267578125\n",
            "Batch: 28, Loss: 0.2783370614051819, Accuracy: 0.91796875\n",
            "Batch: 29, Loss: 0.31170281767845154, Accuracy: 0.9052734375\n",
            "TEST Loss: 1.050974726676941, Accuracy: 0.798828125\n",
            "Batch: 31, Loss: 0.3012132942676544, Accuracy: 0.9150390625\n",
            "Batch: 32, Loss: 0.27470722794532776, Accuracy: 0.9287109375\n",
            "Batch: 33, Loss: 0.31240397691726685, Accuracy: 0.9052734375\n",
            "Batch: 34, Loss: 0.35361355543136597, Accuracy: 0.8935546875\n",
            "TEST Loss: 0.7398136854171753, Accuracy: 0.8212890625\n",
            "Batch: 36, Loss: 0.2945643365383148, Accuracy: 0.912109375\n",
            "Batch: 37, Loss: 0.24917908012866974, Accuracy: 0.9287109375\n",
            "Epoch 57/100\n",
            "Batch: 1, Loss: 0.3950713872909546, Accuracy: 0.8916015625\n",
            "Batch: 2, Loss: 0.2720351815223694, Accuracy: 0.919921875\n",
            "Batch: 3, Loss: 0.3342812955379486, Accuracy: 0.8994140625\n",
            "Batch: 4, Loss: 0.2958942651748657, Accuracy: 0.9169921875\n",
            "TEST Loss: 1.405707836151123, Accuracy: 0.6904296875\n",
            "Batch: 6, Loss: 0.3231028914451599, Accuracy: 0.8955078125\n",
            "Batch: 7, Loss: 0.28509587049484253, Accuracy: 0.9208984375\n",
            "Batch: 8, Loss: 0.3040462136268616, Accuracy: 0.91015625\n",
            "Batch: 9, Loss: 0.3190249502658844, Accuracy: 0.8955078125\n",
            "TEST Loss: 1.1401050090789795, Accuracy: 0.759765625\n",
            "Batch: 11, Loss: 0.36349087953567505, Accuracy: 0.8818359375\n",
            "Batch: 12, Loss: 0.30359750986099243, Accuracy: 0.904296875\n",
            "Batch: 13, Loss: 0.2712315022945404, Accuracy: 0.9189453125\n",
            "Batch: 14, Loss: 0.28420162200927734, Accuracy: 0.912109375\n",
            "TEST Loss: 1.0728204250335693, Accuracy: 0.7939453125\n",
            "Batch: 16, Loss: 0.2747744619846344, Accuracy: 0.92578125\n",
            "Batch: 17, Loss: 0.3423093557357788, Accuracy: 0.890625\n",
            "Batch: 18, Loss: 0.33543914556503296, Accuracy: 0.8994140625\n",
            "Batch: 19, Loss: 0.2846452593803406, Accuracy: 0.912109375\n",
            "TEST Loss: 1.3615295886993408, Accuracy: 0.7333984375\n",
            "Batch: 21, Loss: 0.2606281638145447, Accuracy: 0.9228515625\n",
            "Batch: 22, Loss: 0.3256163001060486, Accuracy: 0.9013671875\n",
            "Batch: 23, Loss: 0.33369916677474976, Accuracy: 0.908203125\n",
            "Batch: 24, Loss: 0.3107668161392212, Accuracy: 0.9150390625\n",
            "TEST Loss: 1.3999226093292236, Accuracy: 0.7177734375\n",
            "Batch: 26, Loss: 0.26702046394348145, Accuracy: 0.9189453125\n",
            "Batch: 27, Loss: 0.27548325061798096, Accuracy: 0.9208984375\n",
            "Batch: 28, Loss: 0.2582797110080719, Accuracy: 0.9228515625\n",
            "Batch: 29, Loss: 0.2844259440898895, Accuracy: 0.9248046875\n",
            "TEST Loss: 1.037635326385498, Accuracy: 0.7822265625\n",
            "Batch: 31, Loss: 0.26406046748161316, Accuracy: 0.921875\n",
            "Batch: 32, Loss: 0.27424174547195435, Accuracy: 0.923828125\n",
            "Batch: 33, Loss: 0.2713775634765625, Accuracy: 0.9189453125\n",
            "Batch: 34, Loss: 0.31894350051879883, Accuracy: 0.892578125\n",
            "TEST Loss: 0.7474347352981567, Accuracy: 0.814453125\n",
            "Batch: 36, Loss: 0.2622319161891937, Accuracy: 0.9189453125\n",
            "Batch: 37, Loss: 0.2872401475906372, Accuracy: 0.9111328125\n",
            "Epoch 58/100\n",
            "Batch: 1, Loss: 0.36164140701293945, Accuracy: 0.904296875\n",
            "Batch: 2, Loss: 0.284389853477478, Accuracy: 0.900390625\n",
            "Batch: 3, Loss: 0.3338242173194885, Accuracy: 0.9052734375\n",
            "Batch: 4, Loss: 0.29844141006469727, Accuracy: 0.9140625\n",
            "TEST Loss: 1.3919422626495361, Accuracy: 0.7041015625\n",
            "Batch: 6, Loss: 0.3091272711753845, Accuracy: 0.8984375\n",
            "Batch: 7, Loss: 0.2587151825428009, Accuracy: 0.923828125\n",
            "Batch: 8, Loss: 0.28131920099258423, Accuracy: 0.9150390625\n",
            "Batch: 9, Loss: 0.311786949634552, Accuracy: 0.9013671875\n",
            "TEST Loss: 1.1494320631027222, Accuracy: 0.7578125\n",
            "Batch: 11, Loss: 0.35864850878715515, Accuracy: 0.8857421875\n",
            "Batch: 12, Loss: 0.2974050045013428, Accuracy: 0.9091796875\n",
            "Batch: 13, Loss: 0.25382697582244873, Accuracy: 0.916015625\n",
            "Batch: 14, Loss: 0.26056089997291565, Accuracy: 0.92578125\n",
            "TEST Loss: 1.0732165575027466, Accuracy: 0.7939453125\n",
            "Batch: 16, Loss: 0.2555537521839142, Accuracy: 0.9267578125\n",
            "Batch: 17, Loss: 0.33715349435806274, Accuracy: 0.8955078125\n",
            "Batch: 18, Loss: 0.3192039132118225, Accuracy: 0.8994140625\n",
            "Batch: 19, Loss: 0.31540870666503906, Accuracy: 0.8984375\n",
            "TEST Loss: 1.3876206874847412, Accuracy: 0.7314453125\n",
            "Batch: 21, Loss: 0.25832343101501465, Accuracy: 0.9091796875\n",
            "Batch: 22, Loss: 0.29561227560043335, Accuracy: 0.9130859375\n",
            "Batch: 23, Loss: 0.3066117763519287, Accuracy: 0.9013671875\n",
            "Batch: 24, Loss: 0.2933090329170227, Accuracy: 0.908203125\n",
            "TEST Loss: 1.415296196937561, Accuracy: 0.7265625\n",
            "Batch: 26, Loss: 0.28767481446266174, Accuracy: 0.9140625\n",
            "Batch: 27, Loss: 0.23221230506896973, Accuracy: 0.9443359375\n",
            "Batch: 28, Loss: 0.24295350909233093, Accuracy: 0.9267578125\n",
            "Batch: 29, Loss: 0.24812035262584686, Accuracy: 0.931640625\n",
            "TEST Loss: 1.0219900608062744, Accuracy: 0.7880859375\n",
            "Batch: 31, Loss: 0.2557913064956665, Accuracy: 0.91796875\n",
            "Batch: 32, Loss: 0.22768568992614746, Accuracy: 0.93359375\n",
            "Batch: 33, Loss: 0.2909896969795227, Accuracy: 0.9033203125\n",
            "Batch: 34, Loss: 0.33121490478515625, Accuracy: 0.9052734375\n",
            "TEST Loss: 0.7131062746047974, Accuracy: 0.828125\n",
            "Batch: 36, Loss: 0.2810942232608795, Accuracy: 0.912109375\n",
            "Batch: 37, Loss: 0.26148420572280884, Accuracy: 0.9189453125\n",
            "Epoch 59/100\n",
            "Batch: 1, Loss: 0.33962517976760864, Accuracy: 0.90234375\n",
            "Batch: 2, Loss: 0.2529807686805725, Accuracy: 0.923828125\n",
            "Batch: 3, Loss: 0.32707661390304565, Accuracy: 0.9072265625\n",
            "Batch: 4, Loss: 0.266845166683197, Accuracy: 0.9208984375\n",
            "TEST Loss: 1.3882511854171753, Accuracy: 0.703125\n",
            "Batch: 6, Loss: 0.2932590842247009, Accuracy: 0.8994140625\n",
            "Batch: 7, Loss: 0.28580278158187866, Accuracy: 0.9091796875\n",
            "Batch: 8, Loss: 0.2598016858100891, Accuracy: 0.91796875\n",
            "Batch: 9, Loss: 0.27917855978012085, Accuracy: 0.9150390625\n",
            "TEST Loss: 1.1173447370529175, Accuracy: 0.759765625\n",
            "Batch: 11, Loss: 0.32440659403800964, Accuracy: 0.90234375\n",
            "Batch: 12, Loss: 0.27733632922172546, Accuracy: 0.9150390625\n",
            "Batch: 13, Loss: 0.22445376217365265, Accuracy: 0.9306640625\n",
            "Batch: 14, Loss: 0.27077192068099976, Accuracy: 0.919921875\n",
            "TEST Loss: 1.043308973312378, Accuracy: 0.802734375\n",
            "Batch: 16, Loss: 0.2563733756542206, Accuracy: 0.939453125\n",
            "Batch: 17, Loss: 0.32199782133102417, Accuracy: 0.90234375\n",
            "Batch: 18, Loss: 0.29368093609809875, Accuracy: 0.9189453125\n",
            "Batch: 19, Loss: 0.2851731777191162, Accuracy: 0.919921875\n",
            "TEST Loss: 1.3521870374679565, Accuracy: 0.7353515625\n",
            "Batch: 21, Loss: 0.26629528403282166, Accuracy: 0.9111328125\n",
            "Batch: 22, Loss: 0.29342859983444214, Accuracy: 0.919921875\n",
            "Batch: 23, Loss: 0.32059741020202637, Accuracy: 0.9111328125\n",
            "Batch: 24, Loss: 0.3140453100204468, Accuracy: 0.896484375\n",
            "TEST Loss: 1.4654873609542847, Accuracy: 0.71875\n",
            "Batch: 26, Loss: 0.28171390295028687, Accuracy: 0.91796875\n",
            "Batch: 27, Loss: 0.2236994504928589, Accuracy: 0.935546875\n",
            "Batch: 28, Loss: 0.23335696756839752, Accuracy: 0.931640625\n",
            "Batch: 29, Loss: 0.2618882954120636, Accuracy: 0.9140625\n",
            "TEST Loss: 1.016404151916504, Accuracy: 0.794921875\n",
            "Batch: 31, Loss: 0.27240514755249023, Accuracy: 0.9150390625\n",
            "Batch: 32, Loss: 0.2272966206073761, Accuracy: 0.92578125\n",
            "Batch: 33, Loss: 0.26659202575683594, Accuracy: 0.921875\n",
            "Batch: 34, Loss: 0.3081434965133667, Accuracy: 0.9072265625\n",
            "TEST Loss: 0.7242687940597534, Accuracy: 0.8251953125\n",
            "Batch: 36, Loss: 0.2270859181880951, Accuracy: 0.9306640625\n",
            "Batch: 37, Loss: 0.2427016794681549, Accuracy: 0.9169921875\n",
            "Epoch 60/100\n",
            "Batch: 1, Loss: 0.33364027738571167, Accuracy: 0.90234375\n",
            "Batch: 2, Loss: 0.27956873178482056, Accuracy: 0.9130859375\n",
            "Batch: 3, Loss: 0.28814172744750977, Accuracy: 0.91796875\n",
            "Batch: 4, Loss: 0.270320862531662, Accuracy: 0.919921875\n",
            "TEST Loss: 1.4019200801849365, Accuracy: 0.701171875\n",
            "Batch: 6, Loss: 0.28222352266311646, Accuracy: 0.9111328125\n",
            "Batch: 7, Loss: 0.28329476714134216, Accuracy: 0.9150390625\n",
            "Batch: 8, Loss: 0.2735222578048706, Accuracy: 0.9140625\n",
            "Batch: 9, Loss: 0.2766393721103668, Accuracy: 0.9111328125\n",
            "TEST Loss: 1.1222018003463745, Accuracy: 0.7666015625\n",
            "Batch: 11, Loss: 0.32452481985092163, Accuracy: 0.8994140625\n",
            "Batch: 12, Loss: 0.2815430164337158, Accuracy: 0.9052734375\n",
            "Batch: 13, Loss: 0.24641822278499603, Accuracy: 0.92578125\n",
            "Batch: 14, Loss: 0.24857273697853088, Accuracy: 0.9208984375\n",
            "TEST Loss: 1.0713316202163696, Accuracy: 0.79296875\n",
            "Batch: 16, Loss: 0.24849596619606018, Accuracy: 0.9296875\n",
            "Batch: 17, Loss: 0.295118510723114, Accuracy: 0.9052734375\n",
            "Batch: 18, Loss: 0.3033677935600281, Accuracy: 0.90625\n",
            "Batch: 19, Loss: 0.2623414993286133, Accuracy: 0.9267578125\n",
            "TEST Loss: 1.3770990371704102, Accuracy: 0.7451171875\n",
            "Batch: 21, Loss: 0.24460597336292267, Accuracy: 0.9296875\n",
            "Batch: 22, Loss: 0.30431002378463745, Accuracy: 0.904296875\n",
            "Batch: 23, Loss: 0.3015371263027191, Accuracy: 0.9072265625\n",
            "Batch: 24, Loss: 0.2777581214904785, Accuracy: 0.9228515625\n",
            "TEST Loss: 1.4462568759918213, Accuracy: 0.728515625\n",
            "Batch: 26, Loss: 0.24707502126693726, Accuracy: 0.9365234375\n",
            "Batch: 27, Loss: 0.2339751422405243, Accuracy: 0.9248046875\n",
            "Batch: 28, Loss: 0.22939497232437134, Accuracy: 0.9365234375\n",
            "Batch: 29, Loss: 0.23880517482757568, Accuracy: 0.9384765625\n",
            "TEST Loss: 1.0358027219772339, Accuracy: 0.791015625\n",
            "Batch: 31, Loss: 0.2649914622306824, Accuracy: 0.9228515625\n",
            "Batch: 32, Loss: 0.22965529561042786, Accuracy: 0.935546875\n",
            "Batch: 33, Loss: 0.26752251386642456, Accuracy: 0.923828125\n",
            "Batch: 34, Loss: 0.2529907822608948, Accuracy: 0.921875\n",
            "TEST Loss: 0.7291336059570312, Accuracy: 0.8212890625\n",
            "Batch: 36, Loss: 0.2133731245994568, Accuracy: 0.93359375\n",
            "Batch: 37, Loss: 0.2491530179977417, Accuracy: 0.9248046875\n",
            "Saved Weights at epoch 60 to file Weights_mozart.h5\n",
            "Epoch 61/100\n",
            "Batch: 1, Loss: 0.2857745289802551, Accuracy: 0.9228515625\n",
            "Batch: 2, Loss: 0.2854522168636322, Accuracy: 0.9111328125\n",
            "Batch: 3, Loss: 0.31626033782958984, Accuracy: 0.912109375\n",
            "Batch: 4, Loss: 0.2274835705757141, Accuracy: 0.9296875\n",
            "TEST Loss: 1.439517855644226, Accuracy: 0.697265625\n",
            "Batch: 6, Loss: 0.2963874936103821, Accuracy: 0.9013671875\n",
            "Batch: 7, Loss: 0.2696617841720581, Accuracy: 0.923828125\n",
            "Batch: 8, Loss: 0.2861693501472473, Accuracy: 0.90234375\n",
            "Batch: 9, Loss: 0.29596593976020813, Accuracy: 0.9072265625\n",
            "TEST Loss: 1.1977801322937012, Accuracy: 0.7490234375\n",
            "Batch: 11, Loss: 0.31145477294921875, Accuracy: 0.8984375\n",
            "Batch: 12, Loss: 0.2964304983615875, Accuracy: 0.9013671875\n",
            "Batch: 13, Loss: 0.2436729371547699, Accuracy: 0.9306640625\n",
            "Batch: 14, Loss: 0.2137078493833542, Accuracy: 0.9384765625\n",
            "TEST Loss: 1.0820164680480957, Accuracy: 0.8056640625\n",
            "Batch: 16, Loss: 0.23444703221321106, Accuracy: 0.9326171875\n",
            "Batch: 17, Loss: 0.26857107877731323, Accuracy: 0.9248046875\n",
            "Batch: 18, Loss: 0.27122026681900024, Accuracy: 0.916015625\n",
            "Batch: 19, Loss: 0.2776031494140625, Accuracy: 0.916015625\n",
            "TEST Loss: 1.3869102001190186, Accuracy: 0.7421875\n",
            "Batch: 21, Loss: 0.2442876398563385, Accuracy: 0.927734375\n",
            "Batch: 22, Loss: 0.22789397835731506, Accuracy: 0.9296875\n",
            "Batch: 23, Loss: 0.27314138412475586, Accuracy: 0.9228515625\n",
            "Batch: 24, Loss: 0.29616081714630127, Accuracy: 0.9169921875\n",
            "TEST Loss: 1.4050853252410889, Accuracy: 0.7255859375\n",
            "Batch: 26, Loss: 0.24803021550178528, Accuracy: 0.9375\n",
            "Batch: 27, Loss: 0.24189642071723938, Accuracy: 0.927734375\n",
            "Batch: 28, Loss: 0.23028089106082916, Accuracy: 0.931640625\n",
            "Batch: 29, Loss: 0.25124555826187134, Accuracy: 0.9267578125\n",
            "TEST Loss: 1.0530774593353271, Accuracy: 0.78515625\n",
            "Batch: 31, Loss: 0.23404903709888458, Accuracy: 0.9326171875\n",
            "Batch: 32, Loss: 0.2221914827823639, Accuracy: 0.9287109375\n",
            "Batch: 33, Loss: 0.2486352026462555, Accuracy: 0.931640625\n",
            "Batch: 34, Loss: 0.31481534242630005, Accuracy: 0.8935546875\n",
            "TEST Loss: 0.725004255771637, Accuracy: 0.8251953125\n",
            "Batch: 36, Loss: 0.21444231271743774, Accuracy: 0.93359375\n",
            "Batch: 37, Loss: 0.2412140816450119, Accuracy: 0.921875\n",
            "Epoch 62/100\n",
            "Batch: 1, Loss: 0.3261767625808716, Accuracy: 0.9052734375\n",
            "Batch: 2, Loss: 0.2603312134742737, Accuracy: 0.9228515625\n",
            "Batch: 3, Loss: 0.2766229510307312, Accuracy: 0.92578125\n",
            "Batch: 4, Loss: 0.2224637269973755, Accuracy: 0.939453125\n",
            "TEST Loss: 1.4101266860961914, Accuracy: 0.6953125\n",
            "Batch: 6, Loss: 0.2888783812522888, Accuracy: 0.9052734375\n",
            "Batch: 7, Loss: 0.26024875044822693, Accuracy: 0.916015625\n",
            "Batch: 8, Loss: 0.24932385981082916, Accuracy: 0.9287109375\n",
            "Batch: 9, Loss: 0.2653456926345825, Accuracy: 0.9169921875\n",
            "TEST Loss: 1.1135132312774658, Accuracy: 0.771484375\n",
            "Batch: 11, Loss: 0.2819528579711914, Accuracy: 0.90625\n",
            "Batch: 12, Loss: 0.28098300099372864, Accuracy: 0.91015625\n",
            "Batch: 13, Loss: 0.2035585194826126, Accuracy: 0.94140625\n",
            "Batch: 14, Loss: 0.2639510929584503, Accuracy: 0.91015625\n",
            "TEST Loss: 1.1318790912628174, Accuracy: 0.791015625\n",
            "Batch: 16, Loss: 0.23062768578529358, Accuracy: 0.927734375\n",
            "Batch: 17, Loss: 0.2887338399887085, Accuracy: 0.9169921875\n",
            "Batch: 18, Loss: 0.28501611948013306, Accuracy: 0.90625\n",
            "Batch: 19, Loss: 0.2440715879201889, Accuracy: 0.9326171875\n",
            "TEST Loss: 1.397824764251709, Accuracy: 0.7392578125\n",
            "Batch: 21, Loss: 0.23485393822193146, Accuracy: 0.9326171875\n",
            "Batch: 22, Loss: 0.2807158827781677, Accuracy: 0.9169921875\n",
            "Batch: 23, Loss: 0.296358197927475, Accuracy: 0.9052734375\n",
            "Batch: 24, Loss: 0.2782953381538391, Accuracy: 0.9248046875\n",
            "TEST Loss: 1.4268854856491089, Accuracy: 0.7255859375\n",
            "Batch: 26, Loss: 0.23507648706436157, Accuracy: 0.93359375\n",
            "Batch: 27, Loss: 0.21716353297233582, Accuracy: 0.939453125\n",
            "Batch: 28, Loss: 0.22141355276107788, Accuracy: 0.9326171875\n",
            "Batch: 29, Loss: 0.24165377020835876, Accuracy: 0.9296875\n",
            "TEST Loss: 1.0553033351898193, Accuracy: 0.7880859375\n",
            "Batch: 31, Loss: 0.24328751862049103, Accuracy: 0.9296875\n",
            "Batch: 32, Loss: 0.2355097234249115, Accuracy: 0.927734375\n",
            "Batch: 33, Loss: 0.2564629912376404, Accuracy: 0.9248046875\n",
            "Batch: 34, Loss: 0.2862357199192047, Accuracy: 0.9111328125\n",
            "TEST Loss: 0.7492368221282959, Accuracy: 0.818359375\n",
            "Batch: 36, Loss: 0.212559774518013, Accuracy: 0.9375\n",
            "Batch: 37, Loss: 0.21056485176086426, Accuracy: 0.9326171875\n",
            "Epoch 63/100\n",
            "Batch: 1, Loss: 0.30354416370391846, Accuracy: 0.91015625\n",
            "Batch: 2, Loss: 0.24301040172576904, Accuracy: 0.931640625\n",
            "Batch: 3, Loss: 0.26564839482307434, Accuracy: 0.9228515625\n",
            "Batch: 4, Loss: 0.23384001851081848, Accuracy: 0.9326171875\n",
            "TEST Loss: 1.3689714670181274, Accuracy: 0.7099609375\n",
            "Batch: 6, Loss: 0.25309476256370544, Accuracy: 0.919921875\n",
            "Batch: 7, Loss: 0.255715936422348, Accuracy: 0.9228515625\n",
            "Batch: 8, Loss: 0.23301054537296295, Accuracy: 0.9326171875\n",
            "Batch: 9, Loss: 0.2422657608985901, Accuracy: 0.91796875\n",
            "TEST Loss: 1.172694444656372, Accuracy: 0.7646484375\n",
            "Batch: 11, Loss: 0.2969815135002136, Accuracy: 0.9013671875\n",
            "Batch: 12, Loss: 0.2429284155368805, Accuracy: 0.9326171875\n",
            "Batch: 13, Loss: 0.21163305640220642, Accuracy: 0.9365234375\n",
            "Batch: 14, Loss: 0.24256914854049683, Accuracy: 0.921875\n",
            "TEST Loss: 1.0881271362304688, Accuracy: 0.8037109375\n",
            "Batch: 16, Loss: 0.24148602783679962, Accuracy: 0.927734375\n",
            "Batch: 17, Loss: 0.2718579173088074, Accuracy: 0.91796875\n",
            "Batch: 18, Loss: 0.28806471824645996, Accuracy: 0.923828125\n",
            "Batch: 19, Loss: 0.266548752784729, Accuracy: 0.91796875\n",
            "TEST Loss: 1.4284417629241943, Accuracy: 0.7373046875\n",
            "Batch: 21, Loss: 0.2348097860813141, Accuracy: 0.9267578125\n",
            "Batch: 22, Loss: 0.2547706365585327, Accuracy: 0.921875\n",
            "Batch: 23, Loss: 0.32152146100997925, Accuracy: 0.9033203125\n",
            "Batch: 24, Loss: 0.2397206425666809, Accuracy: 0.9287109375\n",
            "TEST Loss: 1.3867384195327759, Accuracy: 0.736328125\n",
            "Batch: 26, Loss: 0.24458056688308716, Accuracy: 0.9306640625\n",
            "Batch: 27, Loss: 0.23696331679821014, Accuracy: 0.9345703125\n",
            "Batch: 28, Loss: 0.2060232162475586, Accuracy: 0.935546875\n",
            "Batch: 29, Loss: 0.20927561819553375, Accuracy: 0.935546875\n",
            "TEST Loss: 1.0423643589019775, Accuracy: 0.7919921875\n",
            "Batch: 31, Loss: 0.24787139892578125, Accuracy: 0.9169921875\n",
            "Batch: 32, Loss: 0.2029159963130951, Accuracy: 0.9384765625\n",
            "Batch: 33, Loss: 0.25758349895477295, Accuracy: 0.91015625\n",
            "Batch: 34, Loss: 0.29504090547561646, Accuracy: 0.91015625\n",
            "TEST Loss: 0.7094182968139648, Accuracy: 0.8349609375\n",
            "Batch: 36, Loss: 0.24052084982395172, Accuracy: 0.927734375\n",
            "Batch: 37, Loss: 0.20592175424098969, Accuracy: 0.9345703125\n",
            "Epoch 64/100\n",
            "Batch: 1, Loss: 0.2774537205696106, Accuracy: 0.927734375\n",
            "Batch: 2, Loss: 0.20698538422584534, Accuracy: 0.9443359375\n",
            "Batch: 3, Loss: 0.29628071188926697, Accuracy: 0.919921875\n",
            "Batch: 4, Loss: 0.2339167296886444, Accuracy: 0.9345703125\n",
            "TEST Loss: 1.4083112478256226, Accuracy: 0.6943359375\n",
            "Batch: 6, Loss: 0.252422958612442, Accuracy: 0.923828125\n",
            "Batch: 7, Loss: 0.2497083991765976, Accuracy: 0.9169921875\n",
            "Batch: 8, Loss: 0.22387343645095825, Accuracy: 0.935546875\n",
            "Batch: 9, Loss: 0.27063408493995667, Accuracy: 0.91015625\n",
            "TEST Loss: 1.1120328903198242, Accuracy: 0.76953125\n",
            "Batch: 11, Loss: 0.270779550075531, Accuracy: 0.9091796875\n",
            "Batch: 12, Loss: 0.2572587728500366, Accuracy: 0.912109375\n",
            "Batch: 13, Loss: 0.22135531902313232, Accuracy: 0.931640625\n",
            "Batch: 14, Loss: 0.2141641229391098, Accuracy: 0.9326171875\n",
            "TEST Loss: 1.0696347951889038, Accuracy: 0.7998046875\n",
            "Batch: 16, Loss: 0.219101220369339, Accuracy: 0.9345703125\n",
            "Batch: 17, Loss: 0.2774825692176819, Accuracy: 0.919921875\n",
            "Batch: 18, Loss: 0.2896844446659088, Accuracy: 0.912109375\n",
            "Batch: 19, Loss: 0.2271224856376648, Accuracy: 0.931640625\n",
            "TEST Loss: 1.4269492626190186, Accuracy: 0.73828125\n",
            "Batch: 21, Loss: 0.21144366264343262, Accuracy: 0.939453125\n",
            "Batch: 22, Loss: 0.24452656507492065, Accuracy: 0.923828125\n",
            "Batch: 23, Loss: 0.26027071475982666, Accuracy: 0.9150390625\n",
            "Batch: 24, Loss: 0.25768351554870605, Accuracy: 0.9287109375\n",
            "TEST Loss: 1.444867491722107, Accuracy: 0.7294921875\n",
            "Batch: 26, Loss: 0.23785074055194855, Accuracy: 0.9248046875\n",
            "Batch: 27, Loss: 0.18807169795036316, Accuracy: 0.9453125\n",
            "Batch: 28, Loss: 0.20026123523712158, Accuracy: 0.9404296875\n",
            "Batch: 29, Loss: 0.20873215794563293, Accuracy: 0.9375\n",
            "TEST Loss: 1.0301910638809204, Accuracy: 0.7958984375\n",
            "Batch: 31, Loss: 0.21654942631721497, Accuracy: 0.935546875\n",
            "Batch: 32, Loss: 0.20703330636024475, Accuracy: 0.935546875\n",
            "Batch: 33, Loss: 0.24659523367881775, Accuracy: 0.9228515625\n",
            "Batch: 34, Loss: 0.3034071922302246, Accuracy: 0.9052734375\n",
            "TEST Loss: 0.6957589387893677, Accuracy: 0.830078125\n",
            "Batch: 36, Loss: 0.20315048098564148, Accuracy: 0.9365234375\n",
            "Batch: 37, Loss: 0.21572694182395935, Accuracy: 0.9404296875\n",
            "Epoch 65/100\n",
            "Batch: 1, Loss: 0.2686161994934082, Accuracy: 0.927734375\n",
            "Batch: 2, Loss: 0.24025478959083557, Accuracy: 0.919921875\n",
            "Batch: 3, Loss: 0.2461605668067932, Accuracy: 0.931640625\n",
            "Batch: 4, Loss: 0.22258581221103668, Accuracy: 0.9404296875\n",
            "TEST Loss: 1.431542992591858, Accuracy: 0.7060546875\n",
            "Batch: 6, Loss: 0.25674042105674744, Accuracy: 0.9189453125\n",
            "Batch: 7, Loss: 0.23346343636512756, Accuracy: 0.9345703125\n",
            "Batch: 8, Loss: 0.24811097979545593, Accuracy: 0.92578125\n",
            "Batch: 9, Loss: 0.263424277305603, Accuracy: 0.9111328125\n",
            "TEST Loss: 1.1631417274475098, Accuracy: 0.7490234375\n",
            "Batch: 11, Loss: 0.2823992073535919, Accuracy: 0.912109375\n",
            "Batch: 12, Loss: 0.26959097385406494, Accuracy: 0.9140625\n",
            "Batch: 13, Loss: 0.18538793921470642, Accuracy: 0.939453125\n",
            "Batch: 14, Loss: 0.22704194486141205, Accuracy: 0.9306640625\n",
            "TEST Loss: 1.1181718111038208, Accuracy: 0.7998046875\n",
            "Batch: 16, Loss: 0.19440880417823792, Accuracy: 0.9423828125\n",
            "Batch: 17, Loss: 0.2693634033203125, Accuracy: 0.916015625\n",
            "Batch: 18, Loss: 0.2676685154438019, Accuracy: 0.9091796875\n",
            "Batch: 19, Loss: 0.2383934110403061, Accuracy: 0.931640625\n",
            "TEST Loss: 1.409615397453308, Accuracy: 0.7421875\n",
            "Batch: 21, Loss: 0.20931394398212433, Accuracy: 0.9326171875\n",
            "Batch: 22, Loss: 0.25889521837234497, Accuracy: 0.90625\n",
            "Batch: 23, Loss: 0.25452956557273865, Accuracy: 0.9169921875\n",
            "Batch: 24, Loss: 0.24912555515766144, Accuracy: 0.9267578125\n",
            "TEST Loss: 1.4025932550430298, Accuracy: 0.73046875\n",
            "Batch: 26, Loss: 0.24060669541358948, Accuracy: 0.923828125\n",
            "Batch: 27, Loss: 0.20534953474998474, Accuracy: 0.9375\n",
            "Batch: 28, Loss: 0.2074640393257141, Accuracy: 0.9306640625\n",
            "Batch: 29, Loss: 0.19772133231163025, Accuracy: 0.947265625\n",
            "TEST Loss: 1.0119175910949707, Accuracy: 0.8095703125\n",
            "Batch: 31, Loss: 0.23033800721168518, Accuracy: 0.9306640625\n",
            "Batch: 32, Loss: 0.19480377435684204, Accuracy: 0.9443359375\n",
            "Batch: 33, Loss: 0.21863622963428497, Accuracy: 0.9306640625\n",
            "Batch: 34, Loss: 0.2642226815223694, Accuracy: 0.916015625\n",
            "TEST Loss: 0.7133069038391113, Accuracy: 0.833984375\n",
            "Batch: 36, Loss: 0.21169961988925934, Accuracy: 0.939453125\n",
            "Batch: 37, Loss: 0.19186267256736755, Accuracy: 0.9443359375\n",
            "Epoch 66/100\n",
            "Batch: 1, Loss: 0.28007879853248596, Accuracy: 0.92578125\n",
            "Batch: 2, Loss: 0.2047605663537979, Accuracy: 0.9365234375\n",
            "Batch: 3, Loss: 0.24793970584869385, Accuracy: 0.923828125\n",
            "Batch: 4, Loss: 0.21176153421401978, Accuracy: 0.939453125\n",
            "TEST Loss: 1.3648951053619385, Accuracy: 0.7109375\n",
            "Batch: 6, Loss: 0.23481953144073486, Accuracy: 0.92578125\n",
            "Batch: 7, Loss: 0.20751476287841797, Accuracy: 0.9384765625\n",
            "Batch: 8, Loss: 0.24073167145252228, Accuracy: 0.927734375\n",
            "Batch: 9, Loss: 0.22602425515651703, Accuracy: 0.9326171875\n",
            "TEST Loss: 1.1572978496551514, Accuracy: 0.767578125\n",
            "Batch: 11, Loss: 0.2759888768196106, Accuracy: 0.9091796875\n",
            "Batch: 12, Loss: 0.23902522027492523, Accuracy: 0.9384765625\n",
            "Batch: 13, Loss: 0.19834305346012115, Accuracy: 0.939453125\n",
            "Batch: 14, Loss: 0.22444486618041992, Accuracy: 0.9345703125\n",
            "TEST Loss: 1.0764466524124146, Accuracy: 0.80859375\n",
            "Batch: 16, Loss: 0.20917102694511414, Accuracy: 0.9423828125\n",
            "Batch: 17, Loss: 0.24347850680351257, Accuracy: 0.919921875\n",
            "Batch: 18, Loss: 0.2680191397666931, Accuracy: 0.919921875\n",
            "Batch: 19, Loss: 0.2102874517440796, Accuracy: 0.9365234375\n",
            "TEST Loss: 1.4388774633407593, Accuracy: 0.7421875\n",
            "Batch: 21, Loss: 0.20861995220184326, Accuracy: 0.935546875\n",
            "Batch: 22, Loss: 0.23790666460990906, Accuracy: 0.9345703125\n",
            "Batch: 23, Loss: 0.23507922887802124, Accuracy: 0.9423828125\n",
            "Batch: 24, Loss: 0.2481761872768402, Accuracy: 0.9208984375\n",
            "TEST Loss: 1.458917260169983, Accuracy: 0.7177734375\n",
            "Batch: 26, Loss: 0.20632675290107727, Accuracy: 0.94921875\n",
            "Batch: 27, Loss: 0.19161686301231384, Accuracy: 0.947265625\n",
            "Batch: 28, Loss: 0.2056046426296234, Accuracy: 0.939453125\n",
            "Batch: 29, Loss: 0.2205289751291275, Accuracy: 0.93359375\n",
            "TEST Loss: 1.0690373182296753, Accuracy: 0.7958984375\n",
            "Batch: 31, Loss: 0.20485325157642365, Accuracy: 0.93359375\n",
            "Batch: 32, Loss: 0.19451743364334106, Accuracy: 0.9453125\n",
            "Batch: 33, Loss: 0.21969211101531982, Accuracy: 0.9326171875\n",
            "Batch: 34, Loss: 0.23856250941753387, Accuracy: 0.9365234375\n",
            "TEST Loss: 0.7068175077438354, Accuracy: 0.83203125\n",
            "Batch: 36, Loss: 0.19963575899600983, Accuracy: 0.935546875\n",
            "Batch: 37, Loss: 0.21710284054279327, Accuracy: 0.92578125\n",
            "Epoch 67/100\n",
            "Batch: 1, Loss: 0.26389673352241516, Accuracy: 0.9267578125\n",
            "Batch: 2, Loss: 0.21883568167686462, Accuracy: 0.931640625\n",
            "Batch: 3, Loss: 0.26559287309646606, Accuracy: 0.927734375\n",
            "Batch: 4, Loss: 0.21422219276428223, Accuracy: 0.93359375\n",
            "TEST Loss: 1.5169042348861694, Accuracy: 0.6884765625\n",
            "Batch: 6, Loss: 0.25769898295402527, Accuracy: 0.91796875\n",
            "Batch: 7, Loss: 0.2380223572254181, Accuracy: 0.9345703125\n",
            "Batch: 8, Loss: 0.21566176414489746, Accuracy: 0.9296875\n",
            "Batch: 9, Loss: 0.2216625213623047, Accuracy: 0.921875\n",
            "TEST Loss: 1.1428747177124023, Accuracy: 0.7763671875\n",
            "Batch: 11, Loss: 0.2656773328781128, Accuracy: 0.91796875\n",
            "Batch: 12, Loss: 0.21724838018417358, Accuracy: 0.9375\n",
            "Batch: 13, Loss: 0.18354949355125427, Accuracy: 0.9521484375\n",
            "Batch: 14, Loss: 0.2122168242931366, Accuracy: 0.9404296875\n",
            "TEST Loss: 1.0917266607284546, Accuracy: 0.810546875\n",
            "Batch: 16, Loss: 0.19880340993404388, Accuracy: 0.9384765625\n",
            "Batch: 17, Loss: 0.2563224732875824, Accuracy: 0.9296875\n",
            "Batch: 18, Loss: 0.23429065942764282, Accuracy: 0.935546875\n",
            "Batch: 19, Loss: 0.20508939027786255, Accuracy: 0.94140625\n",
            "TEST Loss: 1.4414212703704834, Accuracy: 0.7451171875\n",
            "Batch: 21, Loss: 0.19825804233551025, Accuracy: 0.94140625\n",
            "Batch: 22, Loss: 0.22137342393398285, Accuracy: 0.9423828125\n",
            "Batch: 23, Loss: 0.2559441328048706, Accuracy: 0.923828125\n",
            "Batch: 24, Loss: 0.23638179898262024, Accuracy: 0.9287109375\n",
            "TEST Loss: 1.393481731414795, Accuracy: 0.736328125\n",
            "Batch: 26, Loss: 0.2072724848985672, Accuracy: 0.9501953125\n",
            "Batch: 27, Loss: 0.18431302905082703, Accuracy: 0.9501953125\n",
            "Batch: 28, Loss: 0.18416601419448853, Accuracy: 0.94921875\n",
            "Batch: 29, Loss: 0.20781809091567993, Accuracy: 0.9404296875\n",
            "TEST Loss: 1.066603660583496, Accuracy: 0.796875\n",
            "Batch: 31, Loss: 0.21009376645088196, Accuracy: 0.94140625\n",
            "Batch: 32, Loss: 0.17973926663398743, Accuracy: 0.9501953125\n",
            "Batch: 33, Loss: 0.22051531076431274, Accuracy: 0.9208984375\n",
            "Batch: 34, Loss: 0.22774338722229004, Accuracy: 0.94140625\n",
            "TEST Loss: 0.7021064162254333, Accuracy: 0.8271484375\n",
            "Batch: 36, Loss: 0.20310959219932556, Accuracy: 0.939453125\n",
            "Batch: 37, Loss: 0.1970960795879364, Accuracy: 0.9404296875\n",
            "Epoch 68/100\n",
            "Batch: 1, Loss: 0.23575696349143982, Accuracy: 0.94140625\n",
            "Batch: 2, Loss: 0.20430801808834076, Accuracy: 0.9365234375\n",
            "Batch: 3, Loss: 0.2539101839065552, Accuracy: 0.9208984375\n",
            "Batch: 4, Loss: 0.1930662989616394, Accuracy: 0.9453125\n",
            "TEST Loss: 1.4971195459365845, Accuracy: 0.6962890625\n",
            "Batch: 6, Loss: 0.26574018597602844, Accuracy: 0.904296875\n",
            "Batch: 7, Loss: 0.2116638720035553, Accuracy: 0.943359375\n",
            "Batch: 8, Loss: 0.19370800256729126, Accuracy: 0.9453125\n",
            "Batch: 9, Loss: 0.2171015739440918, Accuracy: 0.9365234375\n",
            "TEST Loss: 1.1922250986099243, Accuracy: 0.7607421875\n",
            "Batch: 11, Loss: 0.2492375373840332, Accuracy: 0.919921875\n",
            "Batch: 12, Loss: 0.22340704500675201, Accuracy: 0.9365234375\n",
            "Batch: 13, Loss: 0.19515933096408844, Accuracy: 0.94921875\n",
            "Batch: 14, Loss: 0.20976820588111877, Accuracy: 0.931640625\n",
            "TEST Loss: 1.0621126890182495, Accuracy: 0.80859375\n",
            "Batch: 16, Loss: 0.18962401151657104, Accuracy: 0.943359375\n",
            "Batch: 17, Loss: 0.21704092621803284, Accuracy: 0.9443359375\n",
            "Batch: 18, Loss: 0.2385353147983551, Accuracy: 0.9384765625\n",
            "Batch: 19, Loss: 0.19204309582710266, Accuracy: 0.94140625\n",
            "TEST Loss: 1.409278154373169, Accuracy: 0.75390625\n",
            "Batch: 21, Loss: 0.19985884428024292, Accuracy: 0.9443359375\n",
            "Batch: 22, Loss: 0.20989632606506348, Accuracy: 0.9365234375\n",
            "Batch: 23, Loss: 0.21601949632167816, Accuracy: 0.9306640625\n",
            "Batch: 24, Loss: 0.22947168350219727, Accuracy: 0.9384765625\n",
            "TEST Loss: 1.461262583732605, Accuracy: 0.7216796875\n",
            "Batch: 26, Loss: 0.2266450822353363, Accuracy: 0.9267578125\n",
            "Batch: 27, Loss: 0.1908000111579895, Accuracy: 0.9423828125\n",
            "Batch: 28, Loss: 0.19943062961101532, Accuracy: 0.9404296875\n",
            "Batch: 29, Loss: 0.20933063328266144, Accuracy: 0.9326171875\n",
            "TEST Loss: 1.0387130975723267, Accuracy: 0.794921875\n",
            "Batch: 31, Loss: 0.21565325558185577, Accuracy: 0.9287109375\n",
            "Batch: 32, Loss: 0.19263046979904175, Accuracy: 0.943359375\n",
            "Batch: 33, Loss: 0.2069966197013855, Accuracy: 0.9443359375\n",
            "Batch: 34, Loss: 0.26504820585250854, Accuracy: 0.916015625\n",
            "TEST Loss: 0.7122575044631958, Accuracy: 0.830078125\n",
            "Batch: 36, Loss: 0.1988324671983719, Accuracy: 0.9453125\n",
            "Batch: 37, Loss: 0.1939353197813034, Accuracy: 0.947265625\n",
            "Epoch 69/100\n",
            "Batch: 1, Loss: 0.2616316080093384, Accuracy: 0.921875\n",
            "Batch: 2, Loss: 0.17807996273040771, Accuracy: 0.943359375\n",
            "Batch: 3, Loss: 0.2709358334541321, Accuracy: 0.923828125\n",
            "Batch: 4, Loss: 0.20116883516311646, Accuracy: 0.94921875\n",
            "TEST Loss: 1.4497803449630737, Accuracy: 0.7041015625\n",
            "Batch: 6, Loss: 0.21542967855930328, Accuracy: 0.9248046875\n",
            "Batch: 7, Loss: 0.21103161573410034, Accuracy: 0.9404296875\n",
            "Batch: 8, Loss: 0.19173495471477509, Accuracy: 0.9443359375\n",
            "Batch: 9, Loss: 0.22738437354564667, Accuracy: 0.931640625\n",
            "TEST Loss: 1.2226401567459106, Accuracy: 0.7666015625\n",
            "Batch: 11, Loss: 0.22995895147323608, Accuracy: 0.92578125\n",
            "Batch: 12, Loss: 0.22583319246768951, Accuracy: 0.9375\n",
            "Batch: 13, Loss: 0.17888665199279785, Accuracy: 0.9482421875\n",
            "Batch: 14, Loss: 0.1906292587518692, Accuracy: 0.947265625\n",
            "TEST Loss: 1.0719913244247437, Accuracy: 0.8115234375\n",
            "Batch: 16, Loss: 0.1982952356338501, Accuracy: 0.9423828125\n",
            "Batch: 17, Loss: 0.2453724592924118, Accuracy: 0.9267578125\n",
            "Batch: 18, Loss: 0.20700912177562714, Accuracy: 0.939453125\n",
            "Batch: 19, Loss: 0.19206786155700684, Accuracy: 0.9453125\n",
            "TEST Loss: 1.4142141342163086, Accuracy: 0.75\n",
            "Batch: 21, Loss: 0.21243584156036377, Accuracy: 0.9306640625\n",
            "Batch: 22, Loss: 0.23051679134368896, Accuracy: 0.9267578125\n",
            "Batch: 23, Loss: 0.22632083296775818, Accuracy: 0.935546875\n",
            "Batch: 24, Loss: 0.23113760352134705, Accuracy: 0.9296875\n",
            "TEST Loss: 1.5092865228652954, Accuracy: 0.7333984375\n",
            "Batch: 26, Loss: 0.19042940437793732, Accuracy: 0.9521484375\n",
            "Batch: 27, Loss: 0.18546772003173828, Accuracy: 0.947265625\n",
            "Batch: 28, Loss: 0.1821390688419342, Accuracy: 0.9482421875\n",
            "Batch: 29, Loss: 0.19175821542739868, Accuracy: 0.9453125\n",
            "TEST Loss: 1.0595182180404663, Accuracy: 0.80078125\n",
            "Batch: 31, Loss: 0.18682920932769775, Accuracy: 0.9482421875\n",
            "Batch: 32, Loss: 0.18332602083683014, Accuracy: 0.951171875\n",
            "Batch: 33, Loss: 0.21348613500595093, Accuracy: 0.931640625\n",
            "Batch: 34, Loss: 0.23350533843040466, Accuracy: 0.9248046875\n",
            "TEST Loss: 0.7396805286407471, Accuracy: 0.83203125\n",
            "Batch: 36, Loss: 0.19725023210048676, Accuracy: 0.935546875\n",
            "Batch: 37, Loss: 0.17493149638175964, Accuracy: 0.943359375\n",
            "Epoch 70/100\n",
            "Batch: 1, Loss: 0.2427416443824768, Accuracy: 0.931640625\n",
            "Batch: 2, Loss: 0.20476606488227844, Accuracy: 0.9345703125\n",
            "Batch: 3, Loss: 0.2489616572856903, Accuracy: 0.92578125\n",
            "Batch: 4, Loss: 0.1971447467803955, Accuracy: 0.951171875\n",
            "TEST Loss: 1.5253046751022339, Accuracy: 0.7021484375\n",
            "Batch: 6, Loss: 0.2211819291114807, Accuracy: 0.931640625\n",
            "Batch: 7, Loss: 0.19303077459335327, Accuracy: 0.9462890625\n",
            "Batch: 8, Loss: 0.2077120840549469, Accuracy: 0.9345703125\n",
            "Batch: 9, Loss: 0.2335427701473236, Accuracy: 0.923828125\n",
            "TEST Loss: 1.1837046146392822, Accuracy: 0.7685546875\n",
            "Batch: 11, Loss: 0.2365580052137375, Accuracy: 0.9140625\n",
            "Batch: 12, Loss: 0.2030576467514038, Accuracy: 0.9443359375\n",
            "Batch: 13, Loss: 0.16132716834545135, Accuracy: 0.9580078125\n",
            "Batch: 14, Loss: 0.195403054356575, Accuracy: 0.9453125\n",
            "TEST Loss: 1.0589816570281982, Accuracy: 0.8173828125\n",
            "Batch: 16, Loss: 0.1651557981967926, Accuracy: 0.9599609375\n",
            "Batch: 17, Loss: 0.21997232735157013, Accuracy: 0.93359375\n",
            "Batch: 18, Loss: 0.23943878710269928, Accuracy: 0.92578125\n",
            "Batch: 19, Loss: 0.19188189506530762, Accuracy: 0.9501953125\n",
            "TEST Loss: 1.3997606039047241, Accuracy: 0.751953125\n",
            "Batch: 21, Loss: 0.16716331243515015, Accuracy: 0.9462890625\n",
            "Batch: 22, Loss: 0.18424701690673828, Accuracy: 0.947265625\n",
            "Batch: 23, Loss: 0.21740062534809113, Accuracy: 0.93359375\n",
            "Batch: 24, Loss: 0.22542279958724976, Accuracy: 0.92578125\n",
            "TEST Loss: 1.4204905033111572, Accuracy: 0.7451171875\n",
            "Batch: 26, Loss: 0.19081628322601318, Accuracy: 0.9501953125\n",
            "Batch: 27, Loss: 0.1813928633928299, Accuracy: 0.9482421875\n",
            "Batch: 28, Loss: 0.18359850347042084, Accuracy: 0.9482421875\n",
            "Batch: 29, Loss: 0.18043658137321472, Accuracy: 0.94921875\n",
            "TEST Loss: 1.0529708862304688, Accuracy: 0.8037109375\n",
            "Batch: 31, Loss: 0.17640842497348785, Accuracy: 0.943359375\n",
            "Batch: 32, Loss: 0.18375691771507263, Accuracy: 0.947265625\n",
            "Batch: 33, Loss: 0.19363820552825928, Accuracy: 0.935546875\n",
            "Batch: 34, Loss: 0.23728516697883606, Accuracy: 0.923828125\n",
            "TEST Loss: 0.7151837348937988, Accuracy: 0.8330078125\n",
            "Batch: 36, Loss: 0.18625888228416443, Accuracy: 0.9345703125\n",
            "Batch: 37, Loss: 0.1704058051109314, Accuracy: 0.9580078125\n",
            "Saved Weights at epoch 70 to file Weights_mozart.h5\n",
            "Epoch 71/100\n",
            "Batch: 1, Loss: 0.24298575520515442, Accuracy: 0.931640625\n",
            "Batch: 2, Loss: 0.15927135944366455, Accuracy: 0.9580078125\n",
            "Batch: 3, Loss: 0.23710089921951294, Accuracy: 0.931640625\n",
            "Batch: 4, Loss: 0.20657747983932495, Accuracy: 0.9404296875\n",
            "TEST Loss: 1.447076678276062, Accuracy: 0.7060546875\n",
            "Batch: 6, Loss: 0.22937996685504913, Accuracy: 0.9267578125\n",
            "Batch: 7, Loss: 0.18480205535888672, Accuracy: 0.9404296875\n",
            "Batch: 8, Loss: 0.21410104632377625, Accuracy: 0.9375\n",
            "Batch: 9, Loss: 0.17855772376060486, Accuracy: 0.947265625\n",
            "TEST Loss: 1.2019767761230469, Accuracy: 0.7626953125\n",
            "Batch: 11, Loss: 0.23319029808044434, Accuracy: 0.91796875\n",
            "Batch: 12, Loss: 0.21626165509223938, Accuracy: 0.927734375\n",
            "Batch: 13, Loss: 0.16720548272132874, Accuracy: 0.9482421875\n",
            "Batch: 14, Loss: 0.19833022356033325, Accuracy: 0.9462890625\n",
            "TEST Loss: 1.0610480308532715, Accuracy: 0.814453125\n",
            "Batch: 16, Loss: 0.1882311850786209, Accuracy: 0.9453125\n",
            "Batch: 17, Loss: 0.21504533290863037, Accuracy: 0.9375\n",
            "Batch: 18, Loss: 0.18546079099178314, Accuracy: 0.943359375\n",
            "Batch: 19, Loss: 0.1888066530227661, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.4480884075164795, Accuracy: 0.748046875\n",
            "Batch: 21, Loss: 0.18015843629837036, Accuracy: 0.9404296875\n",
            "Batch: 22, Loss: 0.21392133831977844, Accuracy: 0.9326171875\n",
            "Batch: 23, Loss: 0.21793632209300995, Accuracy: 0.93359375\n",
            "Batch: 24, Loss: 0.2235056757926941, Accuracy: 0.9345703125\n",
            "TEST Loss: 1.4425841569900513, Accuracy: 0.740234375\n",
            "Batch: 26, Loss: 0.18821021914482117, Accuracy: 0.94921875\n",
            "Batch: 27, Loss: 0.1743696928024292, Accuracy: 0.94921875\n",
            "Batch: 28, Loss: 0.1668720245361328, Accuracy: 0.951171875\n",
            "Batch: 29, Loss: 0.184651181101799, Accuracy: 0.9423828125\n",
            "TEST Loss: 1.0643103122711182, Accuracy: 0.8017578125\n",
            "Batch: 31, Loss: 0.19322408735752106, Accuracy: 0.9384765625\n",
            "Batch: 32, Loss: 0.16299273073673248, Accuracy: 0.94921875\n",
            "Batch: 33, Loss: 0.19594880938529968, Accuracy: 0.9423828125\n",
            "Batch: 34, Loss: 0.20271481573581696, Accuracy: 0.943359375\n",
            "TEST Loss: 0.7107746601104736, Accuracy: 0.8359375\n",
            "Batch: 36, Loss: 0.16878217458724976, Accuracy: 0.94921875\n",
            "Batch: 37, Loss: 0.1628236174583435, Accuracy: 0.953125\n",
            "Epoch 72/100\n",
            "Batch: 1, Loss: 0.2631561756134033, Accuracy: 0.923828125\n",
            "Batch: 2, Loss: 0.18096382915973663, Accuracy: 0.9482421875\n",
            "Batch: 3, Loss: 0.19057142734527588, Accuracy: 0.947265625\n",
            "Batch: 4, Loss: 0.1822965294122696, Accuracy: 0.9501953125\n",
            "TEST Loss: 1.5055556297302246, Accuracy: 0.7021484375\n",
            "Batch: 6, Loss: 0.22073513269424438, Accuracy: 0.9345703125\n",
            "Batch: 7, Loss: 0.20044678449630737, Accuracy: 0.9375\n",
            "Batch: 8, Loss: 0.21467097103595734, Accuracy: 0.927734375\n",
            "Batch: 9, Loss: 0.1997721642255783, Accuracy: 0.943359375\n",
            "TEST Loss: 1.178725004196167, Accuracy: 0.7666015625\n",
            "Batch: 11, Loss: 0.20580142736434937, Accuracy: 0.9404296875\n",
            "Batch: 12, Loss: 0.18449649214744568, Accuracy: 0.94140625\n",
            "Batch: 13, Loss: 0.16402822732925415, Accuracy: 0.9482421875\n",
            "Batch: 14, Loss: 0.18342551589012146, Accuracy: 0.9482421875\n",
            "TEST Loss: 1.0954465866088867, Accuracy: 0.814453125\n",
            "Batch: 16, Loss: 0.1767469048500061, Accuracy: 0.9521484375\n",
            "Batch: 17, Loss: 0.2043944001197815, Accuracy: 0.9384765625\n",
            "Batch: 18, Loss: 0.22245356440544128, Accuracy: 0.9345703125\n",
            "Batch: 19, Loss: 0.17724984884262085, Accuracy: 0.95703125\n",
            "TEST Loss: 1.4640212059020996, Accuracy: 0.7353515625\n",
            "Batch: 21, Loss: 0.1657162606716156, Accuracy: 0.9521484375\n",
            "Batch: 22, Loss: 0.19437074661254883, Accuracy: 0.947265625\n",
            "Batch: 23, Loss: 0.2114185094833374, Accuracy: 0.9365234375\n",
            "Batch: 24, Loss: 0.19628050923347473, Accuracy: 0.9482421875\n",
            "TEST Loss: 1.4335992336273193, Accuracy: 0.7451171875\n",
            "Batch: 26, Loss: 0.20335540175437927, Accuracy: 0.9482421875\n",
            "Batch: 27, Loss: 0.17047113180160522, Accuracy: 0.95703125\n",
            "Batch: 28, Loss: 0.15362298488616943, Accuracy: 0.951171875\n",
            "Batch: 29, Loss: 0.17245841026306152, Accuracy: 0.9482421875\n",
            "TEST Loss: 1.0928484201431274, Accuracy: 0.794921875\n",
            "Batch: 31, Loss: 0.16101281344890594, Accuracy: 0.9609375\n",
            "Batch: 32, Loss: 0.18312372267246246, Accuracy: 0.943359375\n",
            "Batch: 33, Loss: 0.17753225564956665, Accuracy: 0.9443359375\n",
            "Batch: 34, Loss: 0.2292603701353073, Accuracy: 0.93359375\n",
            "TEST Loss: 0.6916758418083191, Accuracy: 0.8447265625\n",
            "Batch: 36, Loss: 0.16944286227226257, Accuracy: 0.9462890625\n",
            "Batch: 37, Loss: 0.15471765398979187, Accuracy: 0.9541015625\n",
            "Epoch 73/100\n",
            "Batch: 1, Loss: 0.20575430989265442, Accuracy: 0.9384765625\n",
            "Batch: 2, Loss: 0.19399094581604004, Accuracy: 0.94140625\n",
            "Batch: 3, Loss: 0.2172117829322815, Accuracy: 0.9296875\n",
            "Batch: 4, Loss: 0.18357042968273163, Accuracy: 0.939453125\n",
            "TEST Loss: 1.4499322175979614, Accuracy: 0.7080078125\n",
            "Batch: 6, Loss: 0.20932401716709137, Accuracy: 0.939453125\n",
            "Batch: 7, Loss: 0.1992381513118744, Accuracy: 0.9375\n",
            "Batch: 8, Loss: 0.1959620714187622, Accuracy: 0.947265625\n",
            "Batch: 9, Loss: 0.19559180736541748, Accuracy: 0.939453125\n",
            "TEST Loss: 1.175032377243042, Accuracy: 0.7890625\n",
            "Batch: 11, Loss: 0.2322150468826294, Accuracy: 0.9287109375\n",
            "Batch: 12, Loss: 0.23900429904460907, Accuracy: 0.923828125\n",
            "Batch: 13, Loss: 0.18139944970607758, Accuracy: 0.9375\n",
            "Batch: 14, Loss: 0.17167118191719055, Accuracy: 0.95703125\n",
            "TEST Loss: 1.0995206832885742, Accuracy: 0.8134765625\n",
            "Batch: 16, Loss: 0.1650334894657135, Accuracy: 0.9501953125\n",
            "Batch: 17, Loss: 0.18343664705753326, Accuracy: 0.9453125\n",
            "Batch: 18, Loss: 0.20923469960689545, Accuracy: 0.9404296875\n",
            "Batch: 19, Loss: 0.184978187084198, Accuracy: 0.9482421875\n",
            "TEST Loss: 1.4767372608184814, Accuracy: 0.748046875\n",
            "Batch: 21, Loss: 0.1620422750711441, Accuracy: 0.958984375\n",
            "Batch: 22, Loss: 0.19073747098445892, Accuracy: 0.947265625\n",
            "Batch: 23, Loss: 0.2430272251367569, Accuracy: 0.92578125\n",
            "Batch: 24, Loss: 0.1976318061351776, Accuracy: 0.94140625\n",
            "TEST Loss: 1.4990719556808472, Accuracy: 0.736328125\n",
            "Batch: 26, Loss: 0.18264344334602356, Accuracy: 0.951171875\n",
            "Batch: 27, Loss: 0.1892428994178772, Accuracy: 0.939453125\n",
            "Batch: 28, Loss: 0.16171790659427643, Accuracy: 0.951171875\n",
            "Batch: 29, Loss: 0.1568727344274521, Accuracy: 0.958984375\n",
            "TEST Loss: 1.0345845222473145, Accuracy: 0.8125\n",
            "Batch: 31, Loss: 0.1699943095445633, Accuracy: 0.9521484375\n",
            "Batch: 32, Loss: 0.19390715658664703, Accuracy: 0.943359375\n",
            "Batch: 33, Loss: 0.19598783552646637, Accuracy: 0.9365234375\n",
            "Batch: 34, Loss: 0.22000467777252197, Accuracy: 0.9267578125\n",
            "TEST Loss: 0.7061554193496704, Accuracy: 0.8369140625\n",
            "Batch: 36, Loss: 0.15942586958408356, Accuracy: 0.9521484375\n",
            "Batch: 37, Loss: 0.15900027751922607, Accuracy: 0.9560546875\n",
            "Epoch 74/100\n",
            "Batch: 1, Loss: 0.22071731090545654, Accuracy: 0.9423828125\n",
            "Batch: 2, Loss: 0.16951653361320496, Accuracy: 0.94921875\n",
            "Batch: 3, Loss: 0.20946341753005981, Accuracy: 0.935546875\n",
            "Batch: 4, Loss: 0.18135863542556763, Accuracy: 0.94921875\n",
            "TEST Loss: 1.5031452178955078, Accuracy: 0.70703125\n",
            "Batch: 6, Loss: 0.19859091937541962, Accuracy: 0.9375\n",
            "Batch: 7, Loss: 0.16287055611610413, Accuracy: 0.9541015625\n",
            "Batch: 8, Loss: 0.20008209347724915, Accuracy: 0.9443359375\n",
            "Batch: 9, Loss: 0.18878459930419922, Accuracy: 0.9453125\n",
            "TEST Loss: 1.1850306987762451, Accuracy: 0.78125\n",
            "Batch: 11, Loss: 0.2171083688735962, Accuracy: 0.9287109375\n",
            "Batch: 12, Loss: 0.17844122648239136, Accuracy: 0.9482421875\n",
            "Batch: 13, Loss: 0.16773159801959991, Accuracy: 0.9541015625\n",
            "Batch: 14, Loss: 0.1667199730873108, Accuracy: 0.9482421875\n",
            "TEST Loss: 1.1106986999511719, Accuracy: 0.8037109375\n",
            "Batch: 16, Loss: 0.16979220509529114, Accuracy: 0.9541015625\n",
            "Batch: 17, Loss: 0.18066351115703583, Accuracy: 0.9375\n",
            "Batch: 18, Loss: 0.2138381004333496, Accuracy: 0.935546875\n",
            "Batch: 19, Loss: 0.19203795492649078, Accuracy: 0.947265625\n",
            "TEST Loss: 1.4664852619171143, Accuracy: 0.74609375\n",
            "Batch: 21, Loss: 0.1607849895954132, Accuracy: 0.9462890625\n",
            "Batch: 22, Loss: 0.20166943967342377, Accuracy: 0.9384765625\n",
            "Batch: 23, Loss: 0.18837377429008484, Accuracy: 0.9404296875\n",
            "Batch: 24, Loss: 0.17793910205364227, Accuracy: 0.9501953125\n",
            "TEST Loss: 1.4535801410675049, Accuracy: 0.7392578125\n",
            "Batch: 26, Loss: 0.1925894170999527, Accuracy: 0.947265625\n",
            "Batch: 27, Loss: 0.1762600541114807, Accuracy: 0.953125\n",
            "Batch: 28, Loss: 0.15101784467697144, Accuracy: 0.9541015625\n",
            "Batch: 29, Loss: 0.16898474097251892, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.0539519786834717, Accuracy: 0.80859375\n",
            "Batch: 31, Loss: 0.14665710926055908, Accuracy: 0.9609375\n",
            "Batch: 32, Loss: 0.14902564883232117, Accuracy: 0.958984375\n",
            "Batch: 33, Loss: 0.20644891262054443, Accuracy: 0.94140625\n",
            "Batch: 34, Loss: 0.20308634638786316, Accuracy: 0.939453125\n",
            "TEST Loss: 0.6840837001800537, Accuracy: 0.8466796875\n",
            "Batch: 36, Loss: 0.16628830134868622, Accuracy: 0.9462890625\n",
            "Batch: 37, Loss: 0.15669572353363037, Accuracy: 0.95703125\n",
            "Epoch 75/100\n",
            "Batch: 1, Loss: 0.19889569282531738, Accuracy: 0.94921875\n",
            "Batch: 2, Loss: 0.20304763317108154, Accuracy: 0.935546875\n",
            "Batch: 3, Loss: 0.19961267709732056, Accuracy: 0.94140625\n",
            "Batch: 4, Loss: 0.19168102741241455, Accuracy: 0.9423828125\n",
            "TEST Loss: 1.4875900745391846, Accuracy: 0.7119140625\n",
            "Batch: 6, Loss: 0.2191610336303711, Accuracy: 0.9287109375\n",
            "Batch: 7, Loss: 0.1964026689529419, Accuracy: 0.9482421875\n",
            "Batch: 8, Loss: 0.18057559430599213, Accuracy: 0.94140625\n",
            "Batch: 9, Loss: 0.1911301463842392, Accuracy: 0.9443359375\n",
            "TEST Loss: 1.217071533203125, Accuracy: 0.7685546875\n",
            "Batch: 11, Loss: 0.20814335346221924, Accuracy: 0.939453125\n",
            "Batch: 12, Loss: 0.17863675951957703, Accuracy: 0.9501953125\n",
            "Batch: 13, Loss: 0.14744839072227478, Accuracy: 0.951171875\n",
            "Batch: 14, Loss: 0.17997030913829803, Accuracy: 0.9453125\n",
            "TEST Loss: 1.0897201299667358, Accuracy: 0.822265625\n",
            "Batch: 16, Loss: 0.15778429806232452, Accuracy: 0.9541015625\n",
            "Batch: 17, Loss: 0.21357691287994385, Accuracy: 0.935546875\n",
            "Batch: 18, Loss: 0.2037612497806549, Accuracy: 0.9423828125\n",
            "Batch: 19, Loss: 0.17094933986663818, Accuracy: 0.955078125\n",
            "TEST Loss: 1.4852120876312256, Accuracy: 0.744140625\n",
            "Batch: 21, Loss: 0.14671528339385986, Accuracy: 0.9619140625\n",
            "Batch: 22, Loss: 0.17201349139213562, Accuracy: 0.951171875\n",
            "Batch: 23, Loss: 0.21305808424949646, Accuracy: 0.9365234375\n",
            "Batch: 24, Loss: 0.20495328307151794, Accuracy: 0.9453125\n",
            "TEST Loss: 1.5084593296051025, Accuracy: 0.7412109375\n",
            "Batch: 26, Loss: 0.15322522819042206, Accuracy: 0.95703125\n",
            "Batch: 27, Loss: 0.1630820333957672, Accuracy: 0.951171875\n",
            "Batch: 28, Loss: 0.1532112956047058, Accuracy: 0.958984375\n",
            "Batch: 29, Loss: 0.15102441608905792, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.0659334659576416, Accuracy: 0.8076171875\n",
            "Batch: 31, Loss: 0.17985886335372925, Accuracy: 0.947265625\n",
            "Batch: 32, Loss: 0.15319974720478058, Accuracy: 0.9521484375\n",
            "Batch: 33, Loss: 0.1930135041475296, Accuracy: 0.9404296875\n",
            "Batch: 34, Loss: 0.1822330355644226, Accuracy: 0.94140625\n",
            "TEST Loss: 0.7093350887298584, Accuracy: 0.83984375\n",
            "Batch: 36, Loss: 0.13623781502246857, Accuracy: 0.9560546875\n",
            "Batch: 37, Loss: 0.14027287065982819, Accuracy: 0.95703125\n",
            "Epoch 76/100\n",
            "Batch: 1, Loss: 0.21935708820819855, Accuracy: 0.9365234375\n",
            "Batch: 2, Loss: 0.1724979430437088, Accuracy: 0.9443359375\n",
            "Batch: 3, Loss: 0.18494994938373566, Accuracy: 0.9501953125\n",
            "Batch: 4, Loss: 0.1699800193309784, Accuracy: 0.9541015625\n",
            "TEST Loss: 1.5043108463287354, Accuracy: 0.708984375\n",
            "Batch: 6, Loss: 0.16894572973251343, Accuracy: 0.9501953125\n",
            "Batch: 7, Loss: 0.20038360357284546, Accuracy: 0.9423828125\n",
            "Batch: 8, Loss: 0.19264745712280273, Accuracy: 0.9453125\n",
            "Batch: 9, Loss: 0.16507628560066223, Accuracy: 0.9580078125\n",
            "TEST Loss: 1.191723346710205, Accuracy: 0.7802734375\n",
            "Batch: 11, Loss: 0.2116883248090744, Accuracy: 0.9267578125\n",
            "Batch: 12, Loss: 0.1927715539932251, Accuracy: 0.943359375\n",
            "Batch: 13, Loss: 0.15467402338981628, Accuracy: 0.9541015625\n",
            "Batch: 14, Loss: 0.15636348724365234, Accuracy: 0.95703125\n",
            "TEST Loss: 1.0909333229064941, Accuracy: 0.8125\n",
            "Batch: 16, Loss: 0.1668337881565094, Accuracy: 0.947265625\n",
            "Batch: 17, Loss: 0.1912013590335846, Accuracy: 0.943359375\n",
            "Batch: 18, Loss: 0.19362041354179382, Accuracy: 0.9443359375\n",
            "Batch: 19, Loss: 0.16474288702011108, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.451158046722412, Accuracy: 0.7509765625\n",
            "Batch: 21, Loss: 0.14351531863212585, Accuracy: 0.9580078125\n",
            "Batch: 22, Loss: 0.17852267622947693, Accuracy: 0.953125\n",
            "Batch: 23, Loss: 0.19823232293128967, Accuracy: 0.9326171875\n",
            "Batch: 24, Loss: 0.17850297689437866, Accuracy: 0.94921875\n",
            "TEST Loss: 1.5385589599609375, Accuracy: 0.740234375\n",
            "Batch: 26, Loss: 0.18864648044109344, Accuracy: 0.947265625\n",
            "Batch: 27, Loss: 0.1411987543106079, Accuracy: 0.95703125\n",
            "Batch: 28, Loss: 0.12851965427398682, Accuracy: 0.96484375\n",
            "Batch: 29, Loss: 0.1538739800453186, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.0175871849060059, Accuracy: 0.8115234375\n",
            "Batch: 31, Loss: 0.16474062204360962, Accuracy: 0.953125\n",
            "Batch: 32, Loss: 0.15948066115379333, Accuracy: 0.9443359375\n",
            "Batch: 33, Loss: 0.1645963042974472, Accuracy: 0.94921875\n",
            "Batch: 34, Loss: 0.19248485565185547, Accuracy: 0.94921875\n",
            "TEST Loss: 0.70187908411026, Accuracy: 0.833984375\n",
            "Batch: 36, Loss: 0.14917761087417603, Accuracy: 0.9560546875\n",
            "Batch: 37, Loss: 0.14800295233726501, Accuracy: 0.95703125\n",
            "Epoch 77/100\n",
            "Batch: 1, Loss: 0.1988014578819275, Accuracy: 0.943359375\n",
            "Batch: 2, Loss: 0.14950844645500183, Accuracy: 0.955078125\n",
            "Batch: 3, Loss: 0.20173561573028564, Accuracy: 0.947265625\n",
            "Batch: 4, Loss: 0.15768074989318848, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.50390625, Accuracy: 0.7099609375\n",
            "Batch: 6, Loss: 0.167555570602417, Accuracy: 0.9453125\n",
            "Batch: 7, Loss: 0.17136922478675842, Accuracy: 0.9423828125\n",
            "Batch: 8, Loss: 0.17744332551956177, Accuracy: 0.9443359375\n",
            "Batch: 9, Loss: 0.1924949288368225, Accuracy: 0.9375\n",
            "TEST Loss: 1.207442283630371, Accuracy: 0.7734375\n",
            "Batch: 11, Loss: 0.19629916548728943, Accuracy: 0.9384765625\n",
            "Batch: 12, Loss: 0.17683562636375427, Accuracy: 0.9443359375\n",
            "Batch: 13, Loss: 0.15166926383972168, Accuracy: 0.9462890625\n",
            "Batch: 14, Loss: 0.1586403101682663, Accuracy: 0.9482421875\n",
            "TEST Loss: 1.1192840337753296, Accuracy: 0.80859375\n",
            "Batch: 16, Loss: 0.15381750464439392, Accuracy: 0.9541015625\n",
            "Batch: 17, Loss: 0.19430133700370789, Accuracy: 0.943359375\n",
            "Batch: 18, Loss: 0.20032303035259247, Accuracy: 0.94140625\n",
            "Batch: 19, Loss: 0.1444128155708313, Accuracy: 0.962890625\n",
            "TEST Loss: 1.4627476930618286, Accuracy: 0.751953125\n",
            "Batch: 21, Loss: 0.15121284127235413, Accuracy: 0.9501953125\n",
            "Batch: 22, Loss: 0.1345043182373047, Accuracy: 0.9677734375\n",
            "Batch: 23, Loss: 0.2063976228237152, Accuracy: 0.9365234375\n",
            "Batch: 24, Loss: 0.1903790533542633, Accuracy: 0.94140625\n",
            "TEST Loss: 1.5476287603378296, Accuracy: 0.740234375\n",
            "Batch: 26, Loss: 0.18159694969654083, Accuracy: 0.9404296875\n",
            "Batch: 27, Loss: 0.12254441529512405, Accuracy: 0.962890625\n",
            "Batch: 28, Loss: 0.15488260984420776, Accuracy: 0.9521484375\n",
            "Batch: 29, Loss: 0.17095112800598145, Accuracy: 0.955078125\n",
            "TEST Loss: 1.0928068161010742, Accuracy: 0.7958984375\n",
            "Batch: 31, Loss: 0.14364640414714813, Accuracy: 0.953125\n",
            "Batch: 32, Loss: 0.16897593438625336, Accuracy: 0.9501953125\n",
            "Batch: 33, Loss: 0.17918437719345093, Accuracy: 0.9501953125\n",
            "Batch: 34, Loss: 0.1846807897090912, Accuracy: 0.951171875\n",
            "TEST Loss: 0.706051230430603, Accuracy: 0.837890625\n",
            "Batch: 36, Loss: 0.13104045391082764, Accuracy: 0.9560546875\n",
            "Batch: 37, Loss: 0.14177677035331726, Accuracy: 0.9560546875\n",
            "Epoch 78/100\n",
            "Batch: 1, Loss: 0.20303449034690857, Accuracy: 0.9443359375\n",
            "Batch: 2, Loss: 0.16489607095718384, Accuracy: 0.955078125\n",
            "Batch: 3, Loss: 0.2020750641822815, Accuracy: 0.935546875\n",
            "Batch: 4, Loss: 0.183309406042099, Accuracy: 0.9443359375\n",
            "TEST Loss: 1.5224241018295288, Accuracy: 0.712890625\n",
            "Batch: 6, Loss: 0.18445302546024323, Accuracy: 0.9501953125\n",
            "Batch: 7, Loss: 0.15510784089565277, Accuracy: 0.9521484375\n",
            "Batch: 8, Loss: 0.16528895497322083, Accuracy: 0.9453125\n",
            "Batch: 9, Loss: 0.16990190744400024, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.1976664066314697, Accuracy: 0.78125\n",
            "Batch: 11, Loss: 0.2083818018436432, Accuracy: 0.9287109375\n",
            "Batch: 12, Loss: 0.16461041569709778, Accuracy: 0.9443359375\n",
            "Batch: 13, Loss: 0.1386808454990387, Accuracy: 0.9609375\n",
            "Batch: 14, Loss: 0.1479383111000061, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.1200867891311646, Accuracy: 0.8115234375\n",
            "Batch: 16, Loss: 0.15587198734283447, Accuracy: 0.9619140625\n",
            "Batch: 17, Loss: 0.16368593275547028, Accuracy: 0.9521484375\n",
            "Batch: 18, Loss: 0.17649030685424805, Accuracy: 0.9541015625\n",
            "Batch: 19, Loss: 0.15499866008758545, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.4665014743804932, Accuracy: 0.75390625\n",
            "Batch: 21, Loss: 0.1417785882949829, Accuracy: 0.955078125\n",
            "Batch: 22, Loss: 0.17388620972633362, Accuracy: 0.94921875\n",
            "Batch: 23, Loss: 0.20217451453208923, Accuracy: 0.943359375\n",
            "Batch: 24, Loss: 0.16842612624168396, Accuracy: 0.951171875\n",
            "TEST Loss: 1.537653923034668, Accuracy: 0.7353515625\n",
            "Batch: 26, Loss: 0.1745511293411255, Accuracy: 0.9521484375\n",
            "Batch: 27, Loss: 0.148062601685524, Accuracy: 0.9580078125\n",
            "Batch: 28, Loss: 0.13722380995750427, Accuracy: 0.9619140625\n",
            "Batch: 29, Loss: 0.1555650383234024, Accuracy: 0.953125\n",
            "TEST Loss: 1.1026500463485718, Accuracy: 0.810546875\n",
            "Batch: 31, Loss: 0.14983434975147247, Accuracy: 0.94921875\n",
            "Batch: 32, Loss: 0.1422119438648224, Accuracy: 0.958984375\n",
            "Batch: 33, Loss: 0.14311915636062622, Accuracy: 0.9541015625\n",
            "Batch: 34, Loss: 0.210658460855484, Accuracy: 0.9404296875\n",
            "TEST Loss: 0.7110840678215027, Accuracy: 0.837890625\n",
            "Batch: 36, Loss: 0.13358505070209503, Accuracy: 0.9580078125\n",
            "Batch: 37, Loss: 0.13860908150672913, Accuracy: 0.9609375\n",
            "Epoch 79/100\n",
            "Batch: 1, Loss: 0.20819208025932312, Accuracy: 0.951171875\n",
            "Batch: 2, Loss: 0.16973599791526794, Accuracy: 0.9443359375\n",
            "Batch: 3, Loss: 0.1841021329164505, Accuracy: 0.9619140625\n",
            "Batch: 4, Loss: 0.16487151384353638, Accuracy: 0.953125\n",
            "TEST Loss: 1.456626534461975, Accuracy: 0.7158203125\n",
            "Batch: 6, Loss: 0.19098566472530365, Accuracy: 0.939453125\n",
            "Batch: 7, Loss: 0.16441161930561066, Accuracy: 0.9482421875\n",
            "Batch: 8, Loss: 0.15309348702430725, Accuracy: 0.9560546875\n",
            "Batch: 9, Loss: 0.16327707469463348, Accuracy: 0.955078125\n",
            "TEST Loss: 1.213213562965393, Accuracy: 0.7763671875\n",
            "Batch: 11, Loss: 0.18848058581352234, Accuracy: 0.9423828125\n",
            "Batch: 12, Loss: 0.1720026433467865, Accuracy: 0.9521484375\n",
            "Batch: 13, Loss: 0.13690122961997986, Accuracy: 0.96484375\n",
            "Batch: 14, Loss: 0.15663112699985504, Accuracy: 0.955078125\n",
            "TEST Loss: 1.1347696781158447, Accuracy: 0.818359375\n",
            "Batch: 16, Loss: 0.14028237760066986, Accuracy: 0.966796875\n",
            "Batch: 17, Loss: 0.17037007212638855, Accuracy: 0.9501953125\n",
            "Batch: 18, Loss: 0.1898660659790039, Accuracy: 0.943359375\n",
            "Batch: 19, Loss: 0.1402978003025055, Accuracy: 0.95703125\n",
            "TEST Loss: 1.480189323425293, Accuracy: 0.7607421875\n",
            "Batch: 21, Loss: 0.13170966506004333, Accuracy: 0.9677734375\n",
            "Batch: 22, Loss: 0.15489532053470612, Accuracy: 0.9609375\n",
            "Batch: 23, Loss: 0.1785287857055664, Accuracy: 0.9462890625\n",
            "Batch: 24, Loss: 0.16766667366027832, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.5271209478378296, Accuracy: 0.7421875\n",
            "Batch: 26, Loss: 0.1385233849287033, Accuracy: 0.96484375\n",
            "Batch: 27, Loss: 0.13953405618667603, Accuracy: 0.958984375\n",
            "Batch: 28, Loss: 0.14420533180236816, Accuracy: 0.955078125\n",
            "Batch: 29, Loss: 0.14053426682949066, Accuracy: 0.95703125\n",
            "TEST Loss: 1.0710794925689697, Accuracy: 0.8095703125\n",
            "Batch: 31, Loss: 0.16384613513946533, Accuracy: 0.94921875\n",
            "Batch: 32, Loss: 0.15162788331508636, Accuracy: 0.9560546875\n",
            "Batch: 33, Loss: 0.15061526000499725, Accuracy: 0.94921875\n",
            "Batch: 34, Loss: 0.18258288502693176, Accuracy: 0.9482421875\n",
            "TEST Loss: 0.7157721519470215, Accuracy: 0.83984375\n",
            "Batch: 36, Loss: 0.1640094667673111, Accuracy: 0.94921875\n",
            "Batch: 37, Loss: 0.15068934857845306, Accuracy: 0.9560546875\n",
            "Epoch 80/100\n",
            "Batch: 1, Loss: 0.19555522501468658, Accuracy: 0.9462890625\n",
            "Batch: 2, Loss: 0.1548784077167511, Accuracy: 0.953125\n",
            "Batch: 3, Loss: 0.19418294727802277, Accuracy: 0.9453125\n",
            "Batch: 4, Loss: 0.1446148157119751, Accuracy: 0.953125\n",
            "TEST Loss: 1.5245888233184814, Accuracy: 0.71484375\n",
            "Batch: 6, Loss: 0.19410118460655212, Accuracy: 0.9462890625\n",
            "Batch: 7, Loss: 0.17034916579723358, Accuracy: 0.9560546875\n",
            "Batch: 8, Loss: 0.15577755868434906, Accuracy: 0.953125\n",
            "Batch: 9, Loss: 0.1698734164237976, Accuracy: 0.9501953125\n",
            "TEST Loss: 1.189424753189087, Accuracy: 0.7802734375\n",
            "Batch: 11, Loss: 0.18764658272266388, Accuracy: 0.94921875\n",
            "Batch: 12, Loss: 0.1759277731180191, Accuracy: 0.9501953125\n",
            "Batch: 13, Loss: 0.16250871121883392, Accuracy: 0.951171875\n",
            "Batch: 14, Loss: 0.16891920566558838, Accuracy: 0.9462890625\n",
            "TEST Loss: 1.1451747417449951, Accuracy: 0.8173828125\n",
            "Batch: 16, Loss: 0.12282684445381165, Accuracy: 0.9677734375\n",
            "Batch: 17, Loss: 0.17737334966659546, Accuracy: 0.9384765625\n",
            "Batch: 18, Loss: 0.17667484283447266, Accuracy: 0.9541015625\n",
            "Batch: 19, Loss: 0.15090835094451904, Accuracy: 0.9599609375\n",
            "TEST Loss: 1.5238276720046997, Accuracy: 0.7529296875\n",
            "Batch: 21, Loss: 0.15396028757095337, Accuracy: 0.9560546875\n",
            "Batch: 22, Loss: 0.1550265997648239, Accuracy: 0.953125\n",
            "Batch: 23, Loss: 0.15976263582706451, Accuracy: 0.9521484375\n",
            "Batch: 24, Loss: 0.17124271392822266, Accuracy: 0.953125\n",
            "TEST Loss: 1.5782853364944458, Accuracy: 0.7373046875\n",
            "Batch: 26, Loss: 0.14842677116394043, Accuracy: 0.9599609375\n",
            "Batch: 27, Loss: 0.1394188106060028, Accuracy: 0.9619140625\n",
            "Batch: 28, Loss: 0.15751251578330994, Accuracy: 0.955078125\n",
            "Batch: 29, Loss: 0.13731780648231506, Accuracy: 0.9638671875\n",
            "TEST Loss: 1.0884206295013428, Accuracy: 0.802734375\n",
            "Batch: 31, Loss: 0.1510753631591797, Accuracy: 0.9609375\n",
            "Batch: 32, Loss: 0.14164340496063232, Accuracy: 0.9599609375\n",
            "Batch: 33, Loss: 0.1623588502407074, Accuracy: 0.953125\n",
            "Batch: 34, Loss: 0.1965143233537674, Accuracy: 0.9423828125\n",
            "TEST Loss: 0.6886622905731201, Accuracy: 0.8427734375\n",
            "Batch: 36, Loss: 0.14255401492118835, Accuracy: 0.9609375\n",
            "Batch: 37, Loss: 0.12781259417533875, Accuracy: 0.9619140625\n",
            "Saved Weights at epoch 80 to file Weights_mozart.h5\n",
            "Epoch 81/100\n",
            "Batch: 1, Loss: 0.1844319999217987, Accuracy: 0.9453125\n",
            "Batch: 2, Loss: 0.14645279943943024, Accuracy: 0.9609375\n",
            "Batch: 3, Loss: 0.18880963325500488, Accuracy: 0.9453125\n",
            "Batch: 4, Loss: 0.139984592795372, Accuracy: 0.9658203125\n",
            "TEST Loss: 1.5114548206329346, Accuracy: 0.7109375\n",
            "Batch: 6, Loss: 0.17677092552185059, Accuracy: 0.9482421875\n",
            "Batch: 7, Loss: 0.14539644122123718, Accuracy: 0.958984375\n",
            "Batch: 8, Loss: 0.17290480434894562, Accuracy: 0.9462890625\n",
            "Batch: 9, Loss: 0.17276962101459503, Accuracy: 0.953125\n",
            "TEST Loss: 1.1888524293899536, Accuracy: 0.78515625\n",
            "Batch: 11, Loss: 0.18399490416049957, Accuracy: 0.939453125\n",
            "Batch: 12, Loss: 0.16832822561264038, Accuracy: 0.9482421875\n",
            "Batch: 13, Loss: 0.1587693691253662, Accuracy: 0.9443359375\n",
            "Batch: 14, Loss: 0.1536915898323059, Accuracy: 0.9541015625\n",
            "TEST Loss: 1.116135835647583, Accuracy: 0.810546875\n",
            "Batch: 16, Loss: 0.14178268611431122, Accuracy: 0.9638671875\n",
            "Batch: 17, Loss: 0.15833055973052979, Accuracy: 0.9609375\n",
            "Batch: 18, Loss: 0.17790697515010834, Accuracy: 0.9501953125\n",
            "Batch: 19, Loss: 0.1356327086687088, Accuracy: 0.9599609375\n",
            "TEST Loss: 1.498089075088501, Accuracy: 0.75390625\n",
            "Batch: 21, Loss: 0.15622451901435852, Accuracy: 0.9560546875\n",
            "Batch: 22, Loss: 0.1737421751022339, Accuracy: 0.94921875\n",
            "Batch: 23, Loss: 0.18310734629631042, Accuracy: 0.94140625\n",
            "Batch: 24, Loss: 0.1796114444732666, Accuracy: 0.947265625\n",
            "TEST Loss: 1.5187978744506836, Accuracy: 0.744140625\n",
            "Batch: 26, Loss: 0.1651119887828827, Accuracy: 0.95703125\n",
            "Batch: 27, Loss: 0.17326371371746063, Accuracy: 0.947265625\n",
            "Batch: 28, Loss: 0.12592750787734985, Accuracy: 0.96875\n",
            "Batch: 29, Loss: 0.1481173038482666, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.0825834274291992, Accuracy: 0.8154296875\n",
            "Batch: 31, Loss: 0.13721641898155212, Accuracy: 0.9658203125\n",
            "Batch: 32, Loss: 0.1415790319442749, Accuracy: 0.953125\n",
            "Batch: 33, Loss: 0.16665124893188477, Accuracy: 0.9482421875\n",
            "Batch: 34, Loss: 0.1624089926481247, Accuracy: 0.947265625\n",
            "TEST Loss: 0.6962710618972778, Accuracy: 0.841796875\n",
            "Batch: 36, Loss: 0.1580529510974884, Accuracy: 0.9501953125\n",
            "Batch: 37, Loss: 0.13736236095428467, Accuracy: 0.9541015625\n",
            "Epoch 82/100\n",
            "Batch: 1, Loss: 0.17969608306884766, Accuracy: 0.953125\n",
            "Batch: 2, Loss: 0.12188006937503815, Accuracy: 0.962890625\n",
            "Batch: 3, Loss: 0.1873386800289154, Accuracy: 0.947265625\n",
            "Batch: 4, Loss: 0.15974953770637512, Accuracy: 0.9501953125\n",
            "TEST Loss: 1.5733041763305664, Accuracy: 0.7158203125\n",
            "Batch: 6, Loss: 0.17869749665260315, Accuracy: 0.9443359375\n",
            "Batch: 7, Loss: 0.1553427129983902, Accuracy: 0.955078125\n",
            "Batch: 8, Loss: 0.16921645402908325, Accuracy: 0.9443359375\n",
            "Batch: 9, Loss: 0.15469668805599213, Accuracy: 0.953125\n",
            "TEST Loss: 1.2237370014190674, Accuracy: 0.78125\n",
            "Batch: 11, Loss: 0.20076778531074524, Accuracy: 0.931640625\n",
            "Batch: 12, Loss: 0.13919565081596375, Accuracy: 0.95703125\n",
            "Batch: 13, Loss: 0.14559327065944672, Accuracy: 0.9541015625\n",
            "Batch: 14, Loss: 0.14482703804969788, Accuracy: 0.958984375\n",
            "TEST Loss: 1.135091781616211, Accuracy: 0.8271484375\n",
            "Batch: 16, Loss: 0.14437663555145264, Accuracy: 0.96484375\n",
            "Batch: 17, Loss: 0.1489970088005066, Accuracy: 0.9541015625\n",
            "Batch: 18, Loss: 0.16045530140399933, Accuracy: 0.9482421875\n",
            "Batch: 19, Loss: 0.1442476511001587, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.5154776573181152, Accuracy: 0.7490234375\n",
            "Batch: 21, Loss: 0.1329626441001892, Accuracy: 0.95703125\n",
            "Batch: 22, Loss: 0.15337327122688293, Accuracy: 0.95703125\n",
            "Batch: 23, Loss: 0.14985539019107819, Accuracy: 0.953125\n",
            "Batch: 24, Loss: 0.1674565225839615, Accuracy: 0.9501953125\n",
            "TEST Loss: 1.5359097719192505, Accuracy: 0.73828125\n",
            "Batch: 26, Loss: 0.15343204140663147, Accuracy: 0.9609375\n",
            "Batch: 27, Loss: 0.11088255047798157, Accuracy: 0.974609375\n",
            "Batch: 28, Loss: 0.14815878868103027, Accuracy: 0.9541015625\n",
            "Batch: 29, Loss: 0.1572297215461731, Accuracy: 0.951171875\n",
            "TEST Loss: 1.1397663354873657, Accuracy: 0.80078125\n",
            "Batch: 31, Loss: 0.13712404668331146, Accuracy: 0.9619140625\n",
            "Batch: 32, Loss: 0.11620309948921204, Accuracy: 0.970703125\n",
            "Batch: 33, Loss: 0.16521558165550232, Accuracy: 0.9501953125\n",
            "Batch: 34, Loss: 0.16898472607135773, Accuracy: 0.9453125\n",
            "TEST Loss: 0.6835370659828186, Accuracy: 0.8427734375\n",
            "Batch: 36, Loss: 0.15768131613731384, Accuracy: 0.951171875\n",
            "Batch: 37, Loss: 0.12313694506883621, Accuracy: 0.9609375\n",
            "Epoch 83/100\n",
            "Batch: 1, Loss: 0.17887139320373535, Accuracy: 0.9501953125\n",
            "Batch: 2, Loss: 0.14846311509609222, Accuracy: 0.9541015625\n",
            "Batch: 3, Loss: 0.1839390993118286, Accuracy: 0.94140625\n",
            "Batch: 4, Loss: 0.1671677529811859, Accuracy: 0.943359375\n",
            "TEST Loss: 1.511233925819397, Accuracy: 0.71484375\n",
            "Batch: 6, Loss: 0.14703845977783203, Accuracy: 0.9580078125\n",
            "Batch: 7, Loss: 0.14533060789108276, Accuracy: 0.9619140625\n",
            "Batch: 8, Loss: 0.14131003618240356, Accuracy: 0.9619140625\n",
            "Batch: 9, Loss: 0.141339510679245, Accuracy: 0.9599609375\n",
            "TEST Loss: 1.2038623094558716, Accuracy: 0.77734375\n",
            "Batch: 11, Loss: 0.20572645962238312, Accuracy: 0.9375\n",
            "Batch: 12, Loss: 0.1465735137462616, Accuracy: 0.958984375\n",
            "Batch: 13, Loss: 0.13143764436244965, Accuracy: 0.958984375\n",
            "Batch: 14, Loss: 0.14175385236740112, Accuracy: 0.9580078125\n",
            "TEST Loss: 1.137582778930664, Accuracy: 0.8193359375\n",
            "Batch: 16, Loss: 0.12321490049362183, Accuracy: 0.9697265625\n",
            "Batch: 17, Loss: 0.16227780282497406, Accuracy: 0.955078125\n",
            "Batch: 18, Loss: 0.15674632787704468, Accuracy: 0.955078125\n",
            "Batch: 19, Loss: 0.14797241985797882, Accuracy: 0.95703125\n",
            "TEST Loss: 1.5045650005340576, Accuracy: 0.7529296875\n",
            "Batch: 21, Loss: 0.1288723647594452, Accuracy: 0.9599609375\n",
            "Batch: 22, Loss: 0.14582620561122894, Accuracy: 0.9580078125\n",
            "Batch: 23, Loss: 0.14321109652519226, Accuracy: 0.958984375\n",
            "Batch: 24, Loss: 0.17143365740776062, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.5168509483337402, Accuracy: 0.7490234375\n",
            "Batch: 26, Loss: 0.14610585570335388, Accuracy: 0.966796875\n",
            "Batch: 27, Loss: 0.14148341119289398, Accuracy: 0.9580078125\n",
            "Batch: 28, Loss: 0.10925999283790588, Accuracy: 0.96875\n",
            "Batch: 29, Loss: 0.14309169352054596, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.0799951553344727, Accuracy: 0.802734375\n",
            "Batch: 31, Loss: 0.14251306653022766, Accuracy: 0.958984375\n",
            "Batch: 32, Loss: 0.1484779417514801, Accuracy: 0.9599609375\n",
            "Batch: 33, Loss: 0.1534484326839447, Accuracy: 0.9521484375\n",
            "Batch: 34, Loss: 0.15917319059371948, Accuracy: 0.951171875\n",
            "TEST Loss: 0.7101272344589233, Accuracy: 0.833984375\n",
            "Batch: 36, Loss: 0.12028691172599792, Accuracy: 0.9697265625\n",
            "Batch: 37, Loss: 0.1378532350063324, Accuracy: 0.9609375\n",
            "Epoch 84/100\n",
            "Batch: 1, Loss: 0.16699838638305664, Accuracy: 0.9501953125\n",
            "Batch: 2, Loss: 0.13625648617744446, Accuracy: 0.9599609375\n",
            "Batch: 3, Loss: 0.15381544828414917, Accuracy: 0.962890625\n",
            "Batch: 4, Loss: 0.13447558879852295, Accuracy: 0.9638671875\n",
            "TEST Loss: 1.49492347240448, Accuracy: 0.71484375\n",
            "Batch: 6, Loss: 0.17715536057949066, Accuracy: 0.9501953125\n",
            "Batch: 7, Loss: 0.1365358531475067, Accuracy: 0.96484375\n",
            "Batch: 8, Loss: 0.13553296029567719, Accuracy: 0.9609375\n",
            "Batch: 9, Loss: 0.14256097376346588, Accuracy: 0.95703125\n",
            "TEST Loss: 1.1874266862869263, Accuracy: 0.7880859375\n",
            "Batch: 11, Loss: 0.1742827147245407, Accuracy: 0.943359375\n",
            "Batch: 12, Loss: 0.1571921408176422, Accuracy: 0.94921875\n",
            "Batch: 13, Loss: 0.12298670411109924, Accuracy: 0.9609375\n",
            "Batch: 14, Loss: 0.1517964005470276, Accuracy: 0.953125\n",
            "TEST Loss: 1.1099931001663208, Accuracy: 0.8203125\n",
            "Batch: 16, Loss: 0.1508285105228424, Accuracy: 0.9560546875\n",
            "Batch: 17, Loss: 0.1406097561120987, Accuracy: 0.95703125\n",
            "Batch: 18, Loss: 0.1518990844488144, Accuracy: 0.9619140625\n",
            "Batch: 19, Loss: 0.15720146894454956, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.5127310752868652, Accuracy: 0.7509765625\n",
            "Batch: 21, Loss: 0.11039024591445923, Accuracy: 0.9619140625\n",
            "Batch: 22, Loss: 0.13917574286460876, Accuracy: 0.9580078125\n",
            "Batch: 23, Loss: 0.1813913881778717, Accuracy: 0.9462890625\n",
            "Batch: 24, Loss: 0.16009259223937988, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.609701156616211, Accuracy: 0.728515625\n",
            "Batch: 26, Loss: 0.14697372913360596, Accuracy: 0.9638671875\n",
            "Batch: 27, Loss: 0.1153624951839447, Accuracy: 0.966796875\n",
            "Batch: 28, Loss: 0.12275797873735428, Accuracy: 0.9677734375\n",
            "Batch: 29, Loss: 0.1277032494544983, Accuracy: 0.9638671875\n",
            "TEST Loss: 1.1391693353652954, Accuracy: 0.798828125\n",
            "Batch: 31, Loss: 0.12577833235263824, Accuracy: 0.966796875\n",
            "Batch: 32, Loss: 0.12017367035150528, Accuracy: 0.9677734375\n",
            "Batch: 33, Loss: 0.15130580961704254, Accuracy: 0.9580078125\n",
            "Batch: 34, Loss: 0.1646815538406372, Accuracy: 0.94921875\n",
            "TEST Loss: 0.7258366346359253, Accuracy: 0.841796875\n",
            "Batch: 36, Loss: 0.12803810834884644, Accuracy: 0.966796875\n",
            "Batch: 37, Loss: 0.14237621426582336, Accuracy: 0.958984375\n",
            "Epoch 85/100\n",
            "Batch: 1, Loss: 0.16531357169151306, Accuracy: 0.9599609375\n",
            "Batch: 2, Loss: 0.14947015047073364, Accuracy: 0.955078125\n",
            "Batch: 3, Loss: 0.1573808789253235, Accuracy: 0.951171875\n",
            "Batch: 4, Loss: 0.12883347272872925, Accuracy: 0.96484375\n",
            "TEST Loss: 1.4907571077346802, Accuracy: 0.71875\n",
            "Batch: 6, Loss: 0.1763615906238556, Accuracy: 0.9521484375\n",
            "Batch: 7, Loss: 0.16879944503307343, Accuracy: 0.94140625\n",
            "Batch: 8, Loss: 0.16193270683288574, Accuracy: 0.947265625\n",
            "Batch: 9, Loss: 0.13596799969673157, Accuracy: 0.966796875\n",
            "TEST Loss: 1.2405192852020264, Accuracy: 0.78515625\n",
            "Batch: 11, Loss: 0.16279438138008118, Accuracy: 0.95703125\n",
            "Batch: 12, Loss: 0.18688076734542847, Accuracy: 0.9443359375\n",
            "Batch: 13, Loss: 0.11672329157590866, Accuracy: 0.97265625\n",
            "Batch: 14, Loss: 0.12518681585788727, Accuracy: 0.962890625\n",
            "TEST Loss: 1.1102015972137451, Accuracy: 0.814453125\n",
            "Batch: 16, Loss: 0.1360996961593628, Accuracy: 0.9560546875\n",
            "Batch: 17, Loss: 0.17015567421913147, Accuracy: 0.9443359375\n",
            "Batch: 18, Loss: 0.14802822470664978, Accuracy: 0.958984375\n",
            "Batch: 19, Loss: 0.15052717924118042, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.5415000915527344, Accuracy: 0.7578125\n",
            "Batch: 21, Loss: 0.11162781715393066, Accuracy: 0.9638671875\n",
            "Batch: 22, Loss: 0.14828601479530334, Accuracy: 0.962890625\n",
            "Batch: 23, Loss: 0.19262389838695526, Accuracy: 0.9453125\n",
            "Batch: 24, Loss: 0.16109150648117065, Accuracy: 0.953125\n",
            "TEST Loss: 1.6105694770812988, Accuracy: 0.7412109375\n",
            "Batch: 26, Loss: 0.14670595526695251, Accuracy: 0.9638671875\n",
            "Batch: 27, Loss: 0.13838979601860046, Accuracy: 0.9609375\n",
            "Batch: 28, Loss: 0.11543530225753784, Accuracy: 0.96484375\n",
            "Batch: 29, Loss: 0.13271218538284302, Accuracy: 0.958984375\n",
            "TEST Loss: 1.11460280418396, Accuracy: 0.7978515625\n",
            "Batch: 31, Loss: 0.12182368338108063, Accuracy: 0.9638671875\n",
            "Batch: 32, Loss: 0.14986151456832886, Accuracy: 0.953125\n",
            "Batch: 33, Loss: 0.1304072141647339, Accuracy: 0.958984375\n",
            "Batch: 34, Loss: 0.16584955155849457, Accuracy: 0.9443359375\n",
            "TEST Loss: 0.7293140888214111, Accuracy: 0.8310546875\n",
            "Batch: 36, Loss: 0.1387251764535904, Accuracy: 0.958984375\n",
            "Batch: 37, Loss: 0.13589178025722504, Accuracy: 0.962890625\n",
            "Epoch 86/100\n",
            "Batch: 1, Loss: 0.16745556890964508, Accuracy: 0.9521484375\n",
            "Batch: 2, Loss: 0.14792266488075256, Accuracy: 0.9541015625\n",
            "Batch: 3, Loss: 0.16418537497520447, Accuracy: 0.9521484375\n",
            "Batch: 4, Loss: 0.12445028126239777, Accuracy: 0.96484375\n",
            "TEST Loss: 1.4442381858825684, Accuracy: 0.7216796875\n",
            "Batch: 6, Loss: 0.1574227511882782, Accuracy: 0.94921875\n",
            "Batch: 7, Loss: 0.14793866872787476, Accuracy: 0.9609375\n",
            "Batch: 8, Loss: 0.15700459480285645, Accuracy: 0.9501953125\n",
            "Batch: 9, Loss: 0.1371394395828247, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.2500004768371582, Accuracy: 0.7802734375\n",
            "Batch: 11, Loss: 0.16187900304794312, Accuracy: 0.9580078125\n",
            "Batch: 12, Loss: 0.15346692502498627, Accuracy: 0.9541015625\n",
            "Batch: 13, Loss: 0.12116377055644989, Accuracy: 0.9619140625\n",
            "Batch: 14, Loss: 0.14044898748397827, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.1347360610961914, Accuracy: 0.818359375\n",
            "Batch: 16, Loss: 0.1273042857646942, Accuracy: 0.97265625\n",
            "Batch: 17, Loss: 0.17078489065170288, Accuracy: 0.9482421875\n",
            "Batch: 18, Loss: 0.16822916269302368, Accuracy: 0.9609375\n",
            "Batch: 19, Loss: 0.13698329031467438, Accuracy: 0.9658203125\n",
            "TEST Loss: 1.5381510257720947, Accuracy: 0.7509765625\n",
            "Batch: 21, Loss: 0.11516503244638443, Accuracy: 0.9697265625\n",
            "Batch: 22, Loss: 0.16642747819423676, Accuracy: 0.955078125\n",
            "Batch: 23, Loss: 0.1557510495185852, Accuracy: 0.9482421875\n",
            "Batch: 24, Loss: 0.16858163475990295, Accuracy: 0.951171875\n",
            "TEST Loss: 1.540883183479309, Accuracy: 0.7431640625\n",
            "Batch: 26, Loss: 0.1438116580247879, Accuracy: 0.9619140625\n",
            "Batch: 27, Loss: 0.12120074033737183, Accuracy: 0.9697265625\n",
            "Batch: 28, Loss: 0.13214650750160217, Accuracy: 0.9677734375\n",
            "Batch: 29, Loss: 0.12507414817810059, Accuracy: 0.9599609375\n",
            "TEST Loss: 1.0563583374023438, Accuracy: 0.81640625\n",
            "Batch: 31, Loss: 0.12835043668746948, Accuracy: 0.9658203125\n",
            "Batch: 32, Loss: 0.13631469011306763, Accuracy: 0.95703125\n",
            "Batch: 33, Loss: 0.159836083650589, Accuracy: 0.9580078125\n",
            "Batch: 34, Loss: 0.1737179160118103, Accuracy: 0.94921875\n",
            "TEST Loss: 0.718133807182312, Accuracy: 0.833984375\n",
            "Batch: 36, Loss: 0.13607057929039001, Accuracy: 0.9501953125\n",
            "Batch: 37, Loss: 0.12592801451683044, Accuracy: 0.9580078125\n",
            "Epoch 87/100\n",
            "Batch: 1, Loss: 0.17288322746753693, Accuracy: 0.958984375\n",
            "Batch: 2, Loss: 0.13475869596004486, Accuracy: 0.9619140625\n",
            "Batch: 3, Loss: 0.1591290980577469, Accuracy: 0.955078125\n",
            "Batch: 4, Loss: 0.14715152978897095, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.5641789436340332, Accuracy: 0.7197265625\n",
            "Batch: 6, Loss: 0.18033143877983093, Accuracy: 0.943359375\n",
            "Batch: 7, Loss: 0.14694622159004211, Accuracy: 0.9619140625\n",
            "Batch: 8, Loss: 0.13643814623355865, Accuracy: 0.9619140625\n",
            "Batch: 9, Loss: 0.14314132928848267, Accuracy: 0.958984375\n",
            "TEST Loss: 1.2245440483093262, Accuracy: 0.7734375\n",
            "Batch: 11, Loss: 0.1675490438938141, Accuracy: 0.9521484375\n",
            "Batch: 12, Loss: 0.1484927535057068, Accuracy: 0.9560546875\n",
            "Batch: 13, Loss: 0.10972664505243301, Accuracy: 0.96875\n",
            "Batch: 14, Loss: 0.13224321603775024, Accuracy: 0.966796875\n",
            "TEST Loss: 1.155045509338379, Accuracy: 0.8232421875\n",
            "Batch: 16, Loss: 0.1425982415676117, Accuracy: 0.96484375\n",
            "Batch: 17, Loss: 0.1586245894432068, Accuracy: 0.955078125\n",
            "Batch: 18, Loss: 0.1577996015548706, Accuracy: 0.955078125\n",
            "Batch: 19, Loss: 0.13073985278606415, Accuracy: 0.9609375\n",
            "TEST Loss: 1.5900664329528809, Accuracy: 0.75\n",
            "Batch: 21, Loss: 0.1348070502281189, Accuracy: 0.958984375\n",
            "Batch: 22, Loss: 0.14004966616630554, Accuracy: 0.958984375\n",
            "Batch: 23, Loss: 0.15521004796028137, Accuracy: 0.951171875\n",
            "Batch: 24, Loss: 0.15435868501663208, Accuracy: 0.951171875\n",
            "TEST Loss: 1.5682051181793213, Accuracy: 0.7529296875\n",
            "Batch: 26, Loss: 0.13992071151733398, Accuracy: 0.96484375\n",
            "Batch: 27, Loss: 0.11825545877218246, Accuracy: 0.9658203125\n",
            "Batch: 28, Loss: 0.11654369533061981, Accuracy: 0.9677734375\n",
            "Batch: 29, Loss: 0.13195708394050598, Accuracy: 0.9599609375\n",
            "TEST Loss: 1.1310336589813232, Accuracy: 0.80078125\n",
            "Batch: 31, Loss: 0.12079060822725296, Accuracy: 0.9619140625\n",
            "Batch: 32, Loss: 0.11034092307090759, Accuracy: 0.974609375\n",
            "Batch: 33, Loss: 0.14961612224578857, Accuracy: 0.9541015625\n",
            "Batch: 34, Loss: 0.16096684336662292, Accuracy: 0.94921875\n",
            "TEST Loss: 0.7471204996109009, Accuracy: 0.8388671875\n",
            "Batch: 36, Loss: 0.131163090467453, Accuracy: 0.9560546875\n",
            "Batch: 37, Loss: 0.11264149844646454, Accuracy: 0.9697265625\n",
            "Epoch 88/100\n",
            "Batch: 1, Loss: 0.18610170483589172, Accuracy: 0.9423828125\n",
            "Batch: 2, Loss: 0.13961660861968994, Accuracy: 0.9580078125\n",
            "Batch: 3, Loss: 0.13961729407310486, Accuracy: 0.9609375\n",
            "Batch: 4, Loss: 0.13951422274112701, Accuracy: 0.9658203125\n",
            "TEST Loss: 1.4927221536636353, Accuracy: 0.7265625\n",
            "Batch: 6, Loss: 0.1491495668888092, Accuracy: 0.955078125\n",
            "Batch: 7, Loss: 0.16444917023181915, Accuracy: 0.958984375\n",
            "Batch: 8, Loss: 0.10207268595695496, Accuracy: 0.9775390625\n",
            "Batch: 9, Loss: 0.13256867229938507, Accuracy: 0.955078125\n",
            "TEST Loss: 1.2335963249206543, Accuracy: 0.7724609375\n",
            "Batch: 11, Loss: 0.15547746419906616, Accuracy: 0.94921875\n",
            "Batch: 12, Loss: 0.14583814144134521, Accuracy: 0.95703125\n",
            "Batch: 13, Loss: 0.12613680958747864, Accuracy: 0.966796875\n",
            "Batch: 14, Loss: 0.1295100748538971, Accuracy: 0.9658203125\n",
            "TEST Loss: 1.1214931011199951, Accuracy: 0.8251953125\n",
            "Batch: 16, Loss: 0.12398730218410492, Accuracy: 0.9658203125\n",
            "Batch: 17, Loss: 0.13985975086688995, Accuracy: 0.9619140625\n",
            "Batch: 18, Loss: 0.12967264652252197, Accuracy: 0.9638671875\n",
            "Batch: 19, Loss: 0.11197957396507263, Accuracy: 0.974609375\n",
            "TEST Loss: 1.4990876913070679, Accuracy: 0.7607421875\n",
            "Batch: 21, Loss: 0.12850439548492432, Accuracy: 0.962890625\n",
            "Batch: 22, Loss: 0.13038218021392822, Accuracy: 0.9619140625\n",
            "Batch: 23, Loss: 0.14836794137954712, Accuracy: 0.953125\n",
            "Batch: 24, Loss: 0.1650247573852539, Accuracy: 0.9541015625\n",
            "TEST Loss: 1.5489474534988403, Accuracy: 0.75\n",
            "Batch: 26, Loss: 0.11442413926124573, Accuracy: 0.9716796875\n",
            "Batch: 27, Loss: 0.12767206132411957, Accuracy: 0.95703125\n",
            "Batch: 28, Loss: 0.12806068360805511, Accuracy: 0.9638671875\n",
            "Batch: 29, Loss: 0.11334790289402008, Accuracy: 0.9697265625\n",
            "TEST Loss: 1.1452851295471191, Accuracy: 0.806640625\n",
            "Batch: 31, Loss: 0.12246078252792358, Accuracy: 0.9638671875\n",
            "Batch: 32, Loss: 0.11896564066410065, Accuracy: 0.96875\n",
            "Batch: 33, Loss: 0.14724881947040558, Accuracy: 0.9541015625\n",
            "Batch: 34, Loss: 0.13100607693195343, Accuracy: 0.962890625\n",
            "TEST Loss: 0.7051137685775757, Accuracy: 0.8466796875\n",
            "Batch: 36, Loss: 0.12927526235580444, Accuracy: 0.9658203125\n",
            "Batch: 37, Loss: 0.10794983804225922, Accuracy: 0.962890625\n",
            "Epoch 89/100\n",
            "Batch: 1, Loss: 0.13505704700946808, Accuracy: 0.9599609375\n",
            "Batch: 2, Loss: 0.1347646713256836, Accuracy: 0.9619140625\n",
            "Batch: 3, Loss: 0.14603638648986816, Accuracy: 0.9580078125\n",
            "Batch: 4, Loss: 0.13249123096466064, Accuracy: 0.96484375\n",
            "TEST Loss: 1.5046446323394775, Accuracy: 0.7314453125\n",
            "Batch: 6, Loss: 0.14935022592544556, Accuracy: 0.958984375\n",
            "Batch: 7, Loss: 0.13131651282310486, Accuracy: 0.9619140625\n",
            "Batch: 8, Loss: 0.13440920412540436, Accuracy: 0.9560546875\n",
            "Batch: 9, Loss: 0.119156613945961, Accuracy: 0.966796875\n",
            "TEST Loss: 1.2518925666809082, Accuracy: 0.78125\n",
            "Batch: 11, Loss: 0.1425197422504425, Accuracy: 0.9599609375\n",
            "Batch: 12, Loss: 0.10850583016872406, Accuracy: 0.97265625\n",
            "Batch: 13, Loss: 0.1265486180782318, Accuracy: 0.96484375\n",
            "Batch: 14, Loss: 0.1328621208667755, Accuracy: 0.958984375\n",
            "TEST Loss: 1.168074369430542, Accuracy: 0.8193359375\n",
            "Batch: 16, Loss: 0.11930286139249802, Accuracy: 0.9638671875\n",
            "Batch: 17, Loss: 0.1652628779411316, Accuracy: 0.9599609375\n",
            "Batch: 18, Loss: 0.15031719207763672, Accuracy: 0.9580078125\n",
            "Batch: 19, Loss: 0.12107353657484055, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.5340900421142578, Accuracy: 0.765625\n",
            "Batch: 21, Loss: 0.11178071796894073, Accuracy: 0.9638671875\n",
            "Batch: 22, Loss: 0.13468527793884277, Accuracy: 0.962890625\n",
            "Batch: 23, Loss: 0.14729157090187073, Accuracy: 0.9609375\n",
            "Batch: 24, Loss: 0.15294817090034485, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.6255879402160645, Accuracy: 0.7421875\n",
            "Batch: 26, Loss: 0.13299573957920074, Accuracy: 0.958984375\n",
            "Batch: 27, Loss: 0.12911808490753174, Accuracy: 0.9658203125\n",
            "Batch: 28, Loss: 0.11614055186510086, Accuracy: 0.966796875\n",
            "Batch: 29, Loss: 0.11295881867408752, Accuracy: 0.970703125\n",
            "TEST Loss: 1.1019260883331299, Accuracy: 0.8095703125\n",
            "Batch: 31, Loss: 0.12387707829475403, Accuracy: 0.9638671875\n",
            "Batch: 32, Loss: 0.11198638379573822, Accuracy: 0.9677734375\n",
            "Batch: 33, Loss: 0.1466328203678131, Accuracy: 0.9560546875\n",
            "Batch: 34, Loss: 0.15238717198371887, Accuracy: 0.951171875\n",
            "TEST Loss: 0.7139867544174194, Accuracy: 0.84375\n",
            "Batch: 36, Loss: 0.11011132597923279, Accuracy: 0.96875\n",
            "Batch: 37, Loss: 0.1195046603679657, Accuracy: 0.95703125\n",
            "Epoch 90/100\n",
            "Batch: 1, Loss: 0.15503516793251038, Accuracy: 0.958984375\n",
            "Batch: 2, Loss: 0.13862638175487518, Accuracy: 0.9599609375\n",
            "Batch: 3, Loss: 0.1544675976037979, Accuracy: 0.9541015625\n",
            "Batch: 4, Loss: 0.16262605786323547, Accuracy: 0.95703125\n",
            "TEST Loss: 1.5013675689697266, Accuracy: 0.7216796875\n",
            "Batch: 6, Loss: 0.15154945850372314, Accuracy: 0.955078125\n",
            "Batch: 7, Loss: 0.12114140391349792, Accuracy: 0.962890625\n",
            "Batch: 8, Loss: 0.13913144171237946, Accuracy: 0.9609375\n",
            "Batch: 9, Loss: 0.11152864992618561, Accuracy: 0.97265625\n",
            "TEST Loss: 1.226668357849121, Accuracy: 0.78125\n",
            "Batch: 11, Loss: 0.16355186700820923, Accuracy: 0.9521484375\n",
            "Batch: 12, Loss: 0.14531172811985016, Accuracy: 0.958984375\n",
            "Batch: 13, Loss: 0.11529931426048279, Accuracy: 0.962890625\n",
            "Batch: 14, Loss: 0.114204041659832, Accuracy: 0.9677734375\n",
            "TEST Loss: 1.1588733196258545, Accuracy: 0.814453125\n",
            "Batch: 16, Loss: 0.12186476588249207, Accuracy: 0.9658203125\n",
            "Batch: 17, Loss: 0.1369246393442154, Accuracy: 0.958984375\n",
            "Batch: 18, Loss: 0.15219786763191223, Accuracy: 0.95703125\n",
            "Batch: 19, Loss: 0.12569279968738556, Accuracy: 0.9638671875\n",
            "TEST Loss: 1.5642625093460083, Accuracy: 0.763671875\n",
            "Batch: 21, Loss: 0.1327260583639145, Accuracy: 0.95703125\n",
            "Batch: 22, Loss: 0.1117638647556305, Accuracy: 0.96875\n",
            "Batch: 23, Loss: 0.12406187504529953, Accuracy: 0.9638671875\n",
            "Batch: 24, Loss: 0.16379553079605103, Accuracy: 0.9580078125\n",
            "TEST Loss: 1.5980520248413086, Accuracy: 0.7451171875\n",
            "Batch: 26, Loss: 0.14239287376403809, Accuracy: 0.9580078125\n",
            "Batch: 27, Loss: 0.11991710960865021, Accuracy: 0.970703125\n",
            "Batch: 28, Loss: 0.11553555727005005, Accuracy: 0.9638671875\n",
            "Batch: 29, Loss: 0.10885678231716156, Accuracy: 0.97265625\n",
            "TEST Loss: 1.1495506763458252, Accuracy: 0.7998046875\n",
            "Batch: 31, Loss: 0.13226449489593506, Accuracy: 0.9619140625\n",
            "Batch: 32, Loss: 0.1050693616271019, Accuracy: 0.97265625\n",
            "Batch: 33, Loss: 0.14471375942230225, Accuracy: 0.9541015625\n",
            "Batch: 34, Loss: 0.166703462600708, Accuracy: 0.9560546875\n",
            "TEST Loss: 0.7576533555984497, Accuracy: 0.841796875\n",
            "Batch: 36, Loss: 0.1261260211467743, Accuracy: 0.9619140625\n",
            "Batch: 37, Loss: 0.12745873630046844, Accuracy: 0.9580078125\n",
            "Saved Weights at epoch 90 to file Weights_mozart.h5\n",
            "Epoch 91/100\n",
            "Batch: 1, Loss: 0.17195430397987366, Accuracy: 0.947265625\n",
            "Batch: 2, Loss: 0.1405094414949417, Accuracy: 0.951171875\n",
            "Batch: 3, Loss: 0.1441953182220459, Accuracy: 0.962890625\n",
            "Batch: 4, Loss: 0.13025955855846405, Accuracy: 0.95703125\n",
            "TEST Loss: 1.4910686016082764, Accuracy: 0.7314453125\n",
            "Batch: 6, Loss: 0.16939446330070496, Accuracy: 0.9482421875\n",
            "Batch: 7, Loss: 0.14758256077766418, Accuracy: 0.953125\n",
            "Batch: 8, Loss: 0.13392049074172974, Accuracy: 0.9580078125\n",
            "Batch: 9, Loss: 0.10948361456394196, Accuracy: 0.9677734375\n",
            "TEST Loss: 1.26693594455719, Accuracy: 0.7802734375\n",
            "Batch: 11, Loss: 0.1514161378145218, Accuracy: 0.951171875\n",
            "Batch: 12, Loss: 0.14258545637130737, Accuracy: 0.951171875\n",
            "Batch: 13, Loss: 0.10979901254177094, Accuracy: 0.96875\n",
            "Batch: 14, Loss: 0.12281375378370285, Accuracy: 0.962890625\n",
            "TEST Loss: 1.1452882289886475, Accuracy: 0.8203125\n",
            "Batch: 16, Loss: 0.10665673017501831, Accuracy: 0.9736328125\n",
            "Batch: 17, Loss: 0.13204950094223022, Accuracy: 0.9619140625\n",
            "Batch: 18, Loss: 0.14795005321502686, Accuracy: 0.9599609375\n",
            "Batch: 19, Loss: 0.13284581899642944, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.5786337852478027, Accuracy: 0.755859375\n",
            "Batch: 21, Loss: 0.1194394901394844, Accuracy: 0.9580078125\n",
            "Batch: 22, Loss: 0.12261081486940384, Accuracy: 0.9658203125\n",
            "Batch: 23, Loss: 0.12704917788505554, Accuracy: 0.966796875\n",
            "Batch: 24, Loss: 0.137294203042984, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.57902193069458, Accuracy: 0.7412109375\n",
            "Batch: 26, Loss: 0.13498453795909882, Accuracy: 0.96484375\n",
            "Batch: 27, Loss: 0.12255281955003738, Accuracy: 0.9619140625\n",
            "Batch: 28, Loss: 0.11574314534664154, Accuracy: 0.9697265625\n",
            "Batch: 29, Loss: 0.10661700367927551, Accuracy: 0.96875\n",
            "TEST Loss: 1.0866897106170654, Accuracy: 0.8115234375\n",
            "Batch: 31, Loss: 0.12011222541332245, Accuracy: 0.9638671875\n",
            "Batch: 32, Loss: 0.123789481818676, Accuracy: 0.9619140625\n",
            "Batch: 33, Loss: 0.1507227122783661, Accuracy: 0.953125\n",
            "Batch: 34, Loss: 0.1710468977689743, Accuracy: 0.9482421875\n",
            "TEST Loss: 0.7700643539428711, Accuracy: 0.8447265625\n",
            "Batch: 36, Loss: 0.12695007026195526, Accuracy: 0.9609375\n",
            "Batch: 37, Loss: 0.12195532768964767, Accuracy: 0.958984375\n",
            "Epoch 92/100\n",
            "Batch: 1, Loss: 0.14698036015033722, Accuracy: 0.9619140625\n",
            "Batch: 2, Loss: 0.14072462916374207, Accuracy: 0.9521484375\n",
            "Batch: 3, Loss: 0.13839751482009888, Accuracy: 0.955078125\n",
            "Batch: 4, Loss: 0.1485593318939209, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.5977747440338135, Accuracy: 0.71875\n",
            "Batch: 6, Loss: 0.15393060445785522, Accuracy: 0.9521484375\n",
            "Batch: 7, Loss: 0.13337594270706177, Accuracy: 0.9599609375\n",
            "Batch: 8, Loss: 0.15702533721923828, Accuracy: 0.951171875\n",
            "Batch: 9, Loss: 0.1400585174560547, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.2157198190689087, Accuracy: 0.783203125\n",
            "Batch: 11, Loss: 0.16247645020484924, Accuracy: 0.94921875\n",
            "Batch: 12, Loss: 0.13733220100402832, Accuracy: 0.958984375\n",
            "Batch: 13, Loss: 0.10725875198841095, Accuracy: 0.96875\n",
            "Batch: 14, Loss: 0.12476824223995209, Accuracy: 0.962890625\n",
            "TEST Loss: 1.1514184474945068, Accuracy: 0.8193359375\n",
            "Batch: 16, Loss: 0.1306140124797821, Accuracy: 0.962890625\n",
            "Batch: 17, Loss: 0.1461455225944519, Accuracy: 0.9521484375\n",
            "Batch: 18, Loss: 0.12443575263023376, Accuracy: 0.9677734375\n",
            "Batch: 19, Loss: 0.1283973753452301, Accuracy: 0.9609375\n",
            "TEST Loss: 1.5493848323822021, Accuracy: 0.7548828125\n",
            "Batch: 21, Loss: 0.13131770491600037, Accuracy: 0.955078125\n",
            "Batch: 22, Loss: 0.12334655970335007, Accuracy: 0.966796875\n",
            "Batch: 23, Loss: 0.14637000858783722, Accuracy: 0.958984375\n",
            "Batch: 24, Loss: 0.14345966279506683, Accuracy: 0.962890625\n",
            "TEST Loss: 1.594416856765747, Accuracy: 0.7353515625\n",
            "Batch: 26, Loss: 0.12838433682918549, Accuracy: 0.96484375\n",
            "Batch: 27, Loss: 0.13416080176830292, Accuracy: 0.9599609375\n",
            "Batch: 28, Loss: 0.11431083083152771, Accuracy: 0.974609375\n",
            "Batch: 29, Loss: 0.12806576490402222, Accuracy: 0.9658203125\n",
            "TEST Loss: 1.164210319519043, Accuracy: 0.80078125\n",
            "Batch: 31, Loss: 0.10957471281290054, Accuracy: 0.9677734375\n",
            "Batch: 32, Loss: 0.11171647906303406, Accuracy: 0.96875\n",
            "Batch: 33, Loss: 0.15307655930519104, Accuracy: 0.9541015625\n",
            "Batch: 34, Loss: 0.13597548007965088, Accuracy: 0.95703125\n",
            "TEST Loss: 0.7805439233779907, Accuracy: 0.84765625\n",
            "Batch: 36, Loss: 0.12019993364810944, Accuracy: 0.953125\n",
            "Batch: 37, Loss: 0.12148967385292053, Accuracy: 0.9619140625\n",
            "Epoch 93/100\n",
            "Batch: 1, Loss: 0.15996815264225006, Accuracy: 0.9560546875\n",
            "Batch: 2, Loss: 0.1210324838757515, Accuracy: 0.96484375\n",
            "Batch: 3, Loss: 0.14687037467956543, Accuracy: 0.9619140625\n",
            "Batch: 4, Loss: 0.11766037344932556, Accuracy: 0.9677734375\n",
            "TEST Loss: 1.537229299545288, Accuracy: 0.724609375\n",
            "Batch: 6, Loss: 0.1521957367658615, Accuracy: 0.951171875\n",
            "Batch: 7, Loss: 0.1253395527601242, Accuracy: 0.9658203125\n",
            "Batch: 8, Loss: 0.13462486863136292, Accuracy: 0.966796875\n",
            "Batch: 9, Loss: 0.1352713406085968, Accuracy: 0.9580078125\n",
            "TEST Loss: 1.2379164695739746, Accuracy: 0.7802734375\n",
            "Batch: 11, Loss: 0.1391930729150772, Accuracy: 0.9580078125\n",
            "Batch: 12, Loss: 0.11395534127950668, Accuracy: 0.9697265625\n",
            "Batch: 13, Loss: 0.14295616745948792, Accuracy: 0.953125\n",
            "Batch: 14, Loss: 0.15782923996448517, Accuracy: 0.955078125\n",
            "TEST Loss: 1.1616551876068115, Accuracy: 0.8173828125\n",
            "Batch: 16, Loss: 0.12921807169914246, Accuracy: 0.966796875\n",
            "Batch: 17, Loss: 0.15868808329105377, Accuracy: 0.955078125\n",
            "Batch: 18, Loss: 0.12962734699249268, Accuracy: 0.9599609375\n",
            "Batch: 19, Loss: 0.13514770567417145, Accuracy: 0.955078125\n",
            "TEST Loss: 1.5139095783233643, Accuracy: 0.7568359375\n",
            "Batch: 21, Loss: 0.11428631097078323, Accuracy: 0.9677734375\n",
            "Batch: 22, Loss: 0.13940036296844482, Accuracy: 0.9609375\n",
            "Batch: 23, Loss: 0.16052912175655365, Accuracy: 0.951171875\n",
            "Batch: 24, Loss: 0.1369107961654663, Accuracy: 0.9609375\n",
            "TEST Loss: 1.5341975688934326, Accuracy: 0.7421875\n",
            "Batch: 26, Loss: 0.13170482218265533, Accuracy: 0.962890625\n",
            "Batch: 27, Loss: 0.11716337502002716, Accuracy: 0.9697265625\n",
            "Batch: 28, Loss: 0.10454264283180237, Accuracy: 0.97265625\n",
            "Batch: 29, Loss: 0.1232328936457634, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.1189956665039062, Accuracy: 0.80078125\n",
            "Batch: 31, Loss: 0.12718906998634338, Accuracy: 0.9677734375\n",
            "Batch: 32, Loss: 0.11156288534402847, Accuracy: 0.9677734375\n",
            "Batch: 33, Loss: 0.1156098023056984, Accuracy: 0.962890625\n",
            "Batch: 34, Loss: 0.12628859281539917, Accuracy: 0.9638671875\n",
            "TEST Loss: 0.7755693197250366, Accuracy: 0.83984375\n",
            "Batch: 36, Loss: 0.10515183210372925, Accuracy: 0.96484375\n",
            "Batch: 37, Loss: 0.11907167732715607, Accuracy: 0.962890625\n",
            "Epoch 94/100\n",
            "Batch: 1, Loss: 0.1600165069103241, Accuracy: 0.94140625\n",
            "Batch: 2, Loss: 0.1044430360198021, Accuracy: 0.9736328125\n",
            "Batch: 3, Loss: 0.13773569464683533, Accuracy: 0.9580078125\n",
            "Batch: 4, Loss: 0.11537569761276245, Accuracy: 0.9697265625\n",
            "TEST Loss: 1.4620599746704102, Accuracy: 0.7265625\n",
            "Batch: 6, Loss: 0.143301859498024, Accuracy: 0.9619140625\n",
            "Batch: 7, Loss: 0.1304740309715271, Accuracy: 0.9560546875\n",
            "Batch: 8, Loss: 0.13079780340194702, Accuracy: 0.9599609375\n",
            "Batch: 9, Loss: 0.12734274566173553, Accuracy: 0.9599609375\n",
            "TEST Loss: 1.2458674907684326, Accuracy: 0.767578125\n",
            "Batch: 11, Loss: 0.14577050507068634, Accuracy: 0.9580078125\n",
            "Batch: 12, Loss: 0.13170146942138672, Accuracy: 0.953125\n",
            "Batch: 13, Loss: 0.10986794531345367, Accuracy: 0.96875\n",
            "Batch: 14, Loss: 0.11515959352254868, Accuracy: 0.9697265625\n",
            "TEST Loss: 1.1821619272232056, Accuracy: 0.8203125\n",
            "Batch: 16, Loss: 0.093718022108078, Accuracy: 0.9765625\n",
            "Batch: 17, Loss: 0.12394438683986664, Accuracy: 0.9658203125\n",
            "Batch: 18, Loss: 0.13140968978405, Accuracy: 0.9609375\n",
            "Batch: 19, Loss: 0.09817604720592499, Accuracy: 0.9736328125\n",
            "TEST Loss: 1.533097267150879, Accuracy: 0.759765625\n",
            "Batch: 21, Loss: 0.13210012018680573, Accuracy: 0.9541015625\n",
            "Batch: 22, Loss: 0.11412639170885086, Accuracy: 0.966796875\n",
            "Batch: 23, Loss: 0.15656930208206177, Accuracy: 0.9541015625\n",
            "Batch: 24, Loss: 0.14049623906612396, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.5542055368423462, Accuracy: 0.75\n",
            "Batch: 26, Loss: 0.12238974869251251, Accuracy: 0.9658203125\n",
            "Batch: 27, Loss: 0.08617406338453293, Accuracy: 0.978515625\n",
            "Batch: 28, Loss: 0.11714474111795425, Accuracy: 0.9658203125\n",
            "Batch: 29, Loss: 0.10925263911485672, Accuracy: 0.9658203125\n",
            "TEST Loss: 1.1220271587371826, Accuracy: 0.806640625\n",
            "Batch: 31, Loss: 0.10639016330242157, Accuracy: 0.962890625\n",
            "Batch: 32, Loss: 0.11052992939949036, Accuracy: 0.9677734375\n",
            "Batch: 33, Loss: 0.1345231831073761, Accuracy: 0.95703125\n",
            "Batch: 34, Loss: 0.1291498839855194, Accuracy: 0.9638671875\n",
            "TEST Loss: 0.7549728155136108, Accuracy: 0.8544921875\n",
            "Batch: 36, Loss: 0.11144183576107025, Accuracy: 0.96875\n",
            "Batch: 37, Loss: 0.12733519077301025, Accuracy: 0.9619140625\n",
            "Epoch 95/100\n",
            "Batch: 1, Loss: 0.1276528537273407, Accuracy: 0.9609375\n",
            "Batch: 2, Loss: 0.10169492661952972, Accuracy: 0.9677734375\n",
            "Batch: 3, Loss: 0.13155323266983032, Accuracy: 0.9599609375\n",
            "Batch: 4, Loss: 0.1252220869064331, Accuracy: 0.966796875\n",
            "TEST Loss: 1.5489041805267334, Accuracy: 0.712890625\n",
            "Batch: 6, Loss: 0.12385958433151245, Accuracy: 0.9697265625\n",
            "Batch: 7, Loss: 0.11260282248258591, Accuracy: 0.9658203125\n",
            "Batch: 8, Loss: 0.11908825486898422, Accuracy: 0.96484375\n",
            "Batch: 9, Loss: 0.12073088437318802, Accuracy: 0.96484375\n",
            "TEST Loss: 1.2168312072753906, Accuracy: 0.787109375\n",
            "Batch: 11, Loss: 0.1342761069536209, Accuracy: 0.96484375\n",
            "Batch: 12, Loss: 0.13420841097831726, Accuracy: 0.955078125\n",
            "Batch: 13, Loss: 0.10979793220758438, Accuracy: 0.9697265625\n",
            "Batch: 14, Loss: 0.12444009631872177, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.1433559656143188, Accuracy: 0.8251953125\n",
            "Batch: 16, Loss: 0.10744543373584747, Accuracy: 0.9677734375\n",
            "Batch: 17, Loss: 0.13224095106124878, Accuracy: 0.9541015625\n",
            "Batch: 18, Loss: 0.1366531401872635, Accuracy: 0.958984375\n",
            "Batch: 19, Loss: 0.11288963258266449, Accuracy: 0.9716796875\n",
            "TEST Loss: 1.5551074743270874, Accuracy: 0.7529296875\n",
            "Batch: 21, Loss: 0.11327069997787476, Accuracy: 0.9716796875\n",
            "Batch: 22, Loss: 0.12687772512435913, Accuracy: 0.962890625\n",
            "Batch: 23, Loss: 0.15210938453674316, Accuracy: 0.953125\n",
            "Batch: 24, Loss: 0.1410113424062729, Accuracy: 0.9677734375\n",
            "TEST Loss: 1.5759875774383545, Accuracy: 0.736328125\n",
            "Batch: 26, Loss: 0.11456568539142609, Accuracy: 0.9697265625\n",
            "Batch: 27, Loss: 0.10149058699607849, Accuracy: 0.978515625\n",
            "Batch: 28, Loss: 0.10407516360282898, Accuracy: 0.97265625\n",
            "Batch: 29, Loss: 0.10847261548042297, Accuracy: 0.962890625\n",
            "TEST Loss: 1.1057093143463135, Accuracy: 0.8076171875\n",
            "Batch: 31, Loss: 0.1099386066198349, Accuracy: 0.970703125\n",
            "Batch: 32, Loss: 0.10036277770996094, Accuracy: 0.9736328125\n",
            "Batch: 33, Loss: 0.13894394040107727, Accuracy: 0.9609375\n",
            "Batch: 34, Loss: 0.12952813506126404, Accuracy: 0.962890625\n",
            "TEST Loss: 0.7631903290748596, Accuracy: 0.8408203125\n",
            "Batch: 36, Loss: 0.1190376803278923, Accuracy: 0.9619140625\n",
            "Batch: 37, Loss: 0.09459942579269409, Accuracy: 0.9677734375\n",
            "Epoch 96/100\n",
            "Batch: 1, Loss: 0.13758189976215363, Accuracy: 0.9658203125\n",
            "Batch: 2, Loss: 0.13241907954216003, Accuracy: 0.962890625\n",
            "Batch: 3, Loss: 0.1530989706516266, Accuracy: 0.96484375\n",
            "Batch: 4, Loss: 0.1065019741654396, Accuracy: 0.96875\n",
            "TEST Loss: 1.5254356861114502, Accuracy: 0.7177734375\n",
            "Batch: 6, Loss: 0.14594170451164246, Accuracy: 0.9560546875\n",
            "Batch: 7, Loss: 0.12183532863855362, Accuracy: 0.962890625\n",
            "Batch: 8, Loss: 0.12425768375396729, Accuracy: 0.9638671875\n",
            "Batch: 9, Loss: 0.1345480978488922, Accuracy: 0.95703125\n",
            "TEST Loss: 1.2634345293045044, Accuracy: 0.7802734375\n",
            "Batch: 11, Loss: 0.13988390564918518, Accuracy: 0.953125\n",
            "Batch: 12, Loss: 0.12858213484287262, Accuracy: 0.958984375\n",
            "Batch: 13, Loss: 0.09240337461233139, Accuracy: 0.9716796875\n",
            "Batch: 14, Loss: 0.10674622654914856, Accuracy: 0.9736328125\n",
            "TEST Loss: 1.1700257062911987, Accuracy: 0.828125\n",
            "Batch: 16, Loss: 0.10056211799383163, Accuracy: 0.9716796875\n",
            "Batch: 17, Loss: 0.12647230923175812, Accuracy: 0.9658203125\n",
            "Batch: 18, Loss: 0.13543696701526642, Accuracy: 0.958984375\n",
            "Batch: 19, Loss: 0.12846320867538452, Accuracy: 0.9658203125\n",
            "TEST Loss: 1.596260666847229, Accuracy: 0.7548828125\n",
            "Batch: 21, Loss: 0.11049878597259521, Accuracy: 0.966796875\n",
            "Batch: 22, Loss: 0.11386483162641525, Accuracy: 0.966796875\n",
            "Batch: 23, Loss: 0.13090482354164124, Accuracy: 0.9580078125\n",
            "Batch: 24, Loss: 0.1560841202735901, Accuracy: 0.95703125\n",
            "TEST Loss: 1.5690451860427856, Accuracy: 0.74609375\n",
            "Batch: 26, Loss: 0.12872034311294556, Accuracy: 0.96875\n",
            "Batch: 27, Loss: 0.09928878396749496, Accuracy: 0.974609375\n",
            "Batch: 28, Loss: 0.10844850540161133, Accuracy: 0.9658203125\n",
            "Batch: 29, Loss: 0.10880281031131744, Accuracy: 0.96875\n",
            "TEST Loss: 1.1402767896652222, Accuracy: 0.8037109375\n",
            "Batch: 31, Loss: 0.09499134123325348, Accuracy: 0.974609375\n",
            "Batch: 32, Loss: 0.09765783697366714, Accuracy: 0.9755859375\n",
            "Batch: 33, Loss: 0.1265282779932022, Accuracy: 0.95703125\n",
            "Batch: 34, Loss: 0.1532384753227234, Accuracy: 0.9560546875\n",
            "TEST Loss: 0.7462399005889893, Accuracy: 0.8466796875\n",
            "Batch: 36, Loss: 0.12241217494010925, Accuracy: 0.962890625\n",
            "Batch: 37, Loss: 0.10168192535638809, Accuracy: 0.970703125\n",
            "Epoch 97/100\n",
            "Batch: 1, Loss: 0.12933258712291718, Accuracy: 0.966796875\n",
            "Batch: 2, Loss: 0.11180435121059418, Accuracy: 0.9619140625\n",
            "Batch: 3, Loss: 0.14198365807533264, Accuracy: 0.9580078125\n",
            "Batch: 4, Loss: 0.11040537804365158, Accuracy: 0.966796875\n",
            "TEST Loss: 1.5342943668365479, Accuracy: 0.7275390625\n",
            "Batch: 6, Loss: 0.12526659667491913, Accuracy: 0.9609375\n",
            "Batch: 7, Loss: 0.11290204524993896, Accuracy: 0.96875\n",
            "Batch: 8, Loss: 0.13691483438014984, Accuracy: 0.9609375\n",
            "Batch: 9, Loss: 0.13449585437774658, Accuracy: 0.958984375\n",
            "TEST Loss: 1.3019866943359375, Accuracy: 0.7763671875\n",
            "Batch: 11, Loss: 0.15683841705322266, Accuracy: 0.953125\n",
            "Batch: 12, Loss: 0.12802167236804962, Accuracy: 0.9638671875\n",
            "Batch: 13, Loss: 0.09119521081447601, Accuracy: 0.9794921875\n",
            "Batch: 14, Loss: 0.09301784634590149, Accuracy: 0.9736328125\n",
            "TEST Loss: 1.1502662897109985, Accuracy: 0.8232421875\n",
            "Batch: 16, Loss: 0.11794610321521759, Accuracy: 0.96484375\n",
            "Batch: 17, Loss: 0.11530918627977371, Accuracy: 0.966796875\n",
            "Batch: 18, Loss: 0.15024836361408234, Accuracy: 0.9521484375\n",
            "Batch: 19, Loss: 0.13795465230941772, Accuracy: 0.9560546875\n",
            "TEST Loss: 1.5585606098175049, Accuracy: 0.7529296875\n",
            "Batch: 21, Loss: 0.10380151122808456, Accuracy: 0.97265625\n",
            "Batch: 22, Loss: 0.12201488018035889, Accuracy: 0.9697265625\n",
            "Batch: 23, Loss: 0.12404325604438782, Accuracy: 0.9619140625\n",
            "Batch: 24, Loss: 0.13075293600559235, Accuracy: 0.9599609375\n",
            "TEST Loss: 1.5835188627243042, Accuracy: 0.7490234375\n",
            "Batch: 26, Loss: 0.1317242681980133, Accuracy: 0.9609375\n",
            "Batch: 27, Loss: 0.09233111143112183, Accuracy: 0.970703125\n",
            "Batch: 28, Loss: 0.11018381267786026, Accuracy: 0.96484375\n",
            "Batch: 29, Loss: 0.11538151651620865, Accuracy: 0.9677734375\n",
            "TEST Loss: 1.1505141258239746, Accuracy: 0.80859375\n",
            "Batch: 31, Loss: 0.09028343856334686, Accuracy: 0.9765625\n",
            "Batch: 32, Loss: 0.1048206239938736, Accuracy: 0.9609375\n",
            "Batch: 33, Loss: 0.1231289803981781, Accuracy: 0.9677734375\n",
            "Batch: 34, Loss: 0.13284094631671906, Accuracy: 0.9619140625\n",
            "TEST Loss: 0.790919303894043, Accuracy: 0.84375\n",
            "Batch: 36, Loss: 0.10979391634464264, Accuracy: 0.9638671875\n",
            "Batch: 37, Loss: 0.1051650121808052, Accuracy: 0.9697265625\n",
            "Epoch 98/100\n",
            "Batch: 1, Loss: 0.12534750998020172, Accuracy: 0.970703125\n",
            "Batch: 2, Loss: 0.10261839628219604, Accuracy: 0.9697265625\n",
            "Batch: 3, Loss: 0.14188385009765625, Accuracy: 0.95703125\n",
            "Batch: 4, Loss: 0.10310140252113342, Accuracy: 0.97265625\n",
            "TEST Loss: 1.586822271347046, Accuracy: 0.716796875\n",
            "Batch: 6, Loss: 0.13294614851474762, Accuracy: 0.95703125\n",
            "Batch: 7, Loss: 0.08854363113641739, Accuracy: 0.9775390625\n",
            "Batch: 8, Loss: 0.10380631685256958, Accuracy: 0.9736328125\n",
            "Batch: 9, Loss: 0.13727207481861115, Accuracy: 0.9521484375\n",
            "TEST Loss: 1.254162073135376, Accuracy: 0.78515625\n",
            "Batch: 11, Loss: 0.13989752531051636, Accuracy: 0.955078125\n",
            "Batch: 12, Loss: 0.12964338064193726, Accuracy: 0.9609375\n",
            "Batch: 13, Loss: 0.09740564227104187, Accuracy: 0.9716796875\n",
            "Batch: 14, Loss: 0.09863132238388062, Accuracy: 0.9697265625\n",
            "TEST Loss: 1.1921595335006714, Accuracy: 0.8193359375\n",
            "Batch: 16, Loss: 0.09141045808792114, Accuracy: 0.9736328125\n",
            "Batch: 17, Loss: 0.1186290830373764, Accuracy: 0.9736328125\n",
            "Batch: 18, Loss: 0.10960543900728226, Accuracy: 0.9677734375\n",
            "Batch: 19, Loss: 0.14660067856311798, Accuracy: 0.95703125\n",
            "TEST Loss: 1.5377862453460693, Accuracy: 0.7568359375\n",
            "Batch: 21, Loss: 0.11614743620157242, Accuracy: 0.966796875\n",
            "Batch: 22, Loss: 0.113040491938591, Accuracy: 0.966796875\n",
            "Batch: 23, Loss: 0.11802919209003448, Accuracy: 0.9658203125\n",
            "Batch: 24, Loss: 0.106844462454319, Accuracy: 0.96875\n",
            "TEST Loss: 1.6320563554763794, Accuracy: 0.7451171875\n",
            "Batch: 26, Loss: 0.12087132781744003, Accuracy: 0.962890625\n",
            "Batch: 27, Loss: 0.10287418961524963, Accuracy: 0.966796875\n",
            "Batch: 28, Loss: 0.08912286162376404, Accuracy: 0.9775390625\n",
            "Batch: 29, Loss: 0.10367244482040405, Accuracy: 0.9775390625\n",
            "TEST Loss: 1.166207194328308, Accuracy: 0.8037109375\n",
            "Batch: 31, Loss: 0.10348885506391525, Accuracy: 0.96875\n",
            "Batch: 32, Loss: 0.11225226521492004, Accuracy: 0.970703125\n",
            "Batch: 33, Loss: 0.13898973166942596, Accuracy: 0.9580078125\n",
            "Batch: 34, Loss: 0.13873229920864105, Accuracy: 0.9560546875\n",
            "TEST Loss: 0.7354539036750793, Accuracy: 0.849609375\n",
            "Batch: 36, Loss: 0.10309043526649475, Accuracy: 0.9716796875\n",
            "Batch: 37, Loss: 0.10100336372852325, Accuracy: 0.97265625\n",
            "Epoch 99/100\n",
            "Batch: 1, Loss: 0.14097833633422852, Accuracy: 0.958984375\n",
            "Batch: 2, Loss: 0.10183584690093994, Accuracy: 0.9736328125\n",
            "Batch: 3, Loss: 0.12179206311702728, Accuracy: 0.95703125\n",
            "Batch: 4, Loss: 0.12364968657493591, Accuracy: 0.9609375\n",
            "TEST Loss: 1.5592408180236816, Accuracy: 0.7255859375\n",
            "Batch: 6, Loss: 0.1394900381565094, Accuracy: 0.9580078125\n",
            "Batch: 7, Loss: 0.1062847226858139, Accuracy: 0.96875\n",
            "Batch: 8, Loss: 0.12194675207138062, Accuracy: 0.9658203125\n",
            "Batch: 9, Loss: 0.1188710480928421, Accuracy: 0.9580078125\n",
            "TEST Loss: 1.245662808418274, Accuracy: 0.7919921875\n",
            "Batch: 11, Loss: 0.13650016486644745, Accuracy: 0.9580078125\n",
            "Batch: 12, Loss: 0.13523027300834656, Accuracy: 0.9599609375\n",
            "Batch: 13, Loss: 0.1271044909954071, Accuracy: 0.9599609375\n",
            "Batch: 14, Loss: 0.09835237264633179, Accuracy: 0.9736328125\n",
            "TEST Loss: 1.2053232192993164, Accuracy: 0.8203125\n",
            "Batch: 16, Loss: 0.11053472757339478, Accuracy: 0.97265625\n",
            "Batch: 17, Loss: 0.11266113817691803, Accuracy: 0.9716796875\n",
            "Batch: 18, Loss: 0.13417282700538635, Accuracy: 0.962890625\n",
            "Batch: 19, Loss: 0.12494459748268127, Accuracy: 0.9658203125\n",
            "TEST Loss: 1.6222032308578491, Accuracy: 0.7490234375\n",
            "Batch: 21, Loss: 0.09602988511323929, Accuracy: 0.9775390625\n",
            "Batch: 22, Loss: 0.11847613751888275, Accuracy: 0.966796875\n",
            "Batch: 23, Loss: 0.14909067749977112, Accuracy: 0.9482421875\n",
            "Batch: 24, Loss: 0.13874801993370056, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.6205707788467407, Accuracy: 0.744140625\n",
            "Batch: 26, Loss: 0.10850048065185547, Accuracy: 0.9736328125\n",
            "Batch: 27, Loss: 0.0962800532579422, Accuracy: 0.9736328125\n",
            "Batch: 28, Loss: 0.08758463710546494, Accuracy: 0.982421875\n",
            "Batch: 29, Loss: 0.09908832609653473, Accuracy: 0.97265625\n",
            "TEST Loss: 1.2097837924957275, Accuracy: 0.802734375\n",
            "Batch: 31, Loss: 0.10920798778533936, Accuracy: 0.9677734375\n",
            "Batch: 32, Loss: 0.10213393718004227, Accuracy: 0.97265625\n",
            "Batch: 33, Loss: 0.1399712711572647, Accuracy: 0.9521484375\n",
            "Batch: 34, Loss: 0.12370108813047409, Accuracy: 0.9619140625\n",
            "TEST Loss: 0.7481178045272827, Accuracy: 0.853515625\n",
            "Batch: 36, Loss: 0.11871281266212463, Accuracy: 0.96484375\n",
            "Batch: 37, Loss: 0.10902054607868195, Accuracy: 0.962890625\n",
            "Epoch 100/100\n",
            "Batch: 1, Loss: 0.14760838449001312, Accuracy: 0.9580078125\n",
            "Batch: 2, Loss: 0.11790510267019272, Accuracy: 0.962890625\n",
            "Batch: 3, Loss: 0.1101425439119339, Accuracy: 0.9677734375\n",
            "Batch: 4, Loss: 0.1193295568227768, Accuracy: 0.966796875\n",
            "TEST Loss: 1.5611181259155273, Accuracy: 0.71875\n",
            "Batch: 6, Loss: 0.13651195168495178, Accuracy: 0.955078125\n",
            "Batch: 7, Loss: 0.11850425601005554, Accuracy: 0.970703125\n",
            "Batch: 8, Loss: 0.13783270120620728, Accuracy: 0.96875\n",
            "Batch: 9, Loss: 0.12265495210886002, Accuracy: 0.9619140625\n",
            "TEST Loss: 1.2466158866882324, Accuracy: 0.7783203125\n",
            "Batch: 11, Loss: 0.12808679044246674, Accuracy: 0.962890625\n",
            "Batch: 12, Loss: 0.12271887809038162, Accuracy: 0.9599609375\n",
            "Batch: 13, Loss: 0.10883332788944244, Accuracy: 0.9658203125\n",
            "Batch: 14, Loss: 0.1188560277223587, Accuracy: 0.9638671875\n",
            "TEST Loss: 1.164209246635437, Accuracy: 0.8173828125\n",
            "Batch: 16, Loss: 0.11602221429347992, Accuracy: 0.966796875\n",
            "Batch: 17, Loss: 0.11904080212116241, Accuracy: 0.96875\n",
            "Batch: 18, Loss: 0.1086944043636322, Accuracy: 0.970703125\n",
            "Batch: 19, Loss: 0.13579195737838745, Accuracy: 0.966796875\n",
            "TEST Loss: 1.5443345308303833, Accuracy: 0.759765625\n",
            "Batch: 21, Loss: 0.09306836128234863, Accuracy: 0.966796875\n",
            "Batch: 22, Loss: 0.134916752576828, Accuracy: 0.9609375\n",
            "Batch: 23, Loss: 0.1308831125497818, Accuracy: 0.962890625\n",
            "Batch: 24, Loss: 0.13751554489135742, Accuracy: 0.96875\n",
            "TEST Loss: 1.5611391067504883, Accuracy: 0.75390625\n",
            "Batch: 26, Loss: 0.11584479361772537, Accuracy: 0.9638671875\n",
            "Batch: 27, Loss: 0.09195102751255035, Accuracy: 0.974609375\n",
            "Batch: 28, Loss: 0.09221447259187698, Accuracy: 0.9697265625\n",
            "Batch: 29, Loss: 0.11124464869499207, Accuracy: 0.970703125\n",
            "TEST Loss: 1.1683266162872314, Accuracy: 0.8046875\n",
            "Batch: 31, Loss: 0.10497471690177917, Accuracy: 0.962890625\n",
            "Batch: 32, Loss: 0.0860600620508194, Accuracy: 0.9736328125\n",
            "Batch: 33, Loss: 0.1070440486073494, Accuracy: 0.9658203125\n",
            "Batch: 34, Loss: 0.16077756881713867, Accuracy: 0.9580078125\n",
            "TEST Loss: 0.7646995782852173, Accuracy: 0.8466796875\n",
            "Batch: 36, Loss: 0.09315092861652374, Accuracy: 0.97265625\n",
            "Batch: 37, Loss: 0.10112498700618744, Accuracy: 0.97265625\n",
            "Saved Weights at epoch 100 to file Weights_mozart.h5\n",
            "0\t3.321525065104167\t0.08310546875\n",
            "1\t3.0289178689320884\t0.11243489583333334\n",
            "2\t2.7728799899419148\t0.14778645833333334\n",
            "3\t2.594326957066854\t0.16959635416666666\n",
            "4\t2.5128152052561443\t0.19007161458333333\n",
            "5\t2.452014406522115\t0.21100260416666666\n",
            "6\t2.4023506164550783\t0.23251953125\n",
            "7\t2.347249722480774\t0.25537109375\n",
            "8\t2.2858555793762205\t0.27340494791666664\n",
            "9\t2.2294252634048464\t0.28912760416666666\n",
            "10\t2.1734957575798033\t0.30983072916666665\n",
            "11\t2.1199055155118307\t0.3275390625\n",
            "12\t2.0600956122080487\t0.348046875\n",
            "13\t1.9986758788426717\t0.36868489583333336\n",
            "14\t1.9343644738197328\t0.38909505208333334\n",
            "15\t1.8722026586532592\t0.40751953125\n",
            "16\t1.8048230846722921\t0.43121744791666666\n",
            "17\t1.7444661180178325\t0.44733072916666666\n",
            "18\t1.667246437072754\t0.4723307291666667\n",
            "19\t1.608109752337138\t0.4910481770833333\n",
            "20\t1.5398377458254495\t0.5142252604166667\n",
            "21\t1.4649400154749552\t0.5361979166666667\n",
            "22\t1.393529760837555\t0.5563802083333333\n",
            "23\t1.339287233352661\t0.5765299479166667\n",
            "24\t1.2764990011850992\t0.5958333333333333\n",
            "25\t1.2127612789471944\t0.61982421875\n",
            "26\t1.1434182842572531\t0.6381184895833333\n",
            "27\t1.0866146008173625\t0.6599283854166667\n",
            "28\t1.0387280484040577\t0.6758138020833333\n",
            "29\t0.9967497209707896\t0.6893880208333333\n",
            "30\t0.9680876592795055\t0.6958658854166667\n",
            "31\t0.8982752362887064\t0.7190755208333334\n",
            "32\t0.8591609517733256\t0.73095703125\n",
            "33\t0.8132522463798523\t0.7470703125\n",
            "34\t0.7736849963665009\t0.7588541666666667\n",
            "35\t0.7325648407141367\t0.77216796875\n",
            "36\t0.6979279478391012\t0.7820638020833334\n",
            "37\t0.6772816916306813\t0.78671875\n",
            "38\t0.646048633257548\t0.7959635416666667\n",
            "39\t0.6171665509541829\t0.8057291666666667\n",
            "40\t0.5816212157408397\t0.8201822916666667\n",
            "41\t0.547413037220637\t0.8321614583333333\n",
            "42\t0.5207452227671941\t0.8394856770833333\n",
            "43\t0.49398814837137855\t0.8463541666666666\n",
            "44\t0.4785078138113022\t0.85224609375\n",
            "45\t0.4550337493419647\t0.8603515625\n",
            "46\t0.44373787343502047\t0.86376953125\n",
            "47\t0.4247595359881719\t0.87158203125\n",
            "48\t0.4059335927168528\t0.8761393229166666\n",
            "49\t0.3866470128297806\t0.8816731770833334\n",
            "50\t0.37574319740136464\t0.8843424479166667\n",
            "51\t0.363548884789149\t0.8892578125\n",
            "52\t0.34453872839609784\t0.8944986979166667\n",
            "53\t0.3395875225464503\t0.8946614583333333\n",
            "54\t0.3217519332965215\t0.9020182291666666\n",
            "55\t0.31016905754804613\t0.9057291666666667\n",
            "56\t0.29940856496493023\t0.9105794270833333\n",
            "57\t0.2883361424009005\t0.9119791666666667\n",
            "58\t0.27660046219825746\t0.9166666666666666\n",
            "59\t0.26842939456303916\t0.9195638020833333\n",
            "60\t0.2622849057118098\t0.9210611979166666\n",
            "61\t0.25594791074593864\t0.9230143229166666\n",
            "62\t0.24965730607509612\t0.9241861979166667\n",
            "63\t0.23965089271465936\t0.9276041666666667\n",
            "64\t0.2349393183986346\t0.9277669270833333\n",
            "65\t0.2250204046567281\t0.9334309895833334\n",
            "66\t0.22008718301852545\t0.9359049479166667\n",
            "67\t0.2148206536968549\t0.9365234375\n",
            "68\t0.2088327835003535\t0.9380859375\n",
            "69\t0.20133692473173143\t0.9400716145833333\n",
            "70\t0.19604730109373728\t0.9413736979166667\n",
            "71\t0.1904664342602094\t0.94482421875\n",
            "72\t0.19166174679994583\t0.9428385416666667\n",
            "73\t0.1821179469426473\t0.94658203125\n",
            "74\t0.17942920128504436\t0.9471028645833334\n",
            "75\t0.17317430277665455\t0.94921875\n",
            "76\t0.16848873471220335\t0.9489908854166667\n",
            "77\t0.1652803694208463\t0.9514973958333334\n",
            "78\t0.1617489978671074\t0.9538736979166667\n",
            "79\t0.1615581691265106\t0.9538411458333333\n",
            "80\t0.16047782798608143\t0.9528971354166667\n",
            "81\t0.1525591569642226\t0.9544596354166667\n",
            "82\t0.14867333173751832\t0.9570963541666667\n",
            "83\t0.1442109649380048\t0.9585286458333333\n",
            "84\t0.1476629080871741\t0.9569010416666667\n",
            "85\t0.1457385209699472\t0.9581705729166666\n",
            "86\t0.14150583719213802\t0.9594075520833333\n",
            "87\t0.1342747390270233\t0.96171875\n",
            "88\t0.13171310151616733\t0.9618489583333333\n",
            "89\t0.13435128902395566\t0.9615559895833333\n",
            "90\t0.13314280410607657\t0.95986328125\n",
            "91\t0.13406430184841156\t0.9597330729166667\n",
            "92\t0.13107406993707021\t0.962109375\n",
            "93\t0.12322861552238465\t0.9634114583333333\n",
            "94\t0.12028800398111343\t0.9653971354166667\n",
            "95\t0.12226193398237228\t0.96484375\n",
            "96\t0.11966343224048615\t0.96474609375\n",
            "97\t0.1145167405406634\t0.9670247395833333\n",
            "98\t0.11836316486199697\t0.9654947916666666\n",
            "99\t0.11764349589745203\t0.9660481770833333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5TEkfFsgPcS",
        "colab_type": "text"
      },
      "source": [
        "# Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hEfOvDHmDgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model_for_sampling(num_of_unique_chars):\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Embedding(input_dim = num_of_unique_chars, output_dim = 512, \n",
        "                        batch_input_shape = (1, 1))) \n",
        "  \n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add(LSTM(256, stateful = True)) \n",
        "    model.add(Dropout(0.2))\n",
        "    \n",
        "    model.add((Dense(num_of_unique_chars)))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0Fi0dt7i7Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_seq(seq):\n",
        "  count = 0\n",
        "  for i in seq:\n",
        "      count += 1\n",
        "      if i == \"\\n\":\n",
        "          break\n",
        "  beginning_part_removed = seq[count:]\n",
        "\n",
        "  count = 0\n",
        "  for i in beginning_part_removed:\n",
        "      count += 1\n",
        "      if i == \"\\n\" and beginning_part_removed[count] == \"\\n\":\n",
        "          break\n",
        "  ending_part_removed = beginning_part_removed[:count]\n",
        "  return ending_part_removed\n",
        "\n",
        "def generate_sequence(model_weights_address, initial_index, \n",
        "                      seq_length, is_abc=False):\n",
        "    sequence_index = [initial_index]\n",
        "\n",
        "    model = make_model_for_sampling(num_of_unique_chars)\n",
        "    model.load_weights(model_weights_address)\n",
        "    \n",
        "    for i in range(seq_length):\n",
        "        batch = np.zeros((1, 1))\n",
        "        batch[0, 0] = sequence_index[-1]\n",
        "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
        "        sample = np.random.choice(range(num_of_unique_chars), size = 1, p = predicted_probs)\n",
        "        \n",
        "        sequence_index.append(sample[0])\n",
        "    \n",
        "    seq = ''.join(index_to_char[c] for c in sequence_index)\n",
        "    \n",
        "    if is_abc:\n",
        "      return adjust_seq(seq)\n",
        "    else:\n",
        "      return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2dXl67HTbTk",
        "colab_type": "code",
        "outputId": "9034a50c-2580-407d-f98c-510d3db281b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "seq = generate_sequence(\"Weights_mozart.h5\", 0, 500)\n",
        "print(seq)\n",
        "with open('gen_song.ms', 'w') as gen_song_file:\n",
        "  gen_song_file.write(seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tvyxutrpvy|{ywutrpturpomkihfdhfdca_a_]\\ZXX\\X\\_dhkpkwtwtpyupy{ywutrpoywutrpomkihfdhfdca_^_]\\ZX]X_X]X]fhi__ba]^]\\d]acddfhikmoprtuworpihikihfdcdfcihfidfcdh_hf]i\\df\\hd`fchrpomdhkf]dcdgafcilmlklmnoptrtrttpqomkjkmkmkjkmoqrrrrqomkjkmkmkmkjkmoqrrrrtrqywvtrpomoprtvwvwwrwroprpoprtvwrrrtrprpopomomkfhjkmoprtvwrrrtrprpopomomkfhjkmoprtvwrrrtrprpopomomkfhjkmoprtvwrrrtrprpopomomkfhjkmoprtvwrrrtrprpopomomkfhjkmoprtvwrrrtrprpopomomkfhjkmoprtvwrrrtrprpopomomkfhjkmoprtvwrrrtrprpopomomkfhjkmoprtvwrrrtrprpopomomkfhjkm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxkgs_4VkOtY",
        "colab_type": "text"
      },
      "source": [
        "# Convert To MIDI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmTKn_ETSM4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert gen_song to midi format\n",
        "import MIDI\n",
        "\n",
        "notes = []\n",
        "with open(\"gen_song.ms\", \"r\") as song_file:\n",
        "    chrs = song_file.read()\n",
        "    for chr in chrs:\n",
        "        if ord(chr) >= 35:\n",
        "            notes.append(ord(chr) - 35)\n",
        "\n",
        "song_score = [480, [['track_name', 0, b'Gen Song by Deep Learning, opus 10'], ['set_tempo', 0, 294840]]]\n",
        "# ['note', start_time, duration, channel, note, velocity]\n",
        "\n",
        "\n",
        "song_score.append([['track_name', 0, b'Piano Right'], ['patch_change', 0, 0, 0]])\n",
        "time = 1000\n",
        "for note in notes:\n",
        "    song_score[-1].append(['note', time, 240, 0, note, 50])\n",
        "    time += 360\n",
        "\n",
        "\n",
        "midi_data = MIDI.score2midi(song_score)\n",
        "with open('generated_song.mid', 'wb') as midi_file:\n",
        "    midi_file.write(midi_data)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}